{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Comparativo - Árvore de Decisão e Floresta Aleatória",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amadords/Projetos-Publicos/blob/master/Comparativo_%C3%81rvore_de_Decis%C3%A3o_e_Floresta_Aleat%C3%B3ria.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-VjrUThmp6E"
      },
      "source": [
        "# Então... Árvore ou Floresta?\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "[![LinkedIn](https://img.shields.io/badge/LinkedIn-DanielSousaAmador-purple.svg)](https://www.linkedin.com/in/daniel-sousa-amador)\n",
        "[![GitHub](https://img.shields.io/badge/GitHub-amadords-darkblue.svg)](https://github.com/amadords)\n",
        "[![Medium](https://img.shields.io/badge/Medium-DanielSousaAmador-darkorange.svg)](https://medium.com/@daniel.s.amador)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Se você leu sobre as **[Árvores](https://bit.ly/2Guqmcd)** e **[Florestas](https://bit.ly/2Sg9LM7)** deve ter ficado tentado a utilizar sempre o *Random Forest*, pois é uma melhoria das Árvores e, via de regra, evita mais facilmente problemas como o *sobreajuste*.\n",
        "\n",
        "Geralmente, sim! o *Random Forest* vai se sair melhor, pois ele vai ter um pouco mais de maleabilidade, já que cria várias árvores, contudo nem sempre as árvores se sairão piores. \n",
        "\n",
        "Veja, quando estudantes aprendem técnicas de **Deep Learning** (Aprendizagem Profunda) é comum querer utilizar em tudo, até em problemas que o mais simples dos algoritmos (algoritmos lineares) podem resolver, então muitas vezes as árvores podem já resolver o problema, principalmente porque serve, muitas vezes, de *baseline*, ou seja, serve como ponto de partida o qual os algoritmos devem tentar minimamente ultrapassar seu resultado final. \n",
        "\n",
        "Muitas vezes você irá querer somente *extrair regras* e/ou tentar buscar quais são as *features mais importantes* para o seu modelo e, nesses casos, *normalmente é melhor utilizar Árvore*, pois as florestas irão criar várias árvores, com várias regras diferentes e, caso você necessite somente desse suporte, talvez seja melhor utilizar Árvore.\n",
        "\n",
        "**Dica**: Comece sempre pela *Árvore*, depois utilize também as *Florestas*, mas não comece diretamente pelas Florestas. Isso é apenas um *conselho* e *boa prática*.\n",
        "\n",
        "![comparativo](https://image.freepik.com/fotos-gratis/boxe-profissional-dois-boxe-no-espaco-preto-esfumacado_155003-12726.jpg)\n",
        "\n",
        "## O que faremos aqui?\n",
        "\n",
        "**Comparativo** entre os dois algoritmos!\n",
        "\n",
        "Já adianto que, o *Random Forest* se sairá melhor no exemplo abaixo, contudo, como dito acima, nem sempre isso acontece e cabe ao **Cientista de Dados** avaliar **SEMPRE** os resultados, inclusive fazendo **Tuning** do modelo.\n",
        "\n",
        "## Tuning?\n",
        "\n",
        "Calma, vamos fazer os comparativos e, quando chegarmos nele eu te explico, mas tuning é basicamente alterar os parâmetros do algoritmo para tentar melhorá-lo!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fmAJWZpmp6H"
      },
      "source": [
        "## Checklist\n",
        "1. Leitura e Preparação de Dados\n",
        "2. Random Forest\n",
        "3. Decision Tree\n",
        "4. Verificando Overfitting\n",
        "5. Tuning do Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFB7Twhnmp6K"
      },
      "source": [
        "**Importação das bibliotecas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5SdwJbVmp6M"
      },
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmtMzXtcmp6X"
      },
      "source": [
        "# 1. Leitura e Preparação de Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nQnUS9Qmp6Z"
      },
      "source": [
        "**Leitura dos dados**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xK5kqiosmp6a"
      },
      "source": [
        "df_edu = pd.read_csv('/home/amador/dados/xAPI-Edu-Data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0czeHuump6f",
        "outputId": "51dce50f-ef8d-4ec5-b39c-1a1a27b2dc1e"
      },
      "source": [
        "df_edu.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>NationalITy</th>\n",
              "      <th>PlaceofBirth</th>\n",
              "      <th>StageID</th>\n",
              "      <th>GradeID</th>\n",
              "      <th>SectionID</th>\n",
              "      <th>Topic</th>\n",
              "      <th>Semester</th>\n",
              "      <th>Relation</th>\n",
              "      <th>raisedhands</th>\n",
              "      <th>VisITedResources</th>\n",
              "      <th>AnnouncementsView</th>\n",
              "      <th>Discussion</th>\n",
              "      <th>ParentAnsweringSurvey</th>\n",
              "      <th>ParentschoolSatisfaction</th>\n",
              "      <th>StudentAbsenceDays</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>KW</td>\n",
              "      <td>KuwaIT</td>\n",
              "      <td>lowerlevel</td>\n",
              "      <td>G-04</td>\n",
              "      <td>A</td>\n",
              "      <td>IT</td>\n",
              "      <td>F</td>\n",
              "      <td>Father</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Good</td>\n",
              "      <td>Under-7</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M</td>\n",
              "      <td>KW</td>\n",
              "      <td>KuwaIT</td>\n",
              "      <td>lowerlevel</td>\n",
              "      <td>G-04</td>\n",
              "      <td>A</td>\n",
              "      <td>IT</td>\n",
              "      <td>F</td>\n",
              "      <td>Father</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>25</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Good</td>\n",
              "      <td>Under-7</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>KW</td>\n",
              "      <td>KuwaIT</td>\n",
              "      <td>lowerlevel</td>\n",
              "      <td>G-04</td>\n",
              "      <td>A</td>\n",
              "      <td>IT</td>\n",
              "      <td>F</td>\n",
              "      <td>Father</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>No</td>\n",
              "      <td>Bad</td>\n",
              "      <td>Above-7</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  gender NationalITy PlaceofBirth     StageID GradeID SectionID Topic  \\\n",
              "0      M          KW       KuwaIT  lowerlevel    G-04         A    IT   \n",
              "1      M          KW       KuwaIT  lowerlevel    G-04         A    IT   \n",
              "2      M          KW       KuwaIT  lowerlevel    G-04         A    IT   \n",
              "\n",
              "  Semester Relation  raisedhands  VisITedResources  AnnouncementsView  \\\n",
              "0        F   Father           15                16                  2   \n",
              "1        F   Father           20                20                  3   \n",
              "2        F   Father           10                 7                  0   \n",
              "\n",
              "   Discussion ParentAnsweringSurvey ParentschoolSatisfaction  \\\n",
              "0          20                   Yes                     Good   \n",
              "1          25                   Yes                     Good   \n",
              "2          30                    No                      Bad   \n",
              "\n",
              "  StudentAbsenceDays Class  \n",
              "0            Under-7     M  \n",
              "1            Under-7     M  \n",
              "2            Above-7     L  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3SqKh8Qmp6n"
      },
      "source": [
        "**Verificando classes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK0IImUBmp6o",
        "outputId": "8b88ce88-c6d6-4862-fd69-e972205a28b8"
      },
      "source": [
        "df_edu['Class'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "M    211\n",
              "H    142\n",
              "L    127\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vP0Ro8agmp6u"
      },
      "source": [
        "**Verificando registros nulos**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckKDcUbFmp6v",
        "outputId": "f3dc5238-a458-4f24-b7dc-381aeedc877c"
      },
      "source": [
        "df_edu.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gender                      0\n",
              "NationalITy                 0\n",
              "PlaceofBirth                0\n",
              "StageID                     0\n",
              "GradeID                     0\n",
              "SectionID                   0\n",
              "Topic                       0\n",
              "Semester                    0\n",
              "Relation                    0\n",
              "raisedhands                 0\n",
              "VisITedResources            0\n",
              "AnnouncementsView           0\n",
              "Discussion                  0\n",
              "ParentAnsweringSurvey       0\n",
              "ParentschoolSatisfaction    0\n",
              "StudentAbsenceDays          0\n",
              "Class                       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjOF86qhmp60"
      },
      "source": [
        "**Codificando os atributos numéricos**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0XuFrc3mp62"
      },
      "source": [
        "Features = df_edu\n",
        "Cat_Colums = Features.dtypes.pipe(lambda Features: Features[Features=='object']).index\n",
        "for col in Cat_Colums:\n",
        "    label = LabelEncoder()\n",
        "    Features[col] = label.fit_transform(Features[col])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7pXEws6mp66"
      },
      "source": [
        "**Separando dados**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-b4Gs2f0mp66"
      },
      "source": [
        "dataset = df_edu.drop('Class',axis=1)\n",
        "classes = df_edu['Class']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PiotRvFmp6_"
      },
      "source": [
        "# 2. Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8inhSsgamp6_"
      },
      "source": [
        "**Instanciando o classificador**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6d_cJKJmp7A"
      },
      "source": [
        "# random_state=1 para garantir o mesmo resultado em cada algoritmo (na separação dos dados)\n",
        "# n_estimator=100\n",
        "random_clf = RandomForestClassifier(random_state=1,n_estimators=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp_Rt0Hrmp7E"
      },
      "source": [
        "**Cross Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq1XhSPYmp7F",
        "outputId": "7c161fb5-c500-4317-daf3-07a01929fbd3"
      },
      "source": [
        "resultados_random = cross_val_predict(random_clf, dataset, classes, cv=5)\n",
        "print(classification_report(classes,resultados_random))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.64      0.65       142\n",
            "           1       0.77      0.78      0.77       127\n",
            "           2       0.63      0.63      0.63       211\n",
            "\n",
            "    accuracy                           0.67       480\n",
            "   macro avg       0.68      0.68      0.68       480\n",
            "weighted avg       0.67      0.67      0.67       480\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NhusOIimp7J"
      },
      "source": [
        "# 3. Decision Tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n92vHTRbmp7L"
      },
      "source": [
        "**Métricas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "aT_THT8xmp7M",
        "outputId": "38608c9b-2346-447d-8132-ca5c395c0c7e"
      },
      "source": [
        "tree_clf = DecisionTreeClassifier(random_state=1) # random_state=1 para garantir a mesma semente\n",
        "resultados_tree = cross_val_predict(tree_clf,dataset,classes,cv=5)\n",
        "print(classification_report(classes,resultados_tree))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.61      0.55       142\n",
            "           1       0.74      0.68      0.70       127\n",
            "           2       0.54      0.49      0.52       211\n",
            "\n",
            "    accuracy                           0.57       480\n",
            "   macro avg       0.59      0.59      0.59       480\n",
            "weighted avg       0.58      0.57      0.58       480\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idUwWdPZmp7Q"
      },
      "source": [
        "### Cross Validation?\n",
        "Ou **Validação Cruzada**...\n",
        "\n",
        "Sim! Em ambos algoritmos o utilizamos e ele serve para tentar avaliar a capacidade de um modelo em generalizar os dados e deve sempre ser usado em *modelagens preditavas*!\n",
        "\n",
        "O **cross validation** particiona, ou seja, divide um conjunto de dados em partes a ser definido pelo *Cientista de Dados* em conjuntos menores ou subconjuntos onde, nenhum dado está repetido em nenhum outro subconjunto e o algoritmo utilizará parte dos dados para treinar, parte para testar. \n",
        "\n",
        "Exemplo: Se o **K-fold**, ou seja, a quantidade de particionamento dos dados for igual a 5, o algoritmo fará 5 testes e retornará o resultado para cada um deles.\n",
        "* Teste 1: Treino com subconjuntos 1,2,3 e 4 e teste com o 5.\n",
        "* Teste 2:Treino com subconjuntos 2,3,4 e 5 e teste com o 1.\n",
        "* Teste 3: Treino com subconjuntos 1,3,4 e 5 e teste com o 2.\n",
        "* Teste 4: Treino com subconjuntos 1,2,4 e 5 e teste com o 3.\n",
        "* Teste 5:Treino com subconjuntos 1,2,3 e 5 e teste com o 4.\n",
        "\n",
        "Isso mostra um resultado mais fiel do algoritmo, para evitar mascaração de resultados para melhor ou para pior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVGipT3Amp7R"
      },
      "source": [
        "# 4. Verificando Overfitting\n",
        "\n",
        "Para verificar o overfitting, ou sobreajuste, iremos criar duas funções, uma para o *Random Forest* e outro para a *Decision Tree* que irão comparar vários modelos com o parâmetro **max_depth** e retornará a **acurárica** entre os dados de *treino* e *teste* e, assim vamos ver onde os modelos começam e terminam o sobreajuste."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMonxCiSmp7S"
      },
      "source": [
        "**Dividindo os dados**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC2E8Dmxmp7S"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_edu.drop('Class',axis=1),df_edu['Class'],test_size=0.3,random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sin8xXrQmp7W"
      },
      "source": [
        "**Criando função para comparar os modelos de random forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC03v6NBmp7X"
      },
      "source": [
        "def compara_modelos_random_forest(maxdepth):\n",
        "    if maxdepth == 0:\n",
        "        rf = RandomForestClassifier(n_estimators=100,random_state=1)\n",
        "    else: \n",
        "        rf = RandomForestClassifier(n_estimators=100,random_state=1, max_depth=maxdepth)\n",
        "    rf.fit(X_train, y_train)\n",
        "    train_score = rf.score(X_train, y_train)\n",
        "    test_score = rf.score(X_test, y_test)\n",
        "    return train_score,test_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrp-VGS0mp7b",
        "outputId": "04873fc4-8ebe-49a3-fa2b-e434ff3e5c59"
      },
      "source": [
        "print('{:10} {:20} {:20}'.format('depth', 'Training score','Testing score'))\n",
        "print('{:10} {:20} {:20}'.format('-----', '--------------','-------------'))\n",
        "print('{:1}         {} '.format(2,str(compara_modelos_random_forest(2))))\n",
        "print('{:1}         {} '.format(3,str(compara_modelos_random_forest(3))))\n",
        "print('{:1}         {} '.format(4,str(compara_modelos_random_forest(4))))\n",
        "print('{:1}         {} '.format(10,str(compara_modelos_random_forest(10))))\n",
        "print('{:1}         {} '.format(15,str(compara_modelos_random_forest(15))))\n",
        "print('{:1}         {} '.format('Full',str(compara_modelos_random_forest(0))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "depth      Training score       Testing score       \n",
            "-----      --------------       -------------       \n",
            "2         (0.75, 0.6180555555555556) \n",
            "3         (0.8244047619047619, 0.6805555555555556) \n",
            "4         (0.8720238095238095, 0.7152777777777778) \n",
            "10         (1.0, 0.7569444444444444) \n",
            "15         (1.0, 0.7986111111111112) \n",
            "Full         (1.0, 0.7986111111111112) \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6QV9o7Mmp7f"
      },
      "source": [
        "A partir de **max_depth=10** já está totalmente enviesado, aparentemente o melhor resultado é com o valor **max_depth=3**, pois a diferença entre a acertividade de *treino* e *teste* é de aproximadamente **14%**, enquanto os demais passam disso, ou, no caso do **max_depth=2** que também está no mesmo valor, a acertividade está mais baixa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOniUEX1mp7g"
      },
      "source": [
        "**Criando função para comparar os modelos de decision tree**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-RFJ6Shmp7h"
      },
      "source": [
        "def compara_modelos_decision_tree(maxdepth):\n",
        "    if maxdepth == 0:\n",
        "        df = DecisionTreeClassifier(random_state=1)\n",
        "    else: \n",
        "        df = DecisionTreeClassifier(random_state=1, max_depth=maxdepth)\n",
        "    df.fit(X_train, y_train)\n",
        "    train_score = df.score(X_train, y_train)\n",
        "    test_score = df.score(X_test, y_test)\n",
        "    return train_score,test_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_lQBCi6mp7m",
        "outputId": "e8a6e4ef-7f1d-4d10-fe31-8522866eaf30"
      },
      "source": [
        "print('{:10} {:20} {:20}'.format('depth', 'Training score','Testing score'))\n",
        "print('{:10} {:20} {:20}'.format('-----', '--------------','-------------'))\n",
        "print('{:1}         {} '.format(2,str(compara_modelos_decision_tree(2))))\n",
        "print('{:1}         {} '.format(3,str(compara_modelos_decision_tree(3))))\n",
        "print('{:1}         {} '.format(4,str(compara_modelos_decision_tree(4))))\n",
        "print('{:1}         {} '.format(10,str(compara_modelos_decision_tree(10))))\n",
        "print('{:1}         {} '.format(15,str(compara_modelos_decision_tree(15))))\n",
        "print('{:1}         {} '.format('Full',str(compara_modelos_decision_tree(0))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "depth      Training score       Testing score       \n",
            "-----      --------------       -------------       \n",
            "2         (0.6398809523809523, 0.6805555555555556) \n",
            "3         (0.7321428571428571, 0.7013888888888888) \n",
            "4         (0.7916666666666666, 0.7430555555555556) \n",
            "10         (0.9910714285714286, 0.6875) \n",
            "15         (1.0, 0.6944444444444444) \n",
            "Full         (1.0, 0.6944444444444444) \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2pHJrNUmp7q"
      },
      "source": [
        "A partir de **max_depth=10** já está totalmente enviesado, aparentemente o melhor resultado está entre os valores **max_depth=3** e **max_depth=4**, pois a diferença entre a acertividade de *treino* e *teste* é de aproximadamente **3%** e **5%**, respectivamente, enquanto os demais passam disso. Aquele tem uma difença menor em relação aos dados de *treino* e *teste*, contudo com acertividade inferior, então vale a pena cogitar utilizar o *max_depth=4*, uma vez que sua *acertividade* é melhor, embora o *erro* também seja maior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grMpWsGDmp7t"
      },
      "source": [
        "# 5. Tuning do Modelo\n",
        "Como expliquei, Tunning do modelo é a alteração dos parâmetros do algoritmo para que haja alguma melhora no seu resultado final.\n",
        "\n",
        "O **Tuning** deve **SEMPRE** ser feito para que você possa tentar extrair o melhor do seu modelo.\n",
        "\n",
        "Aqui utilizaremos o **GridSearchCV** da **sklearn.model_selection** para fazer o tuning. O Grid nos permite testar os parâmetros em várias combinações e irá nos permitir realmente encontrar os melhores parâmetros.\n",
        "\n",
        "### Quando utilizar?\n",
        "* Após você encontrar o melhor algoritmo e a razão disso é o custo computacional e temporal.\n",
        "* Quanto *mais parâmetros* você colocar dentro do Grid, *mais demorado* será para o Grid retornar, então usá-lo com todos os parâmetros e todos os algoritmos não é uma boa prática, embora você possa querer fazer.\n",
        "\n",
        "### Como usar?\n",
        "* Para cada parâmetro você cria uma **lista de valores** que o algoritmo irá testar através de uma *análise combinatória* com os demais parâmetros.\n",
        "* Após criar todas as listas, cria-se o **Dicionário** unindo todas as listas.\n",
        "* O dicionário é bem intuitivo e utiliza o padrão **chave:valor**, assim como um dicionário onde se tem **palavra:explicação da palavra**.\n",
        "* No dicionário a **chave** (key) será o nome do parâmetro do algoritmo e o **valor** (value) será a lista criada para aquele parâmetro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwbJOQmvmp7t"
      },
      "source": [
        "**GridSearchCV para testes de Hyperparametros**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2oDUaU1mp7u"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLp-5O4Nmp7y"
      },
      "source": [
        "# lista de possíveis valores de estimators ou quantidade de árvores da floresta.\n",
        "valores_estimators = [10, 20, 50, 100, 150]\n",
        "# lista de possíveis valores para o critério de divisão.\n",
        "valores_criterion = ['gini','entropy']\n",
        "# lista de possíveis valores para a profundidade máxima de cada árvore\n",
        "valores_max_depth = [10, 20, 50, 100]\n",
        "# lista de possíveis valores para os parametros min_samples_split e min_samples_leaf.\n",
        "valores_min_samples_split = [2, 5, 10,15]\n",
        "valores_min_samples_leaf = [1, 5, 10,15]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcJXWMc7mp71"
      },
      "source": [
        "# definindo um dicionário que recebe as listas de parâmetros e valores\n",
        "parametros_grid = dict(n_estimators=valores_estimators,\n",
        "                       criterion=valores_criterion,\n",
        "                       max_depth=valores_max_depth,\n",
        "                       min_samples_split=valores_min_samples_split,\n",
        "                       min_samples_leaf=valores_min_samples_leaf \n",
        "                      )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmwN-UKcmp75",
        "outputId": "c071e872-17da-42d9-a114-6542a44ac017"
      },
      "source": [
        "# visualizando o dicionário\n",
        "parametros_grid"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_estimators': [10, 20, 50, 100, 150],\n",
              " 'criterion': ['gini', 'entropy'],\n",
              " 'max_depth': [10, 20, 50, 100],\n",
              " 'min_samples_split': [2, 5, 10, 15],\n",
              " 'min_samples_leaf': [1, 5, 10, 15]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hdc_0vwRmp78"
      },
      "source": [
        "**Instanciando o GridSearch**\n",
        "\n",
        "Passamos o modelo a ser utilizado, parametros, número de folds e scoring."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_G9PPkYmp79"
      },
      "source": [
        "rf = RandomForestClassifier()\n",
        "grid = GridSearchCV(rf, parametros_grid, cv=5, scoring='accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JQ9Mr7Jmp8A"
      },
      "source": [
        "**Aplicando o GridSearch passando as features e classes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gZfY1ZImp8B",
        "outputId": "2ca794f9-2ff3-45e5-c871-4e4c0a34397f"
      },
      "source": [
        "grid.fit(df_edu.drop('Class',axis=1),df_edu['Class'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
              "             param_grid={'criterion': ['gini', 'entropy'],\n",
              "                         'max_depth': [10, 20, 50, 100],\n",
              "                         'min_samples_leaf': [1, 5, 10, 15],\n",
              "                         'min_samples_split': [2, 5, 10, 15],\n",
              "                         'n_estimators': [10, 20, 50, 100, 150]},\n",
              "             scoring='accuracy')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsB3hRGOmp8G"
      },
      "source": [
        "### Retornos\n",
        "* **grid.cv_results_**: trará todos os *resultados*.\n",
        "* **grid.best_params_**: retornará os *melhores parâmetros* dentro dos definidos para o *tunning*.\n",
        "* **grid.best_score_**: retorna o *melhor score*, ou seja, a melhor acurácia do modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRksh08jmp8G"
      },
      "source": [
        "**Resultados**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV-9qGLsmp8H",
        "outputId": "d7a8a9a8-563c-474c-eead-5476e6454909"
      },
      "source": [
        "grid.cv_results_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([0.02293205, 0.03522577, 0.08094926, 0.1670074 , 0.24271665,\n",
              "        0.01907005, 0.03491116, 0.08191419, 0.15982809, 0.24128251,\n",
              "        0.01795592, 0.0343164 , 0.08096542, 0.15760651, 0.23766122,\n",
              "        0.01822443, 0.03362122, 0.07972255, 0.15460191, 0.23096199,\n",
              "        0.01859546, 0.03418808, 0.08017874, 0.1561121 , 0.23477397,\n",
              "        0.01904745, 0.03352094, 0.08049517, 0.15526686, 0.22934322,\n",
              "        0.01944947, 0.03250241, 0.07839513, 0.1561244 , 0.22885098,\n",
              "        0.01841297, 0.03362656, 0.07836776, 0.15884805, 0.22967916,\n",
              "        0.01887193, 0.03412056, 0.07738152, 0.15168729, 0.22521133,\n",
              "        0.01767783, 0.03267379, 0.07627134, 0.15235372, 0.22459865,\n",
              "        0.01749697, 0.03185611, 0.08015285, 0.14951835, 0.22577643,\n",
              "        0.01796961, 0.03286648, 0.07640452, 0.14964576, 0.22370377,\n",
              "        0.01794796, 0.03197722, 0.07551851, 0.14767203, 0.22017674,\n",
              "        0.01757221, 0.03179832, 0.07490859, 0.14613094, 0.2147419 ,\n",
              "        0.01729274, 0.03195348, 0.0755949 , 0.14537802, 0.22011447,\n",
              "        0.01705198, 0.03247256, 0.07580013, 0.14815044, 0.22123442,\n",
              "        0.01976557, 0.03515329, 0.08191528, 0.16165543, 0.2417738 ,\n",
              "        0.01918302, 0.03463421, 0.08502045, 0.16533079, 0.24062595,\n",
              "        0.01830554, 0.03406506, 0.08183107, 0.15814919, 0.24071631,\n",
              "        0.01804128, 0.03340917, 0.07769876, 0.15835271, 0.23106327,\n",
              "        0.01855898, 0.0337863 , 0.07986417, 0.15505719, 0.23750906,\n",
              "        0.01865706, 0.03390608, 0.07924695, 0.15453091, 0.2307271 ,\n",
              "        0.01822124, 0.03472133, 0.08080034, 0.15698776, 0.22809839,\n",
              "        0.01785192, 0.03303394, 0.07768712, 0.15239248, 0.22501621,\n",
              "        0.01745138, 0.03279648, 0.07722192, 0.14919014, 0.22946601,\n",
              "        0.01796141, 0.0324964 , 0.07743959, 0.15227504, 0.22387552,\n",
              "        0.01724753, 0.03261819, 0.0776351 , 0.15114293, 0.23124847,\n",
              "        0.01825271, 0.03235292, 0.07843962, 0.14940305, 0.22373571,\n",
              "        0.01725855, 0.03161616, 0.07486172, 0.14552078, 0.21821785,\n",
              "        0.01795464, 0.03223319, 0.07566628, 0.14811401, 0.22157803,\n",
              "        0.01749191, 0.03250947, 0.07529836, 0.14684162, 0.21802526,\n",
              "        0.01701336, 0.03143311, 0.07433081, 0.14588995, 0.22072077,\n",
              "        0.01971555, 0.03696737, 0.08167801, 0.16311836, 0.24495516,\n",
              "        0.01884227, 0.04019432, 0.09282084, 0.18611784, 0.25982432,\n",
              "        0.01848035, 0.03434505, 0.09938641, 0.15897002, 0.25392437,\n",
              "        0.02218719, 0.03525114, 0.08233738, 0.17488027, 0.2635078 ,\n",
              "        0.01921024, 0.03486733, 0.08913665, 0.16577463, 0.26816287,\n",
              "        0.01946058, 0.03564668, 0.08345952, 0.15807652, 0.22991457,\n",
              "        0.01816854, 0.03389487, 0.08132081, 0.15435266, 0.23133183,\n",
              "        0.01776857, 0.03371596, 0.07958231, 0.15784154, 0.23864884,\n",
              "        0.0192019 , 0.03399506, 0.07644997, 0.15042992, 0.22027688,\n",
              "        0.01787357, 0.03179817, 0.07784448, 0.148915  , 0.22458591,\n",
              "        0.01774473, 0.03265157, 0.07644496, 0.14915242, 0.22199817,\n",
              "        0.01853957, 0.03234711, 0.0760963 , 0.14817119, 0.22112103,\n",
              "        0.01749144, 0.03146677, 0.0738153 , 0.14581666, 0.21780319,\n",
              "        0.01764517, 0.03141375, 0.07382469, 0.14677305, 0.22201414,\n",
              "        0.01719141, 0.03235283, 0.07488422, 0.14574304, 0.22026706,\n",
              "        0.017589  , 0.03267708, 0.07627831, 0.14778457, 0.22069831,\n",
              "        0.02008438, 0.03481793, 0.08214235, 0.16243706, 0.2427268 ,\n",
              "        0.01864705, 0.0346931 , 0.09426842, 0.16117702, 0.23963485,\n",
              "        0.01876726, 0.03418093, 0.08179588, 0.15795989, 0.23597245,\n",
              "        0.01912379, 0.03562908, 0.07972221, 0.15354552, 0.23412552,\n",
              "        0.01904111, 0.03306036, 0.07817111, 0.15607772, 0.23117194,\n",
              "        0.01879997, 0.03294735, 0.07809443, 0.15284882, 0.2296761 ,\n",
              "        0.01777205, 0.03421187, 0.07921925, 0.15505576, 0.23049603,\n",
              "        0.01890845, 0.03354321, 0.07904229, 0.15382595, 0.23571429,\n",
              "        0.01752529, 0.03314214, 0.07838702, 0.15303135, 0.22412601,\n",
              "        0.0177702 , 0.03466687, 0.0792995 , 0.15584035, 0.2257206 ,\n",
              "        0.01792669, 0.03175073, 0.07650118, 0.15224648, 0.22526646,\n",
              "        0.01801291, 0.0331152 , 0.07696729, 0.15171261, 0.25305591,\n",
              "        0.0196023 , 0.03373632, 0.09248562, 0.17419844, 0.27476578,\n",
              "        0.01894984, 0.03512363, 0.08301926, 0.16685643, 0.26229792,\n",
              "        0.02578454, 0.05405869, 0.15380497, 0.22848792, 0.2457252 ,\n",
              "        0.03039436, 0.06128855, 0.12828565, 0.30596204, 0.43845205,\n",
              "        0.03914118, 0.04967909, 0.09628801, 0.22003231, 0.25964317,\n",
              "        0.02186499, 0.03886161, 0.10135632, 0.17412887, 0.25415416,\n",
              "        0.01920176, 0.03550577, 0.08830347, 0.17969975, 0.25483437,\n",
              "        0.01902542, 0.03549218, 0.08445964, 0.16238623, 0.24286547,\n",
              "        0.01857934, 0.03538952, 0.08303099, 0.16174822, 0.23885856,\n",
              "        0.0187593 , 0.03483753, 0.08188448, 0.16106205, 0.23807931,\n",
              "        0.0185987 , 0.03648772, 0.08307557, 0.1632689 , 0.23933301,\n",
              "        0.01798306, 0.0340651 , 0.08037648, 0.15810046, 0.2401824 ,\n",
              "        0.01800842, 0.03371911, 0.07952971, 0.15310006, 0.22633929,\n",
              "        0.01850314, 0.03368478, 0.07890816, 0.16468625, 0.23612523,\n",
              "        0.01887493, 0.041469  , 0.08406744, 0.15434866, 0.27901397,\n",
              "        0.01849041, 0.03564997, 0.09600492, 0.15475731, 0.2565177 ,\n",
              "        0.02029734, 0.03315935, 0.08270392, 0.17059517, 0.25699506,\n",
              "        0.01914382, 0.03285851, 0.09623833, 0.16809921, 0.23322334,\n",
              "        0.01807771, 0.03396935, 0.07568836, 0.15025058, 0.23820338,\n",
              "        0.01747022, 0.0318449 , 0.07670503, 0.14916143, 0.22275853,\n",
              "        0.02065029, 0.03688645, 0.08771663, 0.17658968, 0.25817327,\n",
              "        0.01995072, 0.03738332, 0.08577881, 0.17554889, 0.26393118,\n",
              "        0.02004089, 0.0389205 , 0.08645225, 0.16579013, 0.24403033,\n",
              "        0.01853786, 0.03428941, 0.08125196, 0.15908194, 0.23688021,\n",
              "        0.01919436, 0.03546386, 0.0823956 , 0.16053658, 0.23783293,\n",
              "        0.01844206, 0.03379111, 0.08175039, 0.16318736, 0.24254518,\n",
              "        0.01832285, 0.03426771, 0.08135614, 0.16352396, 0.24364228,\n",
              "        0.0179719 , 0.03445687, 0.08219194, 0.15893579, 0.23946552,\n",
              "        0.01841106, 0.03251166, 0.07903256, 0.15470738, 0.22916059,\n",
              "        0.01852608, 0.03391776, 0.07904663, 0.15099816, 0.22811165,\n",
              "        0.01826725, 0.03348241, 0.07858157, 0.15837331, 0.2272922 ,\n",
              "        0.01771975, 0.03239617, 0.07929292, 0.15118489, 0.22545071,\n",
              "        0.01730804, 0.03277783, 0.07570114, 0.15212417, 0.22242212,\n",
              "        0.01775594, 0.0314239 , 0.07596445, 0.14922237, 0.22257552,\n",
              "        0.01790771, 0.03215685, 0.07473369, 0.14822049, 0.21921268,\n",
              "        0.01788526, 0.03130803, 0.07483945, 0.14844708, 0.22240896,\n",
              "        0.01946025, 0.03745823, 0.08822789, 0.17037187, 0.25562201,\n",
              "        0.0196713 , 0.03583822, 0.08684335, 0.17283773, 0.25756922,\n",
              "        0.01901097, 0.03584042, 0.08704677, 0.16486101, 0.25346022,\n",
              "        0.01938925, 0.0354548 , 0.0835916 , 0.16410136, 0.24427128,\n",
              "        0.0196466 , 0.03822203, 0.0806911 , 0.15960913, 0.23974066,\n",
              "        0.01984005, 0.03584332, 0.08207779, 0.16406412, 0.24211297,\n",
              "        0.01873522, 0.03460617, 0.08287678, 0.16089778, 0.23845539,\n",
              "        0.02390652, 0.03453693, 0.07951241, 0.15588622, 0.23615012,\n",
              "        0.01766591, 0.03279901, 0.07651367, 0.15017881, 0.22545238,\n",
              "        0.0176723 , 0.03274889, 0.07844   , 0.15280838, 0.22727122,\n",
              "        0.01835837, 0.03410025, 0.07793307, 0.15279617, 0.23247499,\n",
              "        0.01954432, 0.03336935, 0.07830291, 0.15574274, 0.23155117,\n",
              "        0.01751499, 0.03240218, 0.07546906, 0.15063238, 0.2230948 ,\n",
              "        0.01769533, 0.03225098, 0.07650943, 0.14960432, 0.22049217,\n",
              "        0.01791496, 0.0324122 , 0.07723761, 0.14771509, 0.22240033,\n",
              "        0.01824703, 0.03206635, 0.07696848, 0.14818716, 0.22304211,\n",
              "        0.0199388 , 0.03830481, 0.08866496, 0.1721283 , 0.25670252,\n",
              "        0.01993294, 0.03691053, 0.08739948, 0.17322693, 0.25601864,\n",
              "        0.02028871, 0.0357718 , 0.08565555, 0.16580029, 0.24665389,\n",
              "        0.01919017, 0.03462811, 0.08292303, 0.16195645, 0.23970294,\n",
              "        0.01889014, 0.03399963, 0.08111582, 0.16774049, 0.24838886,\n",
              "        0.02047687, 0.03746195, 0.08606424, 0.16097665, 0.23784041,\n",
              "        0.01871901, 0.03414941, 0.07996244, 0.15842004, 0.23959813,\n",
              "        0.01792912, 0.03472152, 0.08053455, 0.15429416, 0.23508401,\n",
              "        0.0190598 , 0.03261371, 0.07698841, 0.15138855, 0.2292913 ,\n",
              "        0.01816874, 0.03327608, 0.07797413, 0.15101285, 0.23104563,\n",
              "        0.01841335, 0.03593721, 0.079918  , 0.15647159, 0.22900281,\n",
              "        0.0178678 , 0.03313718, 0.07771335, 0.15451336, 0.22942853,\n",
              "        0.01740665, 0.03190651, 0.07771173, 0.15658631, 0.22578621,\n",
              "        0.01836762, 0.03362064, 0.07534413, 0.15048251, 0.23211322,\n",
              "        0.01739573, 0.03200073, 0.07494693, 0.15498862, 0.22057166,\n",
              "        0.01743474, 0.03180265, 0.07685547, 0.14903698, 0.22991376]),\n",
              " 'std_fit_time': array([0.00881715, 0.0009818 , 0.00168098, 0.006697  , 0.00277923,\n",
              "        0.00055652, 0.00121012, 0.00229605, 0.00164892, 0.00324563,\n",
              "        0.00107759, 0.00050997, 0.00121947, 0.00174178, 0.00422672,\n",
              "        0.0010774 , 0.00073074, 0.00145794, 0.00385404, 0.00090137,\n",
              "        0.00130508, 0.0002167 , 0.002408  , 0.00156853, 0.00274224,\n",
              "        0.0010629 , 0.00141374, 0.0022861 , 0.0020839 , 0.00231819,\n",
              "        0.00281562, 0.00059892, 0.00149259, 0.00190257, 0.00166301,\n",
              "        0.00062002, 0.00065703, 0.00203552, 0.00513445, 0.00498332,\n",
              "        0.00108132, 0.00134399, 0.00118315, 0.00324912, 0.00519213,\n",
              "        0.00108497, 0.00139023, 0.00109709, 0.00200202, 0.00481441,\n",
              "        0.0010899 , 0.00051024, 0.00647162, 0.00236812, 0.00244344,\n",
              "        0.00132591, 0.00074467, 0.00115632, 0.00199092, 0.00303522,\n",
              "        0.00165632, 0.0003987 , 0.00058606, 0.00318855, 0.0011221 ,\n",
              "        0.00137375, 0.00035929, 0.00119551, 0.00127368, 0.00157338,\n",
              "        0.00054924, 0.00066605, 0.00183998, 0.00196541, 0.002652  ,\n",
              "        0.00085195, 0.00128181, 0.00230353, 0.00250309, 0.00300854,\n",
              "        0.00135129, 0.00078101, 0.00096736, 0.00197985, 0.00077752,\n",
              "        0.0015704 , 0.00031274, 0.00373974, 0.00705464, 0.00440326,\n",
              "        0.0011477 , 0.00083178, 0.00161958, 0.00273277, 0.00693674,\n",
              "        0.00079978, 0.00055211, 0.00143135, 0.00175088, 0.00312608,\n",
              "        0.00142231, 0.00158456, 0.00172067, 0.00329412, 0.01068669,\n",
              "        0.00137843, 0.00119703, 0.0008624 , 0.00216354, 0.00143283,\n",
              "        0.00064454, 0.00108494, 0.00339343, 0.00316325, 0.00181968,\n",
              "        0.00054817, 0.00069339, 0.00094241, 0.00255783, 0.0023884 ,\n",
              "        0.00118121, 0.00109484, 0.0004948 , 0.00200639, 0.01686636,\n",
              "        0.00039742, 0.00146281, 0.00113165, 0.00387806, 0.0020356 ,\n",
              "        0.00069801, 0.00152451, 0.00122295, 0.00215544, 0.00548166,\n",
              "        0.00074349, 0.00053873, 0.00183898, 0.00307601, 0.00330581,\n",
              "        0.00128592, 0.00089279, 0.00282527, 0.00168948, 0.00220117,\n",
              "        0.00132704, 0.00032484, 0.00078562, 0.00221139, 0.00438162,\n",
              "        0.00049439, 0.0018589 , 0.00186457, 0.00306623, 0.00434592,\n",
              "        0.00043996, 0.00053629, 0.00100147, 0.00260991, 0.00460137,\n",
              "        0.00071626, 0.00247139, 0.00126379, 0.00225263, 0.00465205,\n",
              "        0.00055269, 0.00300636, 0.01524651, 0.02973051, 0.01239874,\n",
              "        0.0012548 , 0.0008094 , 0.01585502, 0.00150584, 0.02492635,\n",
              "        0.00284742, 0.00148357, 0.00270327, 0.01388521, 0.02272674,\n",
              "        0.00162213, 0.00173675, 0.0018845 , 0.00914305, 0.03802728,\n",
              "        0.00097501, 0.00153629, 0.00170638, 0.00537517, 0.00258253,\n",
              "        0.00096576, 0.00055555, 0.00340639, 0.00148935, 0.00250691,\n",
              "        0.00123277, 0.0017814 , 0.00155492, 0.00180373, 0.00303678,\n",
              "        0.00105937, 0.00124103, 0.00203014, 0.00366592, 0.00250086,\n",
              "        0.00190591, 0.00079545, 0.00216696, 0.00195201, 0.00199928,\n",
              "        0.00161793, 0.00121801, 0.00115396, 0.00182398, 0.0010728 ,\n",
              "        0.00184473, 0.00044647, 0.0024928 , 0.00267862, 0.00342137,\n",
              "        0.00099563, 0.0006722 , 0.0010361 , 0.00111934, 0.00174692,\n",
              "        0.00069351, 0.00041588, 0.00073667, 0.00373105, 0.00850737,\n",
              "        0.00111184, 0.00239068, 0.00123411, 0.00093513, 0.00261376,\n",
              "        0.00106748, 0.00130634, 0.00197439, 0.00330028, 0.00209548,\n",
              "        0.00245291, 0.00043757, 0.0008927 , 0.00289982, 0.00261238,\n",
              "        0.00093969, 0.00134621, 0.01538011, 0.00132445, 0.001883  ,\n",
              "        0.00119867, 0.0005555 , 0.00187241, 0.00139449, 0.00204496,\n",
              "        0.00250955, 0.00175686, 0.00253768, 0.00242522, 0.00608229,\n",
              "        0.00096577, 0.00040475, 0.00159289, 0.00225181, 0.00264549,\n",
              "        0.00090586, 0.00033562, 0.00051007, 0.00135981, 0.00382348,\n",
              "        0.00049344, 0.00180678, 0.00099604, 0.00229559, 0.00253891,\n",
              "        0.00218497, 0.00090016, 0.00142131, 0.00084493, 0.00526842,\n",
              "        0.00091359, 0.00164156, 0.00397491, 0.00091986, 0.00263141,\n",
              "        0.00170914, 0.00269095, 0.00193544, 0.00523783, 0.00207911,\n",
              "        0.0016631 , 0.00071714, 0.00108293, 0.0024326 , 0.00152996,\n",
              "        0.00068798, 0.00048784, 0.00167844, 0.00829346, 0.01438877,\n",
              "        0.00069754, 0.00156824, 0.01188581, 0.01618157, 0.033856  ,\n",
              "        0.00152451, 0.00151854, 0.01051638, 0.01126956, 0.02984758,\n",
              "        0.00743485, 0.01506316, 0.02885441, 0.04017053, 0.00709766,\n",
              "        0.00372553, 0.00697196, 0.02960993, 0.02645915, 0.06996648,\n",
              "        0.00833043, 0.00552506, 0.00454505, 0.03345095, 0.00458001,\n",
              "        0.00246044, 0.00313454, 0.01858891, 0.00323187, 0.0015257 ,\n",
              "        0.00035584, 0.00034949, 0.00405569, 0.00865446, 0.01231925,\n",
              "        0.00104265, 0.00090303, 0.0035093 , 0.00303888, 0.00267678,\n",
              "        0.00168834, 0.0013723 , 0.00190592, 0.00214647, 0.00133719,\n",
              "        0.00138872, 0.00115182, 0.00207412, 0.00238005, 0.00182958,\n",
              "        0.00052558, 0.00153737, 0.00168429, 0.00453454, 0.00192462,\n",
              "        0.00060812, 0.00051876, 0.00068446, 0.00258323, 0.00368049,\n",
              "        0.0015499 , 0.00070454, 0.0041412 , 0.00151674, 0.00176533,\n",
              "        0.00100242, 0.00184253, 0.00140869, 0.01855219, 0.00988424,\n",
              "        0.00114728, 0.00467719, 0.00642147, 0.0019728 , 0.04014493,\n",
              "        0.00085367, 0.00251044, 0.01084561, 0.00227375, 0.02346301,\n",
              "        0.0015206 , 0.00171343, 0.00418662, 0.01357612, 0.02365386,\n",
              "        0.00168631, 0.00095691, 0.00931528, 0.01332082, 0.01642598,\n",
              "        0.00093956, 0.00215523, 0.00152771, 0.00207593, 0.0241511 ,\n",
              "        0.00047753, 0.00081086, 0.00130667, 0.00306072, 0.00443579,\n",
              "        0.00171474, 0.00084221, 0.00146607, 0.00613957, 0.0049399 ,\n",
              "        0.00150547, 0.00145169, 0.00170795, 0.00823266, 0.02237447,\n",
              "        0.00151845, 0.00330767, 0.0039923 , 0.00141317, 0.00254671,\n",
              "        0.00057054, 0.00092136, 0.00148228, 0.00123778, 0.00226245,\n",
              "        0.00099755, 0.00171992, 0.00215555, 0.0021901 , 0.0015046 ,\n",
              "        0.00029714, 0.0004439 , 0.00062814, 0.00596977, 0.00254206,\n",
              "        0.00086349, 0.00078275, 0.00199223, 0.00484693, 0.00604468,\n",
              "        0.00047475, 0.00081198, 0.00178767, 0.00337147, 0.00218251,\n",
              "        0.00102404, 0.00036406, 0.00170201, 0.00200584, 0.00095568,\n",
              "        0.00188501, 0.00131476, 0.00171229, 0.00064129, 0.00320994,\n",
              "        0.00085278, 0.00119019, 0.00168923, 0.00458178, 0.00355773,\n",
              "        0.00041847, 0.00047593, 0.00153335, 0.00146022, 0.00342724,\n",
              "        0.00041305, 0.0007774 , 0.00215255, 0.00344318, 0.00358249,\n",
              "        0.00119844, 0.00106717, 0.00268724, 0.00244235, 0.00129466,\n",
              "        0.00154093, 0.00102257, 0.00088489, 0.00338611, 0.00237285,\n",
              "        0.00125912, 0.00051809, 0.00049113, 0.00259769, 0.00307322,\n",
              "        0.00147025, 0.00134519, 0.0020311 , 0.00190387, 0.00389766,\n",
              "        0.00124059, 0.00116937, 0.00170801, 0.00296119, 0.00525985,\n",
              "        0.00060964, 0.00095486, 0.00292089, 0.00287745, 0.01554482,\n",
              "        0.00126117, 0.00100983, 0.00133957, 0.00209819, 0.00660487,\n",
              "        0.00127302, 0.00501412, 0.00164308, 0.00344734, 0.00172683,\n",
              "        0.00165772, 0.00260516, 0.00140594, 0.00392752, 0.0052714 ,\n",
              "        0.00187782, 0.0009158 , 0.00201684, 0.00078859, 0.00270031,\n",
              "        0.00649374, 0.0009727 , 0.00176469, 0.00291768, 0.00714769,\n",
              "        0.00036901, 0.00145797, 0.00045467, 0.00112489, 0.00122833,\n",
              "        0.00124087, 0.00052157, 0.00151028, 0.00142745, 0.0032374 ,\n",
              "        0.00049081, 0.00155208, 0.00058368, 0.0013562 , 0.00796556,\n",
              "        0.00100553, 0.00171924, 0.00196994, 0.00385932, 0.00601104,\n",
              "        0.0014439 , 0.00114193, 0.00052931, 0.0011442 , 0.00252168,\n",
              "        0.00084048, 0.00046104, 0.00130453, 0.00214213, 0.00423491,\n",
              "        0.00053444, 0.00099899, 0.00358482, 0.0009622 , 0.00326475,\n",
              "        0.00116276, 0.00027733, 0.00147437, 0.00127923, 0.00379377,\n",
              "        0.00078202, 0.00187463, 0.00273481, 0.00702839, 0.00119526,\n",
              "        0.00095039, 0.00191396, 0.00198227, 0.00409967, 0.00403762,\n",
              "        0.00161988, 0.00091945, 0.00168362, 0.00083276, 0.00171906,\n",
              "        0.00217504, 0.00051502, 0.00075431, 0.00123319, 0.00192765,\n",
              "        0.00155939, 0.00029623, 0.00164633, 0.0042457 , 0.01336859,\n",
              "        0.00138414, 0.00576437, 0.00376753, 0.00296373, 0.00442296,\n",
              "        0.0003202 , 0.00046626, 0.00062311, 0.003833  , 0.0033069 ,\n",
              "        0.00063672, 0.00173213, 0.00297399, 0.00163165, 0.00382127,\n",
              "        0.00155857, 0.00068859, 0.00208884, 0.00361216, 0.00294693,\n",
              "        0.00119191, 0.001175  , 0.00063513, 0.00177511, 0.00309522,\n",
              "        0.00164868, 0.00513271, 0.00242587, 0.0057658 , 0.00153102,\n",
              "        0.00063599, 0.00087362, 0.00170394, 0.00286642, 0.00163692,\n",
              "        0.00049716, 0.00047511, 0.00329538, 0.01266265, 0.00356496,\n",
              "        0.00079885, 0.00211228, 0.00066257, 0.00538803, 0.00832163,\n",
              "        0.00092129, 0.00092229, 0.00138036, 0.01309718, 0.00266287,\n",
              "        0.00052823, 0.00125776, 0.00162057, 0.00271306, 0.01199422]),\n",
              " 'mean_score_time': array([0.00393891, 0.00408831, 0.00706806, 0.01221609, 0.01578603,\n",
              "        0.0029676 , 0.00401411, 0.00638208, 0.01159663, 0.01625562,\n",
              "        0.00324111, 0.00393324, 0.00709553, 0.01135406, 0.01578188,\n",
              "        0.00296512, 0.00409865, 0.00697012, 0.0118752 , 0.01550646,\n",
              "        0.00354614, 0.00449057, 0.00677714, 0.01221743, 0.0157692 ,\n",
              "        0.00281   , 0.00375557, 0.00724688, 0.01113777, 0.01539707,\n",
              "        0.0033514 , 0.00422411, 0.00676312, 0.01124578, 0.01532726,\n",
              "        0.00303597, 0.00389781, 0.00699034, 0.01107807, 0.01545234,\n",
              "        0.002946  , 0.00381794, 0.00682836, 0.01194043, 0.01553521,\n",
              "        0.00329294, 0.00400615, 0.00716777, 0.01061249, 0.01497526,\n",
              "        0.00338678, 0.00419044, 0.00666895, 0.01107316, 0.01523266,\n",
              "        0.00306888, 0.00399413, 0.00661082, 0.01096301, 0.01554456,\n",
              "        0.00301743, 0.00453777, 0.00665836, 0.0111486 , 0.01412454,\n",
              "        0.0035212 , 0.00383244, 0.00642896, 0.01083989, 0.01560287,\n",
              "        0.0029748 , 0.00404029, 0.00665059, 0.01104803, 0.01546497,\n",
              "        0.00311265, 0.00421658, 0.00614305, 0.01137605, 0.01662049,\n",
              "        0.00309858, 0.00378618, 0.00643868, 0.01112571, 0.01600709,\n",
              "        0.00298324, 0.00431557, 0.00693092, 0.01147766, 0.01657863,\n",
              "        0.00333099, 0.00401926, 0.00685225, 0.01117148, 0.01553159,\n",
              "        0.00358195, 0.00410624, 0.00707154, 0.01113682, 0.01579261,\n",
              "        0.00330772, 0.00363913, 0.00657268, 0.01293068, 0.0153934 ,\n",
              "        0.00293288, 0.00397902, 0.00658736, 0.01169505, 0.01681094,\n",
              "        0.00317688, 0.00403485, 0.00625067, 0.0107254 , 0.01576805,\n",
              "        0.00326629, 0.00399394, 0.0062335 , 0.01092448, 0.01583924,\n",
              "        0.00339823, 0.00380125, 0.00654216, 0.01139193, 0.01562095,\n",
              "        0.00319529, 0.0041913 , 0.00668187, 0.01121573, 0.01563506,\n",
              "        0.00339651, 0.00435143, 0.00734816, 0.01131773, 0.01609321,\n",
              "        0.00292583, 0.00380139, 0.00658097, 0.0117732 , 0.01570239,\n",
              "        0.00356731, 0.00433049, 0.00659256, 0.01087914, 0.01586761,\n",
              "        0.00334282, 0.00388212, 0.00664845, 0.01139827, 0.01546903,\n",
              "        0.00328598, 0.00401573, 0.00657158, 0.01095624, 0.01562042,\n",
              "        0.0031538 , 0.00389075, 0.00635409, 0.01103606, 0.0159059 ,\n",
              "        0.00310469, 0.00408168, 0.00708013, 0.01113091, 0.01648426,\n",
              "        0.0030262 , 0.00457277, 0.00887537, 0.01443243, 0.01611042,\n",
              "        0.00318484, 0.00422559, 0.00772204, 0.01115289, 0.01748815,\n",
              "        0.00339584, 0.0039928 , 0.00719867, 0.01270437, 0.01695623,\n",
              "        0.003303  , 0.00433578, 0.00703707, 0.01225796, 0.01778178,\n",
              "        0.00312791, 0.00406437, 0.0070755 , 0.01154065, 0.01575575,\n",
              "        0.00363321, 0.00372162, 0.00711789, 0.01173453, 0.01566577,\n",
              "        0.00370526, 0.00412893, 0.00686884, 0.01166062, 0.01710153,\n",
              "        0.0033566 , 0.00405726, 0.00668035, 0.0116128 , 0.01615467,\n",
              "        0.00337915, 0.0046895 , 0.00619631, 0.01129332, 0.01573162,\n",
              "        0.00293193, 0.00398841, 0.00663037, 0.01123204, 0.01612258,\n",
              "        0.00322089, 0.00430017, 0.00826521, 0.01146536, 0.01543503,\n",
              "        0.00303555, 0.00501909, 0.00649118, 0.01078091, 0.01595178,\n",
              "        0.00302978, 0.00363483, 0.0065886 , 0.01078725, 0.01554642,\n",
              "        0.0031796 , 0.00425849, 0.00678587, 0.01093016, 0.01574645,\n",
              "        0.00328603, 0.00431223, 0.00645518, 0.01162806, 0.01587477,\n",
              "        0.00357056, 0.00412254, 0.00671268, 0.01107287, 0.01583023,\n",
              "        0.00332775, 0.00403891, 0.00855522, 0.01102815, 0.01585956,\n",
              "        0.00283566, 0.00407257, 0.00680246, 0.0117682 , 0.01560793,\n",
              "        0.00300393, 0.00396161, 0.00683064, 0.01149201, 0.01568608,\n",
              "        0.00284867, 0.0041503 , 0.00716352, 0.01209564, 0.01558833,\n",
              "        0.00281229, 0.00415592, 0.00685501, 0.01113434, 0.01631641,\n",
              "        0.00352917, 0.00387878, 0.00667377, 0.01172047, 0.01601863,\n",
              "        0.00351486, 0.00422893, 0.00711951, 0.01145816, 0.0169775 ,\n",
              "        0.00295448, 0.00433311, 0.0068717 , 0.01058021, 0.0155282 ,\n",
              "        0.00320497, 0.00435777, 0.00691257, 0.0124548 , 0.01562133,\n",
              "        0.00359735, 0.00414348, 0.00637603, 0.01103334, 0.01585555,\n",
              "        0.00287576, 0.00430818, 0.00674214, 0.01120491, 0.01726627,\n",
              "        0.00325942, 0.00419512, 0.00845971, 0.01273141, 0.01971788,\n",
              "        0.00329423, 0.00431523, 0.00725398, 0.01196866, 0.01821408,\n",
              "        0.00552044, 0.00619841, 0.01325479, 0.01702561, 0.02098341,\n",
              "        0.00546274, 0.0096952 , 0.01054859, 0.02295947, 0.03056931,\n",
              "        0.00587745, 0.00490189, 0.00787773, 0.01457148, 0.01648598,\n",
              "        0.00331521, 0.00482349, 0.00708189, 0.01144228, 0.01657829,\n",
              "        0.00296898, 0.00402799, 0.00744939, 0.01121035, 0.01578789,\n",
              "        0.00307617, 0.00411425, 0.00680351, 0.01130605, 0.01538496,\n",
              "        0.00309916, 0.00424147, 0.0065701 , 0.01081171, 0.01570029,\n",
              "        0.00394173, 0.00437121, 0.00730405, 0.01182117, 0.01787143,\n",
              "        0.00353527, 0.00404401, 0.00671153, 0.0114718 , 0.01552558,\n",
              "        0.00331569, 0.00408797, 0.00714579, 0.01131721, 0.01546578,\n",
              "        0.00315571, 0.00395861, 0.00718946, 0.01082463, 0.01566606,\n",
              "        0.00292716, 0.00389061, 0.00662856, 0.01397138, 0.01561546,\n",
              "        0.00350261, 0.00442858, 0.00686388, 0.01074705, 0.01817598,\n",
              "        0.00317926, 0.00466628, 0.00822973, 0.01100903, 0.01777873,\n",
              "        0.00356216, 0.00445552, 0.0071352 , 0.01154923, 0.01645041,\n",
              "        0.00321589, 0.0039722 , 0.00924792, 0.01459737, 0.01646128,\n",
              "        0.00355902, 0.00404353, 0.00715284, 0.01101937, 0.01682491,\n",
              "        0.00372782, 0.00421648, 0.00696139, 0.01096025, 0.01615   ,\n",
              "        0.00309086, 0.00461664, 0.00686545, 0.01142063, 0.01609426,\n",
              "        0.00300269, 0.00381012, 0.00695171, 0.01148815, 0.01523709,\n",
              "        0.00326743, 0.00461903, 0.00674849, 0.01130538, 0.01745667,\n",
              "        0.00333509, 0.00403223, 0.00665393, 0.01101089, 0.01558905,\n",
              "        0.00296574, 0.00404673, 0.00682826, 0.01089582, 0.01569843,\n",
              "        0.0034245 , 0.00401707, 0.00720162, 0.01157231, 0.01599078,\n",
              "        0.00335588, 0.00419016, 0.00654206, 0.01155524, 0.01575146,\n",
              "        0.00319562, 0.00401063, 0.00657578, 0.0119874 , 0.01572013,\n",
              "        0.00344939, 0.00399785, 0.00635195, 0.01118369, 0.01519933,\n",
              "        0.00297313, 0.00394316, 0.00708098, 0.01319022, 0.01638136,\n",
              "        0.0030489 , 0.00402975, 0.00685587, 0.01162744, 0.01528749,\n",
              "        0.00328655, 0.00400701, 0.007061  , 0.01097956, 0.01551147,\n",
              "        0.00342855, 0.00371428, 0.00714674, 0.01134772, 0.01542706,\n",
              "        0.00311661, 0.00435929, 0.00640707, 0.01108251, 0.01566281,\n",
              "        0.0031589 , 0.00424604, 0.00673122, 0.01142969, 0.01685996,\n",
              "        0.00362148, 0.00431781, 0.00717063, 0.01068754, 0.01586761,\n",
              "        0.0034482 , 0.00433502, 0.00684195, 0.01118188, 0.01597743,\n",
              "        0.00325274, 0.00388074, 0.0069088 , 0.01187043, 0.01621466,\n",
              "        0.00327191, 0.00420871, 0.00683846, 0.01158738, 0.01701365,\n",
              "        0.00297213, 0.004387  , 0.00677137, 0.01122031, 0.01523118,\n",
              "        0.00330815, 0.00413041, 0.00698714, 0.01134696, 0.016541  ,\n",
              "        0.0033124 , 0.00480537, 0.00668068, 0.01194158, 0.01603484,\n",
              "        0.00310545, 0.00405912, 0.0063107 , 0.01116376, 0.01577702,\n",
              "        0.00337019, 0.00427022, 0.00649676, 0.01178389, 0.01585169,\n",
              "        0.00317249, 0.0040895 , 0.00694895, 0.01093798, 0.01530123,\n",
              "        0.00341759, 0.00416045, 0.00699368, 0.01055236, 0.0149724 ,\n",
              "        0.00286751, 0.0042058 , 0.00681858, 0.01080518, 0.01665068,\n",
              "        0.00356236, 0.00430937, 0.00804405, 0.01072416, 0.01514153,\n",
              "        0.00316038, 0.00388451, 0.00628529, 0.01238513, 0.01536465,\n",
              "        0.00325928, 0.00370445, 0.00611143, 0.01107268, 0.01593213,\n",
              "        0.00306544, 0.00382366, 0.00634232, 0.01069655, 0.0157362 ,\n",
              "        0.00278125, 0.00408053, 0.0063498 , 0.01094332, 0.01522522,\n",
              "        0.00309796, 0.00428443, 0.00669532, 0.01133547, 0.01615663,\n",
              "        0.00314064, 0.0039115 , 0.00794563, 0.01148634, 0.01632762,\n",
              "        0.00302644, 0.0038456 , 0.00661044, 0.01163807, 0.01540213,\n",
              "        0.00314221, 0.00393667, 0.00654907, 0.01143041, 0.0160203 ,\n",
              "        0.00326004, 0.00372643, 0.00672255, 0.01241241, 0.01596885,\n",
              "        0.00415039, 0.00390372, 0.00656924, 0.01181607, 0.0159584 ,\n",
              "        0.00324659, 0.0040575 , 0.00659266, 0.01159596, 0.01640706,\n",
              "        0.00334268, 0.00428181, 0.00694861, 0.01250877, 0.01534476,\n",
              "        0.00318699, 0.00387912, 0.00630121, 0.01120849, 0.01530414,\n",
              "        0.00287924, 0.00445457, 0.00673971, 0.01194906, 0.01541691,\n",
              "        0.00307441, 0.00370603, 0.00663896, 0.0121645 , 0.01585922,\n",
              "        0.0030313 , 0.00384665, 0.00676699, 0.0112833 , 0.01594667,\n",
              "        0.00296988, 0.00404663, 0.00702167, 0.01178546, 0.0152276 ,\n",
              "        0.00296793, 0.00405169, 0.0066853 , 0.01080484, 0.01556854,\n",
              "        0.00331545, 0.00420227, 0.0064899 , 0.01120462, 0.01595302,\n",
              "        0.00299821, 0.00394797, 0.006393  , 0.01082544, 0.01553435]),\n",
              " 'std_score_time': array([5.01493926e-04, 5.37658680e-04, 5.53321674e-04, 1.43990263e-03,\n",
              "        5.04720016e-04, 2.32881381e-04, 2.00584179e-04, 4.37803996e-04,\n",
              "        5.15768051e-04, 1.21623332e-03, 4.47755662e-04, 3.09413544e-04,\n",
              "        9.84299366e-04, 1.16286407e-03, 8.26102590e-04, 3.23924982e-04,\n",
              "        7.52186397e-04, 1.02911066e-03, 9.17558533e-04, 8.52866833e-04,\n",
              "        1.02676983e-03, 9.73769981e-04, 7.80900166e-04, 1.80191046e-03,\n",
              "        1.74825890e-03, 6.47308857e-05, 1.27949813e-04, 1.37989856e-03,\n",
              "        5.70675364e-04, 2.62323979e-04, 4.41695148e-04, 5.35603088e-04,\n",
              "        4.45967076e-04, 6.03173003e-04, 5.33310491e-04, 1.84014011e-04,\n",
              "        2.47122052e-04, 6.72642322e-05, 4.09396772e-04, 6.61674323e-04,\n",
              "        1.92154288e-04, 2.93946714e-04, 5.52959280e-04, 2.17425491e-03,\n",
              "        9.19206197e-04, 4.62832565e-04, 4.20927525e-04, 7.13740164e-04,\n",
              "        5.74275778e-04, 9.27907043e-04, 5.10338996e-04, 1.75559825e-04,\n",
              "        3.77430530e-04, 4.90975616e-04, 8.99982478e-04, 1.75355294e-04,\n",
              "        5.85715380e-04, 4.71463716e-04, 5.40176855e-04, 1.19801377e-03,\n",
              "        3.20049818e-04, 7.48460142e-04, 7.09764356e-04, 9.75923376e-04,\n",
              "        1.64910641e-04, 7.83738364e-04, 3.71603318e-04, 6.59694342e-04,\n",
              "        1.03842267e-03, 3.55174756e-04, 2.45050619e-04, 5.33866197e-04,\n",
              "        5.91141212e-04, 4.05829138e-04, 7.82247156e-04, 4.51012806e-04,\n",
              "        7.19058428e-04, 2.13731713e-04, 1.09224189e-03, 1.81684218e-03,\n",
              "        5.86475833e-04, 1.17034102e-04, 1.70860236e-04, 3.17394311e-04,\n",
              "        1.15547234e-03, 2.79493234e-04, 5.05622379e-04, 5.00324773e-04,\n",
              "        1.47899002e-03, 1.75450288e-03, 3.17855959e-04, 3.83724315e-04,\n",
              "        5.78986147e-04, 9.22662572e-04, 7.50513685e-04, 9.17006696e-04,\n",
              "        3.99087019e-04, 9.93337795e-04, 7.36610927e-04, 1.66141967e-03,\n",
              "        4.69516555e-04, 4.99395815e-05, 8.10309145e-04, 1.74892773e-03,\n",
              "        1.04045600e-03, 1.26602250e-04, 3.23254145e-04, 4.02370260e-04,\n",
              "        2.29700809e-04, 2.04730721e-03, 5.25444656e-04, 5.44452838e-04,\n",
              "        2.06086703e-04, 4.56807051e-04, 8.07259805e-04, 4.52322169e-04,\n",
              "        3.58807950e-04, 1.77393575e-04, 4.76084726e-04, 2.32450979e-04,\n",
              "        4.42960069e-04, 2.86866265e-04, 4.47540198e-04, 6.31197280e-04,\n",
              "        6.70401402e-04, 3.70611233e-04, 5.62981029e-04, 6.81817302e-04,\n",
              "        9.65337806e-04, 1.10651233e-03, 4.09474147e-04, 5.19177123e-04,\n",
              "        7.75955125e-04, 1.27991584e-03, 1.33825330e-03, 2.14385976e-04,\n",
              "        3.02437831e-04, 6.98592631e-04, 1.19697736e-03, 1.04228263e-03,\n",
              "        7.48574847e-04, 1.03910542e-03, 5.23693937e-04, 1.29911540e-03,\n",
              "        7.36675826e-04, 6.74388542e-04, 4.89505973e-04, 4.09974750e-04,\n",
              "        1.52855762e-03, 6.95590581e-04, 5.52893427e-04, 5.83930302e-04,\n",
              "        3.42185548e-04, 7.23844184e-04, 1.01447772e-03, 2.73841191e-04,\n",
              "        4.19012605e-04, 1.81171767e-04, 6.25009703e-04, 1.03502534e-03,\n",
              "        2.69096619e-04, 3.43119455e-04, 5.27880129e-04, 4.02407158e-04,\n",
              "        6.66427977e-04, 2.11615496e-04, 5.40722733e-04, 2.67485802e-03,\n",
              "        3.25454883e-03, 1.31510420e-03, 4.61357962e-04, 6.48582933e-04,\n",
              "        1.69091514e-03, 9.28118821e-04, 2.72199468e-03, 6.28076384e-04,\n",
              "        4.20383165e-04, 1.18910566e-03, 1.96214937e-03, 1.72620778e-03,\n",
              "        3.40979694e-04, 1.06535050e-03, 6.64563751e-04, 6.37838504e-04,\n",
              "        2.38898227e-03, 2.34771713e-04, 2.85683301e-04, 4.49337911e-04,\n",
              "        3.85707974e-04, 4.90555844e-04, 7.55008625e-04, 1.51721506e-04,\n",
              "        9.21221853e-04, 6.94244418e-04, 5.77433832e-04, 9.73756176e-04,\n",
              "        4.91807404e-04, 5.64610292e-04, 1.08305166e-03, 2.30860651e-03,\n",
              "        6.22688217e-04, 2.47128447e-04, 3.97869067e-04, 5.95055168e-04,\n",
              "        8.37064055e-04, 7.85265147e-04, 7.97248961e-04, 3.38990958e-04,\n",
              "        1.13472531e-03, 8.38585007e-04, 2.74424097e-04, 7.67966940e-04,\n",
              "        6.96466750e-04, 1.34369177e-03, 1.87334439e-03, 6.39161082e-04,\n",
              "        7.76806038e-04, 1.86690313e-03, 1.21791586e-03, 2.91855560e-04,\n",
              "        3.13918782e-04, 1.27763053e-03, 4.51186232e-04, 3.93172568e-04,\n",
              "        1.36938202e-03, 2.68091124e-04, 7.49761195e-05, 4.17795689e-04,\n",
              "        2.66129948e-04, 4.99802949e-04, 4.43222727e-04, 7.82540780e-04,\n",
              "        5.32072371e-04, 4.97391320e-04, 7.25186573e-04, 5.61742883e-04,\n",
              "        5.94880516e-04, 4.09053221e-04, 1.48298906e-03, 1.95035002e-04,\n",
              "        5.95412757e-04, 5.26160136e-04, 5.75864788e-04, 8.83580193e-04,\n",
              "        9.16192593e-04, 4.17360085e-04, 4.73371418e-04, 2.27576976e-03,\n",
              "        6.66902847e-04, 1.03235299e-03, 2.88829521e-05, 3.52796555e-04,\n",
              "        6.65022043e-04, 9.66454213e-04, 3.82379300e-04, 4.87788252e-04,\n",
              "        2.62114892e-04, 3.54429034e-04, 5.01486309e-04, 6.58441318e-04,\n",
              "        1.00607940e-04, 3.43835058e-04, 4.43093678e-04, 7.69879920e-04,\n",
              "        4.18632268e-04, 4.36915561e-05, 6.08531118e-04, 3.86731427e-04,\n",
              "        2.86696429e-04, 9.60045312e-04, 6.04313259e-04, 1.66343903e-04,\n",
              "        3.00908027e-04, 6.51188653e-04, 9.72097778e-04, 8.01753104e-04,\n",
              "        4.26368968e-04, 7.43763693e-04, 5.47637792e-04, 2.62096240e-03,\n",
              "        1.39140478e-04, 4.88358767e-04, 7.69897738e-04, 1.68612653e-04,\n",
              "        1.13489324e-03, 7.22924096e-04, 1.07760585e-03, 8.62929487e-04,\n",
              "        1.38212962e-03, 1.03939080e-03, 8.69149868e-04, 8.62817765e-04,\n",
              "        2.94024960e-04, 5.69672214e-04, 6.95447943e-04, 7.02862500e-05,\n",
              "        5.29889879e-04, 4.95009603e-04, 6.39051876e-04, 5.76375699e-04,\n",
              "        4.06779855e-04, 2.80483691e-04, 9.70387044e-04, 2.58337783e-03,\n",
              "        3.42514084e-03, 4.15609391e-04, 4.75810868e-04, 1.61401748e-03,\n",
              "        1.31420685e-03, 2.26457728e-03, 1.83422674e-03, 1.65757148e-03,\n",
              "        3.52026305e-03, 5.98741464e-03, 7.92609215e-03, 7.55575382e-04,\n",
              "        1.62026893e-03, 2.41712967e-03, 1.93430574e-03, 4.51337824e-03,\n",
              "        1.43073350e-03, 1.08509451e-03, 7.66822316e-04, 3.95436719e-03,\n",
              "        6.46227661e-04, 5.12854469e-04, 1.25349479e-03, 1.31296174e-03,\n",
              "        9.78933012e-04, 6.58968778e-04, 2.34334654e-04, 4.22212596e-04,\n",
              "        5.92959670e-04, 5.72779339e-04, 4.62226186e-04, 5.57705744e-04,\n",
              "        7.24322402e-04, 7.96230434e-04, 8.85216341e-04, 6.21763061e-04,\n",
              "        3.14054285e-04, 6.41129290e-04, 5.02448248e-04, 6.62616913e-04,\n",
              "        1.17797610e-03, 1.11138684e-03, 1.20781098e-03, 1.71307564e-03,\n",
              "        1.36345705e-03, 3.73624924e-03, 7.44182140e-04, 4.21582526e-04,\n",
              "        4.20741649e-04, 3.60812170e-04, 4.20546612e-04, 6.47289590e-04,\n",
              "        5.18879363e-04, 3.19690692e-04, 6.72852805e-04, 5.38186973e-04,\n",
              "        2.48978685e-04, 3.72219238e-04, 1.42170244e-03, 8.67624077e-04,\n",
              "        4.99535012e-04, 1.33361951e-04, 3.19152870e-04, 7.13201265e-04,\n",
              "        3.53567352e-03, 5.94726455e-04, 7.91766298e-04, 4.34080645e-04,\n",
              "        6.03198240e-04, 7.63066514e-04, 1.28088551e-03, 3.12274295e-04,\n",
              "        7.88315901e-04, 1.71212853e-03, 4.32344951e-04, 3.33214889e-03,\n",
              "        6.15400805e-04, 1.54529629e-03, 9.46525319e-04, 7.24736136e-04,\n",
              "        1.71082886e-03, 2.89787935e-04, 4.17032783e-04, 1.80388206e-03,\n",
              "        3.62264593e-03, 1.15374411e-03, 7.69957991e-04, 5.30465199e-04,\n",
              "        6.40648342e-04, 4.70734686e-04, 3.10113245e-03, 2.68134934e-04,\n",
              "        6.43283537e-04, 1.38089621e-03, 4.35388377e-04, 8.98821234e-04,\n",
              "        2.50447886e-04, 5.78913845e-04, 5.32061931e-04, 6.29498748e-04,\n",
              "        1.03919059e-03, 5.47988183e-05, 1.70611336e-04, 6.60645374e-04,\n",
              "        1.12529329e-03, 4.54120819e-04, 5.78015595e-04, 1.39348016e-03,\n",
              "        9.17307734e-04, 8.17364075e-04, 1.32657853e-03, 4.72356959e-04,\n",
              "        4.12582992e-04, 4.02470041e-04, 4.54465913e-04, 5.88520206e-04,\n",
              "        1.24044804e-04, 5.01478860e-04, 5.85338683e-04, 6.07088493e-04,\n",
              "        5.90178964e-04, 2.17977156e-04, 3.99258244e-04, 3.61895510e-04,\n",
              "        8.14004332e-04, 7.85252406e-04, 3.64895491e-04, 3.64921966e-04,\n",
              "        3.41332635e-04, 7.20274822e-04, 6.88988156e-04, 2.27624679e-04,\n",
              "        3.20186384e-04, 3.34314555e-04, 1.17923224e-03, 1.24164862e-03,\n",
              "        7.68485910e-04, 1.20524815e-04, 3.04110949e-04, 4.18305065e-04,\n",
              "        9.97677631e-04, 2.46197975e-04, 4.01389568e-04, 1.62427137e-03,\n",
              "        8.01222758e-04, 1.19756931e-03, 3.25088502e-04, 5.02895558e-04,\n",
              "        2.51510633e-04, 3.16426925e-04, 2.29381453e-04, 3.84964356e-04,\n",
              "        5.35308586e-04, 6.94890031e-04, 4.57217308e-04, 2.62587491e-04,\n",
              "        4.75612106e-04, 1.96355636e-04, 6.08361857e-04, 1.09892334e-03,\n",
              "        1.09424079e-03, 4.04619383e-04, 8.67781970e-04, 3.73940898e-04,\n",
              "        7.16972256e-04, 1.60562275e-03, 6.42100029e-04, 5.05517635e-04,\n",
              "        7.74336570e-04, 1.62513957e-03, 1.08765712e-03, 1.08020390e-03,\n",
              "        6.45857288e-04, 1.19693335e-03, 8.61527235e-04, 1.58186069e-03,\n",
              "        9.51256230e-04, 9.46892510e-04, 1.01999755e-03, 7.46464461e-04,\n",
              "        6.49468338e-04, 2.75758396e-04, 2.87938307e-04, 5.90450350e-04,\n",
              "        5.61250166e-04, 7.53265854e-04, 2.80347023e-04, 3.70377645e-04,\n",
              "        6.52018464e-04, 1.15782660e-03, 2.82840638e-03, 3.35746220e-04,\n",
              "        6.04825308e-04, 5.61355831e-04, 5.89423378e-04, 2.95536823e-04,\n",
              "        7.21049346e-04, 2.68952871e-04, 8.72970875e-04, 8.06822712e-04,\n",
              "        1.72345291e-03, 3.99437337e-04, 1.57972488e-03, 2.63968601e-04,\n",
              "        2.24760014e-03, 1.35888026e-03, 5.25306664e-04, 4.19188205e-04,\n",
              "        3.13633130e-04, 1.08958183e-03, 1.33764852e-03, 3.99155130e-04,\n",
              "        7.03364591e-04, 4.55341103e-04, 3.36206292e-04, 1.68273817e-03,\n",
              "        5.33469221e-04, 6.38345193e-04, 7.19080933e-04, 4.79576430e-04,\n",
              "        2.13630870e-04, 5.76388611e-04, 5.75210630e-04, 6.55005234e-04,\n",
              "        5.87696592e-04, 7.64601453e-04, 1.61570725e-04, 5.87245638e-04,\n",
              "        4.79793762e-04, 3.29719548e-04, 1.44989835e-03, 4.05243043e-04,\n",
              "        5.77582113e-04, 2.52123595e-03, 4.38354239e-04, 4.87656664e-04,\n",
              "        3.43031018e-04, 3.87779721e-04, 4.92067637e-04, 1.50786352e-03,\n",
              "        1.16970720e-03, 7.25588183e-04, 2.51118791e-04, 2.92240474e-04,\n",
              "        4.66866374e-04, 1.12181261e-03, 2.33237944e-04, 3.87847854e-04,\n",
              "        4.30217367e-04, 3.99414117e-04, 9.63209627e-04, 4.77398542e-05,\n",
              "        5.90136487e-04, 4.17065396e-04, 3.77236379e-04, 7.07954484e-04,\n",
              "        2.58166851e-04, 5.53994459e-04, 3.08445771e-04, 6.22441072e-04,\n",
              "        7.21424985e-04, 5.00577449e-04, 3.35921744e-04, 1.89959057e-03,\n",
              "        3.61479786e-04, 1.79547180e-03, 2.10978776e-04, 3.28049777e-04,\n",
              "        3.25068267e-04, 1.25749567e-03, 1.26407958e-03, 5.09977566e-04,\n",
              "        5.20923734e-04, 5.39987700e-04, 1.00012370e-03, 1.02829485e-03,\n",
              "        4.31563619e-04, 9.30448964e-05, 4.98720074e-04, 9.04971435e-04,\n",
              "        1.07505063e-03, 8.24501376e-04, 3.57251020e-04, 6.51819244e-04,\n",
              "        1.17508458e-03, 6.62178331e-04, 7.73562803e-04, 2.55009846e-04,\n",
              "        4.24728833e-04, 5.57997076e-04, 1.00986836e-03, 4.33369337e-04,\n",
              "        3.64632433e-04, 3.14153789e-04, 1.37145069e-03, 8.68082978e-04,\n",
              "        4.16176369e-04, 2.91385172e-04, 3.34403638e-04, 6.60664145e-04,\n",
              "        8.35008749e-04, 5.32859070e-05, 1.02639340e-03, 5.54642188e-04,\n",
              "        1.27468169e-03, 1.28583049e-03, 3.06985044e-04, 1.47461874e-04,\n",
              "        1.00387785e-03, 3.80728293e-03, 8.93300789e-04, 3.23041405e-04,\n",
              "        4.46114483e-04, 4.17069905e-04, 5.62235872e-04, 4.36341055e-04,\n",
              "        2.19206797e-04, 3.50997315e-04, 6.78123432e-04, 1.42339188e-03,\n",
              "        6.10218078e-04, 2.18100938e-04, 4.97597361e-04, 5.87326474e-04,\n",
              "        5.02813227e-04, 1.58945112e-03, 5.97571843e-04, 5.90979201e-04,\n",
              "        6.45214799e-04, 1.05306695e-03, 6.69848535e-04, 3.39088308e-04,\n",
              "        3.57478269e-04, 4.54159080e-04, 6.21652082e-04, 3.52580676e-04]),\n",
              " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_max_depth': masked_array(data=[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20,\n",
              "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
              "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
              "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
              "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
              "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
              "                    20, 20, 20, 20, 20, 20, 50, 50, 50, 50, 50, 50, 50, 50,\n",
              "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
              "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
              "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
              "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
              "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
              "                    50, 50, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
              "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
              "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
              "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
              "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
              "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 50,\n",
              "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
              "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
              "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
              "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
              "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
              "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_min_samples_leaf': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15,\n",
              "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
              "                    15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15, 15, 15, 15,\n",
              "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
              "                    15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15, 15, 15,\n",
              "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
              "                    15, 15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15, 15,\n",
              "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
              "                    15, 15, 15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15,\n",
              "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
              "                    15, 15, 15, 15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
              "                    15, 15, 15, 15, 15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
              "                    15, 15, 15, 15, 15, 15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
              "                    15, 15, 15, 15, 15, 15, 15, 15],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_min_samples_split': masked_array(data=[2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15,\n",
              "                    15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10,\n",
              "                    10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5,\n",
              "                    5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2,\n",
              "                    2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15,\n",
              "                    15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
              "                    10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
              "                    10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2,\n",
              "                    5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15,\n",
              "                    2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15,\n",
              "                    15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10,\n",
              "                    10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5,\n",
              "                    5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2,\n",
              "                    2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15,\n",
              "                    15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
              "                    10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
              "                    10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2,\n",
              "                    5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15,\n",
              "                    2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15,\n",
              "                    15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10,\n",
              "                    10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5,\n",
              "                    5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2,\n",
              "                    2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15,\n",
              "                    15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
              "                    10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
              "                    10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2,\n",
              "                    5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15,\n",
              "                    2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15,\n",
              "                    15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10,\n",
              "                    10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5,\n",
              "                    5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2,\n",
              "                    2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15,\n",
              "                    15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
              "                    10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
              "                    10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2,\n",
              "                    5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15,\n",
              "                    2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15,\n",
              "                    15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10,\n",
              "                    10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5,\n",
              "                    5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2,\n",
              "                    2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15,\n",
              "                    15, 15],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_n_estimators': masked_array(data=[10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150}],\n",
              " 'split0_test_score': array([0.59375   , 0.63541667, 0.625     , 0.65625   , 0.59375   ,\n",
              "        0.63541667, 0.64583333, 0.66666667, 0.61458333, 0.63541667,\n",
              "        0.625     , 0.64583333, 0.65625   , 0.66666667, 0.66666667,\n",
              "        0.65625   , 0.63541667, 0.6875    , 0.64583333, 0.64583333,\n",
              "        0.65625   , 0.66666667, 0.67708333, 0.63541667, 0.65625   ,\n",
              "        0.59375   , 0.65625   , 0.65625   , 0.61458333, 0.61458333,\n",
              "        0.66666667, 0.64583333, 0.66666667, 0.67708333, 0.65625   ,\n",
              "        0.70833333, 0.61458333, 0.69791667, 0.60416667, 0.60416667,\n",
              "        0.5625    , 0.63541667, 0.60416667, 0.64583333, 0.63541667,\n",
              "        0.63541667, 0.59375   , 0.63541667, 0.67708333, 0.61458333,\n",
              "        0.6875    , 0.625     , 0.66666667, 0.61458333, 0.58333333,\n",
              "        0.63541667, 0.625     , 0.65625   , 0.66666667, 0.625     ,\n",
              "        0.58333333, 0.66666667, 0.63541667, 0.60416667, 0.625     ,\n",
              "        0.65625   , 0.70833333, 0.69791667, 0.64583333, 0.63541667,\n",
              "        0.57291667, 0.59375   , 0.625     , 0.59375   , 0.64583333,\n",
              "        0.59375   , 0.67708333, 0.59375   , 0.63541667, 0.61458333,\n",
              "        0.59375   , 0.72916667, 0.65625   , 0.625     , 0.67708333,\n",
              "        0.64583333, 0.6875    , 0.625     , 0.66666667, 0.60416667,\n",
              "        0.64583333, 0.64583333, 0.66666667, 0.6875    , 0.63541667,\n",
              "        0.60416667, 0.66666667, 0.66666667, 0.64583333, 0.64583333,\n",
              "        0.61458333, 0.66666667, 0.625     , 0.64583333, 0.65625   ,\n",
              "        0.61458333, 0.61458333, 0.63541667, 0.69791667, 0.66666667,\n",
              "        0.65625   , 0.64583333, 0.65625   , 0.63541667, 0.66666667,\n",
              "        0.59375   , 0.64583333, 0.67708333, 0.66666667, 0.61458333,\n",
              "        0.67708333, 0.63541667, 0.61458333, 0.60416667, 0.61458333,\n",
              "        0.67708333, 0.6875    , 0.625     , 0.61458333, 0.65625   ,\n",
              "        0.70833333, 0.58333333, 0.66666667, 0.61458333, 0.625     ,\n",
              "        0.59375   , 0.64583333, 0.65625   , 0.61458333, 0.59375   ,\n",
              "        0.54166667, 0.60416667, 0.66666667, 0.63541667, 0.61458333,\n",
              "        0.67708333, 0.65625   , 0.59375   , 0.63541667, 0.63541667,\n",
              "        0.65625   , 0.63541667, 0.65625   , 0.63541667, 0.63541667,\n",
              "        0.61458333, 0.6875    , 0.57291667, 0.625     , 0.64583333,\n",
              "        0.69791667, 0.66666667, 0.63541667, 0.61458333, 0.625     ,\n",
              "        0.64583333, 0.64583333, 0.63541667, 0.67708333, 0.63541667,\n",
              "        0.71875   , 0.67708333, 0.64583333, 0.66666667, 0.625     ,\n",
              "        0.67708333, 0.6875    , 0.625     , 0.63541667, 0.66666667,\n",
              "        0.63541667, 0.67708333, 0.59375   , 0.63541667, 0.63541667,\n",
              "        0.59375   , 0.65625   , 0.64583333, 0.65625   , 0.625     ,\n",
              "        0.625     , 0.69791667, 0.61458333, 0.61458333, 0.64583333,\n",
              "        0.64583333, 0.63541667, 0.64583333, 0.65625   , 0.61458333,\n",
              "        0.53125   , 0.63541667, 0.60416667, 0.61458333, 0.61458333,\n",
              "        0.63541667, 0.65625   , 0.67708333, 0.60416667, 0.65625   ,\n",
              "        0.63541667, 0.65625   , 0.625     , 0.625     , 0.63541667,\n",
              "        0.61458333, 0.59375   , 0.63541667, 0.65625   , 0.625     ,\n",
              "        0.61458333, 0.64583333, 0.63541667, 0.63541667, 0.625     ,\n",
              "        0.55208333, 0.625     , 0.63541667, 0.625     , 0.61458333,\n",
              "        0.625     , 0.64583333, 0.65625   , 0.61458333, 0.63541667,\n",
              "        0.64583333, 0.57291667, 0.63541667, 0.625     , 0.625     ,\n",
              "        0.63541667, 0.64583333, 0.63541667, 0.625     , 0.64583333,\n",
              "        0.55208333, 0.64583333, 0.64583333, 0.63541667, 0.65625   ,\n",
              "        0.625     , 0.64583333, 0.64583333, 0.625     , 0.63541667,\n",
              "        0.59375   , 0.625     , 0.625     , 0.67708333, 0.64583333,\n",
              "        0.625     , 0.63541667, 0.61458333, 0.63541667, 0.63541667,\n",
              "        0.60416667, 0.66666667, 0.64583333, 0.625     , 0.625     ,\n",
              "        0.59375   , 0.60416667, 0.66666667, 0.61458333, 0.64583333,\n",
              "        0.60416667, 0.69791667, 0.61458333, 0.64583333, 0.65625   ,\n",
              "        0.63541667, 0.625     , 0.63541667, 0.64583333, 0.66666667,\n",
              "        0.70833333, 0.6875    , 0.64583333, 0.67708333, 0.65625   ,\n",
              "        0.70833333, 0.63541667, 0.64583333, 0.61458333, 0.63541667,\n",
              "        0.71875   , 0.66666667, 0.65625   , 0.65625   , 0.66666667,\n",
              "        0.69791667, 0.60416667, 0.61458333, 0.66666667, 0.60416667,\n",
              "        0.5625    , 0.60416667, 0.60416667, 0.625     , 0.625     ,\n",
              "        0.58333333, 0.64583333, 0.61458333, 0.59375   , 0.625     ,\n",
              "        0.75      , 0.5625    , 0.58333333, 0.64583333, 0.61458333,\n",
              "        0.625     , 0.58333333, 0.58333333, 0.61458333, 0.64583333,\n",
              "        0.63541667, 0.64583333, 0.64583333, 0.625     , 0.65625   ,\n",
              "        0.66666667, 0.69791667, 0.60416667, 0.66666667, 0.65625   ,\n",
              "        0.66666667, 0.64583333, 0.66666667, 0.66666667, 0.64583333,\n",
              "        0.64583333, 0.67708333, 0.65625   , 0.65625   , 0.625     ,\n",
              "        0.66666667, 0.66666667, 0.63541667, 0.63541667, 0.67708333,\n",
              "        0.64583333, 0.6875    , 0.61458333, 0.6875    , 0.625     ,\n",
              "        0.61458333, 0.6875    , 0.65625   , 0.61458333, 0.6875    ,\n",
              "        0.625     , 0.61458333, 0.65625   , 0.65625   , 0.63541667,\n",
              "        0.66666667, 0.6875    , 0.70833333, 0.59375   , 0.625     ,\n",
              "        0.625     , 0.66666667, 0.69791667, 0.61458333, 0.63541667,\n",
              "        0.65625   , 0.65625   , 0.625     , 0.625     , 0.64583333,\n",
              "        0.59375   , 0.6875    , 0.66666667, 0.63541667, 0.625     ,\n",
              "        0.63541667, 0.64583333, 0.70833333, 0.6875    , 0.64583333,\n",
              "        0.6875    , 0.59375   , 0.67708333, 0.66666667, 0.66666667,\n",
              "        0.6875    , 0.63541667, 0.67708333, 0.625     , 0.69791667,\n",
              "        0.53125   , 0.63541667, 0.60416667, 0.63541667, 0.66666667,\n",
              "        0.63541667, 0.66666667, 0.65625   , 0.64583333, 0.61458333,\n",
              "        0.64583333, 0.61458333, 0.61458333, 0.65625   , 0.65625   ,\n",
              "        0.69791667, 0.63541667, 0.65625   , 0.63541667, 0.66666667,\n",
              "        0.65625   , 0.67708333, 0.65625   , 0.65625   , 0.63541667,\n",
              "        0.63541667, 0.625     , 0.66666667, 0.64583333, 0.65625   ,\n",
              "        0.66666667, 0.64583333, 0.60416667, 0.625     , 0.64583333,\n",
              "        0.67708333, 0.6875    , 0.64583333, 0.67708333, 0.64583333,\n",
              "        0.65625   , 0.6875    , 0.61458333, 0.67708333, 0.60416667,\n",
              "        0.65625   , 0.60416667, 0.72916667, 0.61458333, 0.63541667,\n",
              "        0.60416667, 0.64583333, 0.625     , 0.65625   , 0.63541667,\n",
              "        0.6875    , 0.6875    , 0.63541667, 0.64583333, 0.63541667,\n",
              "        0.625     , 0.61458333, 0.67708333, 0.69791667, 0.60416667,\n",
              "        0.66666667, 0.67708333, 0.66666667, 0.67708333, 0.625     ,\n",
              "        0.58333333, 0.61458333, 0.70833333, 0.60416667, 0.61458333,\n",
              "        0.6875    , 0.70833333, 0.67708333, 0.63541667, 0.61458333,\n",
              "        0.60416667, 0.58333333, 0.625     , 0.64583333, 0.65625   ,\n",
              "        0.65625   , 0.67708333, 0.64583333, 0.60416667, 0.625     ,\n",
              "        0.64583333, 0.66666667, 0.66666667, 0.63541667, 0.63541667,\n",
              "        0.625     , 0.6875    , 0.67708333, 0.65625   , 0.64583333,\n",
              "        0.65625   , 0.65625   , 0.64583333, 0.65625   , 0.63541667,\n",
              "        0.70833333, 0.60416667, 0.69791667, 0.64583333, 0.64583333,\n",
              "        0.66666667, 0.63541667, 0.66666667, 0.65625   , 0.63541667,\n",
              "        0.72916667, 0.60416667, 0.67708333, 0.63541667, 0.64583333,\n",
              "        0.5625    , 0.67708333, 0.60416667, 0.625     , 0.625     ,\n",
              "        0.54166667, 0.63541667, 0.65625   , 0.67708333, 0.63541667,\n",
              "        0.63541667, 0.61458333, 0.61458333, 0.60416667, 0.67708333,\n",
              "        0.66666667, 0.67708333, 0.67708333, 0.66666667, 0.65625   ,\n",
              "        0.67708333, 0.6875    , 0.65625   , 0.67708333, 0.60416667,\n",
              "        0.625     , 0.64583333, 0.60416667, 0.59375   , 0.64583333,\n",
              "        0.625     , 0.61458333, 0.66666667, 0.64583333, 0.64583333,\n",
              "        0.67708333, 0.66666667, 0.69791667, 0.64583333, 0.64583333,\n",
              "        0.625     , 0.63541667, 0.67708333, 0.625     , 0.61458333,\n",
              "        0.61458333, 0.625     , 0.65625   , 0.65625   , 0.65625   ,\n",
              "        0.65625   , 0.70833333, 0.63541667, 0.63541667, 0.625     ,\n",
              "        0.625     , 0.65625   , 0.625     , 0.66666667, 0.67708333,\n",
              "        0.69791667, 0.60416667, 0.66666667, 0.65625   , 0.65625   ,\n",
              "        0.64583333, 0.625     , 0.6875    , 0.60416667, 0.66666667,\n",
              "        0.67708333, 0.66666667, 0.625     , 0.61458333, 0.66666667,\n",
              "        0.60416667, 0.625     , 0.64583333, 0.65625   , 0.64583333,\n",
              "        0.70833333, 0.61458333, 0.64583333, 0.67708333, 0.66666667,\n",
              "        0.66666667, 0.69791667, 0.61458333, 0.625     , 0.64583333,\n",
              "        0.6875    , 0.625     , 0.61458333, 0.65625   , 0.625     ,\n",
              "        0.67708333, 0.66666667, 0.66666667, 0.625     , 0.66666667,\n",
              "        0.54166667, 0.66666667, 0.63541667, 0.67708333, 0.625     ,\n",
              "        0.61458333, 0.60416667, 0.64583333, 0.63541667, 0.60416667,\n",
              "        0.625     , 0.6875    , 0.61458333, 0.625     , 0.63541667,\n",
              "        0.65625   , 0.71875   , 0.64583333, 0.67708333, 0.61458333]),\n",
              " 'split1_test_score': array([0.625     , 0.66666667, 0.63541667, 0.59375   , 0.65625   ,\n",
              "        0.64583333, 0.66666667, 0.64583333, 0.63541667, 0.64583333,\n",
              "        0.61458333, 0.65625   , 0.67708333, 0.65625   , 0.625     ,\n",
              "        0.63541667, 0.71875   , 0.67708333, 0.65625   , 0.65625   ,\n",
              "        0.63541667, 0.71875   , 0.66666667, 0.65625   , 0.67708333,\n",
              "        0.64583333, 0.67708333, 0.625     , 0.67708333, 0.67708333,\n",
              "        0.70833333, 0.69791667, 0.71875   , 0.66666667, 0.65625   ,\n",
              "        0.66666667, 0.625     , 0.66666667, 0.66666667, 0.65625   ,\n",
              "        0.625     , 0.67708333, 0.69791667, 0.70833333, 0.65625   ,\n",
              "        0.66666667, 0.67708333, 0.69791667, 0.69791667, 0.67708333,\n",
              "        0.75      , 0.66666667, 0.73958333, 0.66666667, 0.6875    ,\n",
              "        0.71875   , 0.70833333, 0.71875   , 0.69791667, 0.69791667,\n",
              "        0.64583333, 0.70833333, 0.69791667, 0.66666667, 0.71875   ,\n",
              "        0.71875   , 0.72916667, 0.69791667, 0.66666667, 0.70833333,\n",
              "        0.73958333, 0.72916667, 0.6875    , 0.66666667, 0.67708333,\n",
              "        0.69791667, 0.71875   , 0.66666667, 0.69791667, 0.69791667,\n",
              "        0.65625   , 0.625     , 0.66666667, 0.58333333, 0.63541667,\n",
              "        0.625     , 0.60416667, 0.63541667, 0.65625   , 0.63541667,\n",
              "        0.73958333, 0.6875    , 0.64583333, 0.67708333, 0.66666667,\n",
              "        0.65625   , 0.61458333, 0.66666667, 0.67708333, 0.66666667,\n",
              "        0.70833333, 0.66666667, 0.6875    , 0.65625   , 0.67708333,\n",
              "        0.60416667, 0.64583333, 0.67708333, 0.65625   , 0.69791667,\n",
              "        0.67708333, 0.67708333, 0.64583333, 0.6875    , 0.69791667,\n",
              "        0.67708333, 0.64583333, 0.67708333, 0.69791667, 0.67708333,\n",
              "        0.59375   , 0.66666667, 0.71875   , 0.67708333, 0.70833333,\n",
              "        0.63541667, 0.70833333, 0.72916667, 0.64583333, 0.67708333,\n",
              "        0.76041667, 0.70833333, 0.67708333, 0.70833333, 0.65625   ,\n",
              "        0.67708333, 0.64583333, 0.70833333, 0.73958333, 0.73958333,\n",
              "        0.72916667, 0.6875    , 0.69791667, 0.71875   , 0.67708333,\n",
              "        0.77083333, 0.6875    , 0.67708333, 0.71875   , 0.65625   ,\n",
              "        0.69791667, 0.625     , 0.71875   , 0.71875   , 0.6875    ,\n",
              "        0.77083333, 0.6875    , 0.69791667, 0.67708333, 0.72916667,\n",
              "        0.58333333, 0.63541667, 0.58333333, 0.625     , 0.60416667,\n",
              "        0.59375   , 0.6875    , 0.69791667, 0.63541667, 0.63541667,\n",
              "        0.625     , 0.57291667, 0.625     , 0.67708333, 0.65625   ,\n",
              "        0.71875   , 0.64583333, 0.66666667, 0.65625   , 0.65625   ,\n",
              "        0.67708333, 0.69791667, 0.64583333, 0.6875    , 0.66666667,\n",
              "        0.70833333, 0.71875   , 0.64583333, 0.66666667, 0.66666667,\n",
              "        0.625     , 0.63541667, 0.64583333, 0.65625   , 0.64583333,\n",
              "        0.66666667, 0.65625   , 0.65625   , 0.66666667, 0.65625   ,\n",
              "        0.69791667, 0.69791667, 0.70833333, 0.71875   , 0.73958333,\n",
              "        0.67708333, 0.73958333, 0.67708333, 0.67708333, 0.69791667,\n",
              "        0.75      , 0.64583333, 0.66666667, 0.65625   , 0.66666667,\n",
              "        0.72916667, 0.72916667, 0.6875    , 0.6875    , 0.66666667,\n",
              "        0.6875    , 0.70833333, 0.71875   , 0.69791667, 0.69791667,\n",
              "        0.67708333, 0.6875    , 0.6875    , 0.71875   , 0.6875    ,\n",
              "        0.73958333, 0.67708333, 0.63541667, 0.69791667, 0.69791667,\n",
              "        0.65625   , 0.64583333, 0.67708333, 0.6875    , 0.69791667,\n",
              "        0.5625    , 0.57291667, 0.66666667, 0.63541667, 0.625     ,\n",
              "        0.69791667, 0.625     , 0.64583333, 0.625     , 0.63541667,\n",
              "        0.69791667, 0.64583333, 0.625     , 0.64583333, 0.65625   ,\n",
              "        0.66666667, 0.65625   , 0.69791667, 0.6875    , 0.66666667,\n",
              "        0.58333333, 0.63541667, 0.67708333, 0.67708333, 0.67708333,\n",
              "        0.65625   , 0.67708333, 0.65625   , 0.64583333, 0.625     ,\n",
              "        0.61458333, 0.6875    , 0.67708333, 0.67708333, 0.67708333,\n",
              "        0.61458333, 0.71875   , 0.66666667, 0.64583333, 0.64583333,\n",
              "        0.67708333, 0.65625   , 0.72916667, 0.67708333, 0.67708333,\n",
              "        0.67708333, 0.69791667, 0.69791667, 0.67708333, 0.6875    ,\n",
              "        0.66666667, 0.71875   , 0.70833333, 0.66666667, 0.69791667,\n",
              "        0.73958333, 0.66666667, 0.71875   , 0.65625   , 0.6875    ,\n",
              "        0.69791667, 0.71875   , 0.70833333, 0.6875    , 0.67708333,\n",
              "        0.69791667, 0.66666667, 0.72916667, 0.67708333, 0.66666667,\n",
              "        0.6875    , 0.69791667, 0.6875    , 0.69791667, 0.69791667,\n",
              "        0.73958333, 0.64583333, 0.75      , 0.6875    , 0.6875    ,\n",
              "        0.55208333, 0.67708333, 0.61458333, 0.625     , 0.61458333,\n",
              "        0.64583333, 0.64583333, 0.625     , 0.61458333, 0.625     ,\n",
              "        0.63541667, 0.6875    , 0.66666667, 0.6875    , 0.63541667,\n",
              "        0.6875    , 0.64583333, 0.6875    , 0.65625   , 0.65625   ,\n",
              "        0.625     , 0.72916667, 0.65625   , 0.65625   , 0.65625   ,\n",
              "        0.66666667, 0.64583333, 0.70833333, 0.6875    , 0.67708333,\n",
              "        0.6875    , 0.67708333, 0.64583333, 0.65625   , 0.65625   ,\n",
              "        0.69791667, 0.70833333, 0.6875    , 0.66666667, 0.64583333,\n",
              "        0.66666667, 0.66666667, 0.66666667, 0.66666667, 0.66666667,\n",
              "        0.71875   , 0.6875    , 0.67708333, 0.66666667, 0.66666667,\n",
              "        0.70833333, 0.67708333, 0.64583333, 0.64583333, 0.64583333,\n",
              "        0.72916667, 0.67708333, 0.67708333, 0.64583333, 0.65625   ,\n",
              "        0.65625   , 0.67708333, 0.66666667, 0.66666667, 0.66666667,\n",
              "        0.69791667, 0.67708333, 0.70833333, 0.67708333, 0.6875    ,\n",
              "        0.71875   , 0.67708333, 0.64583333, 0.67708333, 0.63541667,\n",
              "        0.65625   , 0.71875   , 0.71875   , 0.63541667, 0.67708333,\n",
              "        0.64583333, 0.67708333, 0.60416667, 0.60416667, 0.60416667,\n",
              "        0.60416667, 0.65625   , 0.72916667, 0.63541667, 0.61458333,\n",
              "        0.60416667, 0.67708333, 0.65625   , 0.65625   , 0.61458333,\n",
              "        0.65625   , 0.65625   , 0.64583333, 0.67708333, 0.65625   ,\n",
              "        0.69791667, 0.69791667, 0.64583333, 0.66666667, 0.64583333,\n",
              "        0.66666667, 0.6875    , 0.66666667, 0.625     , 0.64583333,\n",
              "        0.65625   , 0.64583333, 0.64583333, 0.64583333, 0.64583333,\n",
              "        0.72916667, 0.69791667, 0.66666667, 0.65625   , 0.64583333,\n",
              "        0.66666667, 0.65625   , 0.66666667, 0.64583333, 0.65625   ,\n",
              "        0.64583333, 0.65625   , 0.64583333, 0.65625   , 0.66666667,\n",
              "        0.65625   , 0.71875   , 0.70833333, 0.69791667, 0.65625   ,\n",
              "        0.66666667, 0.63541667, 0.64583333, 0.65625   , 0.66666667,\n",
              "        0.67708333, 0.73958333, 0.6875    , 0.66666667, 0.6875    ,\n",
              "        0.69791667, 0.69791667, 0.6875    , 0.6875    , 0.69791667,\n",
              "        0.70833333, 0.6875    , 0.70833333, 0.66666667, 0.67708333,\n",
              "        0.73958333, 0.6875    , 0.67708333, 0.64583333, 0.65625   ,\n",
              "        0.6875    , 0.66666667, 0.64583333, 0.66666667, 0.61458333,\n",
              "        0.65625   , 0.625     , 0.65625   , 0.64583333, 0.66666667,\n",
              "        0.59375   , 0.65625   , 0.60416667, 0.63541667, 0.63541667,\n",
              "        0.60416667, 0.72916667, 0.64583333, 0.67708333, 0.64583333,\n",
              "        0.61458333, 0.65625   , 0.67708333, 0.64583333, 0.64583333,\n",
              "        0.63541667, 0.66666667, 0.66666667, 0.64583333, 0.66666667,\n",
              "        0.76041667, 0.61458333, 0.69791667, 0.67708333, 0.64583333,\n",
              "        0.66666667, 0.65625   , 0.71875   , 0.67708333, 0.64583333,\n",
              "        0.6875    , 0.66666667, 0.6875    , 0.63541667, 0.64583333,\n",
              "        0.71875   , 0.69791667, 0.6875    , 0.66666667, 0.66666667,\n",
              "        0.65625   , 0.64583333, 0.65625   , 0.65625   , 0.70833333,\n",
              "        0.6875    , 0.69791667, 0.64583333, 0.66666667, 0.65625   ,\n",
              "        0.72916667, 0.64583333, 0.64583333, 0.6875    , 0.64583333,\n",
              "        0.75      , 0.70833333, 0.70833333, 0.67708333, 0.63541667,\n",
              "        0.72916667, 0.64583333, 0.73958333, 0.63541667, 0.66666667,\n",
              "        0.77083333, 0.69791667, 0.75      , 0.67708333, 0.65625   ,\n",
              "        0.67708333, 0.61458333, 0.64583333, 0.63541667, 0.66666667,\n",
              "        0.61458333, 0.60416667, 0.64583333, 0.69791667, 0.67708333,\n",
              "        0.63541667, 0.63541667, 0.64583333, 0.6875    , 0.67708333,\n",
              "        0.65625   , 0.66666667, 0.625     , 0.63541667, 0.65625   ,\n",
              "        0.60416667, 0.65625   , 0.6875    , 0.67708333, 0.64583333,\n",
              "        0.70833333, 0.65625   , 0.63541667, 0.65625   , 0.64583333,\n",
              "        0.64583333, 0.72916667, 0.69791667, 0.6875    , 0.63541667,\n",
              "        0.66666667, 0.63541667, 0.63541667, 0.64583333, 0.64583333,\n",
              "        0.64583333, 0.67708333, 0.67708333, 0.6875    , 0.65625   ,\n",
              "        0.70833333, 0.64583333, 0.66666667, 0.66666667, 0.625     ,\n",
              "        0.67708333, 0.64583333, 0.67708333, 0.6875    , 0.6875    ,\n",
              "        0.61458333, 0.69791667, 0.69791667, 0.67708333, 0.67708333,\n",
              "        0.72916667, 0.69791667, 0.67708333, 0.65625   , 0.6875    ,\n",
              "        0.69791667, 0.69791667, 0.69791667, 0.66666667, 0.67708333,\n",
              "        0.73958333, 0.6875    , 0.67708333, 0.65625   , 0.65625   ,\n",
              "        0.6875    , 0.67708333, 0.70833333, 0.66666667, 0.6875    ]),\n",
              " 'split2_test_score': array([0.625     , 0.65625   , 0.66666667, 0.69791667, 0.71875   ,\n",
              "        0.67708333, 0.70833333, 0.6875    , 0.70833333, 0.6875    ,\n",
              "        0.60416667, 0.6875    , 0.70833333, 0.6875    , 0.69791667,\n",
              "        0.64583333, 0.67708333, 0.69791667, 0.66666667, 0.6875    ,\n",
              "        0.70833333, 0.67708333, 0.66666667, 0.70833333, 0.70833333,\n",
              "        0.66666667, 0.71875   , 0.70833333, 0.69791667, 0.70833333,\n",
              "        0.71875   , 0.64583333, 0.66666667, 0.65625   , 0.69791667,\n",
              "        0.63541667, 0.71875   , 0.73958333, 0.70833333, 0.70833333,\n",
              "        0.6875    , 0.72916667, 0.6875    , 0.65625   , 0.66666667,\n",
              "        0.61458333, 0.6875    , 0.67708333, 0.65625   , 0.6875    ,\n",
              "        0.6875    , 0.72916667, 0.66666667, 0.69791667, 0.70833333,\n",
              "        0.66666667, 0.6875    , 0.6875    , 0.6875    , 0.71875   ,\n",
              "        0.65625   , 0.66666667, 0.70833333, 0.67708333, 0.72916667,\n",
              "        0.63541667, 0.6875    , 0.73958333, 0.71875   , 0.69791667,\n",
              "        0.6875    , 0.6875    , 0.67708333, 0.6875    , 0.69791667,\n",
              "        0.66666667, 0.69791667, 0.65625   , 0.69791667, 0.71875   ,\n",
              "        0.64583333, 0.64583333, 0.65625   , 0.72916667, 0.71875   ,\n",
              "        0.65625   , 0.64583333, 0.72916667, 0.6875    , 0.67708333,\n",
              "        0.64583333, 0.625     , 0.69791667, 0.71875   , 0.66666667,\n",
              "        0.65625   , 0.64583333, 0.6875    , 0.69791667, 0.69791667,\n",
              "        0.6875    , 0.67708333, 0.66666667, 0.67708333, 0.6875    ,\n",
              "        0.61458333, 0.64583333, 0.65625   , 0.67708333, 0.69791667,\n",
              "        0.64583333, 0.66666667, 0.67708333, 0.70833333, 0.71875   ,\n",
              "        0.67708333, 0.63541667, 0.67708333, 0.70833333, 0.6875    ,\n",
              "        0.65625   , 0.6875    , 0.6875    , 0.6875    , 0.65625   ,\n",
              "        0.70833333, 0.70833333, 0.63541667, 0.6875    , 0.70833333,\n",
              "        0.6875    , 0.67708333, 0.6875    , 0.69791667, 0.6875    ,\n",
              "        0.625     , 0.71875   , 0.67708333, 0.65625   , 0.70833333,\n",
              "        0.61458333, 0.64583333, 0.69791667, 0.67708333, 0.6875    ,\n",
              "        0.65625   , 0.64583333, 0.66666667, 0.67708333, 0.70833333,\n",
              "        0.65625   , 0.69791667, 0.70833333, 0.66666667, 0.72916667,\n",
              "        0.65625   , 0.6875    , 0.73958333, 0.65625   , 0.67708333,\n",
              "        0.58333333, 0.72916667, 0.69791667, 0.72916667, 0.66666667,\n",
              "        0.67708333, 0.6875    , 0.70833333, 0.6875    , 0.69791667,\n",
              "        0.61458333, 0.67708333, 0.69791667, 0.67708333, 0.6875    ,\n",
              "        0.60416667, 0.67708333, 0.66666667, 0.67708333, 0.67708333,\n",
              "        0.70833333, 0.6875    , 0.70833333, 0.71875   , 0.70833333,\n",
              "        0.625     , 0.6875    , 0.6875    , 0.6875    , 0.69791667,\n",
              "        0.625     , 0.69791667, 0.69791667, 0.6875    , 0.70833333,\n",
              "        0.65625   , 0.65625   , 0.63541667, 0.73958333, 0.6875    ,\n",
              "        0.625     , 0.66666667, 0.69791667, 0.66666667, 0.69791667,\n",
              "        0.67708333, 0.65625   , 0.65625   , 0.67708333, 0.69791667,\n",
              "        0.69791667, 0.69791667, 0.67708333, 0.69791667, 0.71875   ,\n",
              "        0.69791667, 0.67708333, 0.65625   , 0.6875    , 0.6875    ,\n",
              "        0.70833333, 0.71875   , 0.61458333, 0.63541667, 0.70833333,\n",
              "        0.69791667, 0.66666667, 0.69791667, 0.65625   , 0.69791667,\n",
              "        0.67708333, 0.61458333, 0.625     , 0.625     , 0.73958333,\n",
              "        0.61458333, 0.61458333, 0.69791667, 0.70833333, 0.69791667,\n",
              "        0.66666667, 0.69791667, 0.63541667, 0.69791667, 0.70833333,\n",
              "        0.6875    , 0.67708333, 0.6875    , 0.6875    , 0.6875    ,\n",
              "        0.66666667, 0.70833333, 0.66666667, 0.64583333, 0.73958333,\n",
              "        0.59375   , 0.73958333, 0.65625   , 0.69791667, 0.67708333,\n",
              "        0.71875   , 0.69791667, 0.69791667, 0.70833333, 0.6875    ,\n",
              "        0.6875    , 0.65625   , 0.64583333, 0.70833333, 0.70833333,\n",
              "        0.63541667, 0.6875    , 0.6875    , 0.69791667, 0.67708333,\n",
              "        0.64583333, 0.67708333, 0.6875    , 0.66666667, 0.70833333,\n",
              "        0.70833333, 0.67708333, 0.6875    , 0.70833333, 0.6875    ,\n",
              "        0.61458333, 0.66666667, 0.6875    , 0.6875    , 0.69791667,\n",
              "        0.71875   , 0.59375   , 0.6875    , 0.6875    , 0.67708333,\n",
              "        0.70833333, 0.67708333, 0.72916667, 0.71875   , 0.6875    ,\n",
              "        0.6875    , 0.69791667, 0.65625   , 0.6875    , 0.66666667,\n",
              "        0.63541667, 0.66666667, 0.66666667, 0.66666667, 0.65625   ,\n",
              "        0.66666667, 0.67708333, 0.6875    , 0.67708333, 0.69791667,\n",
              "        0.61458333, 0.66666667, 0.64583333, 0.70833333, 0.69791667,\n",
              "        0.59375   , 0.69791667, 0.69791667, 0.66666667, 0.67708333,\n",
              "        0.64583333, 0.65625   , 0.65625   , 0.70833333, 0.63541667,\n",
              "        0.63541667, 0.67708333, 0.69791667, 0.66666667, 0.70833333,\n",
              "        0.63541667, 0.65625   , 0.75      , 0.6875    , 0.69791667,\n",
              "        0.59375   , 0.69791667, 0.70833333, 0.66666667, 0.67708333,\n",
              "        0.66666667, 0.64583333, 0.66666667, 0.66666667, 0.6875    ,\n",
              "        0.64583333, 0.69791667, 0.69791667, 0.69791667, 0.69791667,\n",
              "        0.67708333, 0.69791667, 0.6875    , 0.69791667, 0.6875    ,\n",
              "        0.6875    , 0.6875    , 0.63541667, 0.67708333, 0.67708333,\n",
              "        0.66666667, 0.67708333, 0.65625   , 0.6875    , 0.6875    ,\n",
              "        0.70833333, 0.64583333, 0.71875   , 0.67708333, 0.67708333,\n",
              "        0.75      , 0.625     , 0.65625   , 0.65625   , 0.65625   ,\n",
              "        0.67708333, 0.69791667, 0.6875    , 0.67708333, 0.6875    ,\n",
              "        0.6875    , 0.70833333, 0.67708333, 0.6875    , 0.66666667,\n",
              "        0.67708333, 0.67708333, 0.66666667, 0.67708333, 0.67708333,\n",
              "        0.64583333, 0.67708333, 0.66666667, 0.6875    , 0.6875    ,\n",
              "        0.6875    , 0.69791667, 0.67708333, 0.67708333, 0.6875    ,\n",
              "        0.65625   , 0.69791667, 0.66666667, 0.67708333, 0.6875    ,\n",
              "        0.6875    , 0.65625   , 0.6875    , 0.6875    , 0.70833333,\n",
              "        0.64583333, 0.70833333, 0.70833333, 0.67708333, 0.66666667,\n",
              "        0.625     , 0.67708333, 0.70833333, 0.71875   , 0.66666667,\n",
              "        0.67708333, 0.67708333, 0.67708333, 0.67708333, 0.70833333,\n",
              "        0.54166667, 0.67708333, 0.70833333, 0.67708333, 0.66666667,\n",
              "        0.67708333, 0.6875    , 0.6875    , 0.69791667, 0.66666667,\n",
              "        0.69791667, 0.69791667, 0.66666667, 0.65625   , 0.69791667,\n",
              "        0.61458333, 0.63541667, 0.65625   , 0.6875    , 0.67708333,\n",
              "        0.65625   , 0.67708333, 0.69791667, 0.6875    , 0.69791667,\n",
              "        0.6875    , 0.66666667, 0.61458333, 0.66666667, 0.66666667,\n",
              "        0.66666667, 0.71875   , 0.67708333, 0.6875    , 0.69791667,\n",
              "        0.58333333, 0.66666667, 0.625     , 0.6875    , 0.69791667,\n",
              "        0.60416667, 0.67708333, 0.66666667, 0.6875    , 0.69791667,\n",
              "        0.60416667, 0.67708333, 0.67708333, 0.6875    , 0.70833333,\n",
              "        0.63541667, 0.6875    , 0.66666667, 0.69791667, 0.69791667,\n",
              "        0.75      , 0.65625   , 0.69791667, 0.6875    , 0.6875    ,\n",
              "        0.6875    , 0.67708333, 0.6875    , 0.66666667, 0.71875   ,\n",
              "        0.66666667, 0.64583333, 0.6875    , 0.69791667, 0.67708333,\n",
              "        0.72916667, 0.63541667, 0.66666667, 0.70833333, 0.66666667,\n",
              "        0.63541667, 0.64583333, 0.65625   , 0.66666667, 0.65625   ,\n",
              "        0.65625   , 0.66666667, 0.6875    , 0.71875   , 0.67708333,\n",
              "        0.64583333, 0.66666667, 0.69791667, 0.67708333, 0.66666667,\n",
              "        0.70833333, 0.65625   , 0.70833333, 0.63541667, 0.70833333,\n",
              "        0.63541667, 0.66666667, 0.66666667, 0.69791667, 0.6875    ,\n",
              "        0.65625   , 0.66666667, 0.69791667, 0.63541667, 0.67708333,\n",
              "        0.70833333, 0.65625   , 0.6875    , 0.67708333, 0.67708333,\n",
              "        0.63541667, 0.6875    , 0.71875   , 0.69791667, 0.66666667,\n",
              "        0.65625   , 0.66666667, 0.70833333, 0.67708333, 0.6875    ,\n",
              "        0.67708333, 0.67708333, 0.70833333, 0.69791667, 0.6875    ,\n",
              "        0.60416667, 0.625     , 0.67708333, 0.6875    , 0.65625   ,\n",
              "        0.60416667, 0.67708333, 0.64583333, 0.6875    , 0.71875   ,\n",
              "        0.70833333, 0.63541667, 0.66666667, 0.69791667, 0.64583333,\n",
              "        0.65625   , 0.6875    , 0.73958333, 0.67708333, 0.67708333,\n",
              "        0.63541667, 0.71875   , 0.66666667, 0.6875    , 0.66666667,\n",
              "        0.70833333, 0.625     , 0.6875    , 0.66666667, 0.67708333,\n",
              "        0.63541667, 0.70833333, 0.6875    , 0.66666667, 0.65625   ,\n",
              "        0.57291667, 0.6875    , 0.67708333, 0.71875   , 0.67708333,\n",
              "        0.65625   , 0.64583333, 0.65625   , 0.69791667, 0.6875    ,\n",
              "        0.70833333, 0.69791667, 0.70833333, 0.67708333, 0.6875    ,\n",
              "        0.6875    , 0.65625   , 0.66666667, 0.72916667, 0.69791667,\n",
              "        0.63541667, 0.66666667, 0.65625   , 0.67708333, 0.6875    ,\n",
              "        0.65625   , 0.65625   , 0.67708333, 0.66666667, 0.67708333,\n",
              "        0.64583333, 0.64583333, 0.71875   , 0.69791667, 0.6875    ,\n",
              "        0.67708333, 0.64583333, 0.67708333, 0.69791667, 0.6875    ,\n",
              "        0.6875    , 0.73958333, 0.63541667, 0.69791667, 0.6875    ,\n",
              "        0.6875    , 0.63541667, 0.66666667, 0.6875    , 0.6875    ]),\n",
              " 'split3_test_score': array([0.65625   , 0.67708333, 0.75      , 0.77083333, 0.78125   ,\n",
              "        0.70833333, 0.6875    , 0.72916667, 0.72916667, 0.70833333,\n",
              "        0.73958333, 0.78125   , 0.77083333, 0.76041667, 0.76041667,\n",
              "        0.73958333, 0.72916667, 0.72916667, 0.76041667, 0.76041667,\n",
              "        0.71875   , 0.75      , 0.72916667, 0.78125   , 0.78125   ,\n",
              "        0.76041667, 0.76041667, 0.78125   , 0.78125   , 0.75      ,\n",
              "        0.71875   , 0.72916667, 0.73958333, 0.75      , 0.75      ,\n",
              "        0.77083333, 0.72916667, 0.76041667, 0.76041667, 0.79166667,\n",
              "        0.70833333, 0.71875   , 0.71875   , 0.77083333, 0.79166667,\n",
              "        0.72916667, 0.71875   , 0.75      , 0.73958333, 0.78125   ,\n",
              "        0.78125   , 0.78125   , 0.78125   , 0.76041667, 0.72916667,\n",
              "        0.76041667, 0.73958333, 0.77083333, 0.77083333, 0.78125   ,\n",
              "        0.73958333, 0.71875   , 0.71875   , 0.76041667, 0.75      ,\n",
              "        0.78125   , 0.78125   , 0.77083333, 0.69791667, 0.77083333,\n",
              "        0.71875   , 0.6875    , 0.73958333, 0.71875   , 0.71875   ,\n",
              "        0.71875   , 0.75      , 0.75      , 0.76041667, 0.72916667,\n",
              "        0.63541667, 0.73958333, 0.75      , 0.75      , 0.77083333,\n",
              "        0.72916667, 0.70833333, 0.71875   , 0.72916667, 0.79166667,\n",
              "        0.72916667, 0.6875    , 0.77083333, 0.75      , 0.76041667,\n",
              "        0.72916667, 0.69791667, 0.72916667, 0.8125    , 0.78125   ,\n",
              "        0.67708333, 0.73958333, 0.69791667, 0.80208333, 0.73958333,\n",
              "        0.69791667, 0.72916667, 0.72916667, 0.70833333, 0.77083333,\n",
              "        0.72916667, 0.72916667, 0.73958333, 0.77083333, 0.77083333,\n",
              "        0.73958333, 0.63541667, 0.75      , 0.75      , 0.77083333,\n",
              "        0.73958333, 0.71875   , 0.76041667, 0.75      , 0.77083333,\n",
              "        0.69791667, 0.8125    , 0.76041667, 0.75      , 0.77083333,\n",
              "        0.78125   , 0.75      , 0.69791667, 0.73958333, 0.73958333,\n",
              "        0.80208333, 0.6875    , 0.76041667, 0.73958333, 0.75      ,\n",
              "        0.6875    , 0.69791667, 0.70833333, 0.77083333, 0.76041667,\n",
              "        0.8125    , 0.72916667, 0.73958333, 0.77083333, 0.72916667,\n",
              "        0.72916667, 0.73958333, 0.76041667, 0.69791667, 0.76041667,\n",
              "        0.69791667, 0.66666667, 0.75      , 0.77083333, 0.72916667,\n",
              "        0.75      , 0.69791667, 0.71875   , 0.75      , 0.73958333,\n",
              "        0.70833333, 0.75      , 0.76041667, 0.77083333, 0.76041667,\n",
              "        0.6875    , 0.77083333, 0.77083333, 0.79166667, 0.76041667,\n",
              "        0.6875    , 0.77083333, 0.76041667, 0.77083333, 0.77083333,\n",
              "        0.6875    , 0.73958333, 0.79166667, 0.72916667, 0.78125   ,\n",
              "        0.72916667, 0.69791667, 0.75      , 0.78125   , 0.72916667,\n",
              "        0.71875   , 0.71875   , 0.77083333, 0.73958333, 0.73958333,\n",
              "        0.66666667, 0.78125   , 0.73958333, 0.77083333, 0.77083333,\n",
              "        0.77083333, 0.6875    , 0.73958333, 0.71875   , 0.75      ,\n",
              "        0.75      , 0.71875   , 0.73958333, 0.79166667, 0.77083333,\n",
              "        0.6875    , 0.72916667, 0.78125   , 0.72916667, 0.73958333,\n",
              "        0.69791667, 0.75      , 0.73958333, 0.78125   , 0.78125   ,\n",
              "        0.71875   , 0.6875    , 0.77083333, 0.73958333, 0.76041667,\n",
              "        0.70833333, 0.70833333, 0.73958333, 0.78125   , 0.77083333,\n",
              "        0.77083333, 0.69791667, 0.76041667, 0.72916667, 0.70833333,\n",
              "        0.72916667, 0.76041667, 0.76041667, 0.77083333, 0.70833333,\n",
              "        0.67708333, 0.71875   , 0.71875   , 0.71875   , 0.75      ,\n",
              "        0.75      , 0.72916667, 0.78125   , 0.80208333, 0.76041667,\n",
              "        0.75      , 0.78125   , 0.73958333, 0.73958333, 0.78125   ,\n",
              "        0.65625   , 0.71875   , 0.75      , 0.80208333, 0.77083333,\n",
              "        0.69791667, 0.76041667, 0.72916667, 0.75      , 0.75      ,\n",
              "        0.72916667, 0.72916667, 0.75      , 0.77083333, 0.73958333,\n",
              "        0.76041667, 0.71875   , 0.80208333, 0.78125   , 0.76041667,\n",
              "        0.79166667, 0.71875   , 0.80208333, 0.72916667, 0.76041667,\n",
              "        0.75      , 0.78125   , 0.75      , 0.78125   , 0.75      ,\n",
              "        0.76041667, 0.69791667, 0.71875   , 0.79166667, 0.73958333,\n",
              "        0.76041667, 0.71875   , 0.73958333, 0.75      , 0.77083333,\n",
              "        0.72916667, 0.75      , 0.78125   , 0.77083333, 0.75      ,\n",
              "        0.67708333, 0.73958333, 0.76041667, 0.73958333, 0.73958333,\n",
              "        0.77083333, 0.79166667, 0.71875   , 0.72916667, 0.73958333,\n",
              "        0.72916667, 0.67708333, 0.76041667, 0.70833333, 0.72916667,\n",
              "        0.71875   , 0.77083333, 0.73958333, 0.71875   , 0.77083333,\n",
              "        0.72916667, 0.78125   , 0.76041667, 0.76041667, 0.73958333,\n",
              "        0.78125   , 0.72916667, 0.71875   , 0.76041667, 0.75      ,\n",
              "        0.6875    , 0.76041667, 0.6875    , 0.77083333, 0.76041667,\n",
              "        0.75      , 0.71875   , 0.79166667, 0.69791667, 0.78125   ,\n",
              "        0.70833333, 0.79166667, 0.80208333, 0.77083333, 0.77083333,\n",
              "        0.76041667, 0.69791667, 0.71875   , 0.79166667, 0.75      ,\n",
              "        0.65625   , 0.70833333, 0.79166667, 0.71875   , 0.78125   ,\n",
              "        0.69791667, 0.76041667, 0.75      , 0.79166667, 0.73958333,\n",
              "        0.70833333, 0.70833333, 0.79166667, 0.75      , 0.71875   ,\n",
              "        0.69791667, 0.66666667, 0.72916667, 0.77083333, 0.72916667,\n",
              "        0.67708333, 0.73958333, 0.69791667, 0.70833333, 0.79166667,\n",
              "        0.71875   , 0.75      , 0.76041667, 0.78125   , 0.71875   ,\n",
              "        0.77083333, 0.76041667, 0.71875   , 0.70833333, 0.75      ,\n",
              "        0.72916667, 0.73958333, 0.78125   , 0.75      , 0.72916667,\n",
              "        0.66666667, 0.8125    , 0.75      , 0.72916667, 0.70833333,\n",
              "        0.6875    , 0.72916667, 0.76041667, 0.78125   , 0.78125   ,\n",
              "        0.625     , 0.75      , 0.73958333, 0.73958333, 0.75      ,\n",
              "        0.73958333, 0.80208333, 0.73958333, 0.73958333, 0.71875   ,\n",
              "        0.76041667, 0.72916667, 0.73958333, 0.79166667, 0.77083333,\n",
              "        0.80208333, 0.75      , 0.76041667, 0.73958333, 0.75      ,\n",
              "        0.77083333, 0.70833333, 0.79166667, 0.75      , 0.78125   ,\n",
              "        0.72916667, 0.72916667, 0.75      , 0.75      , 0.73958333,\n",
              "        0.73958333, 0.73958333, 0.75      , 0.72916667, 0.76041667,\n",
              "        0.77083333, 0.70833333, 0.76041667, 0.77083333, 0.76041667,\n",
              "        0.79166667, 0.76041667, 0.71875   , 0.76041667, 0.76041667,\n",
              "        0.71875   , 0.78125   , 0.76041667, 0.70833333, 0.72916667,\n",
              "        0.6875    , 0.77083333, 0.70833333, 0.77083333, 0.75      ,\n",
              "        0.77083333, 0.72916667, 0.72916667, 0.73958333, 0.77083333,\n",
              "        0.6875    , 0.71875   , 0.73958333, 0.75      , 0.77083333,\n",
              "        0.67708333, 0.76041667, 0.73958333, 0.78125   , 0.75      ,\n",
              "        0.70833333, 0.78125   , 0.73958333, 0.76041667, 0.72916667,\n",
              "        0.77083333, 0.76041667, 0.72916667, 0.75      , 0.75      ,\n",
              "        0.71875   , 0.77083333, 0.82291667, 0.72916667, 0.75      ,\n",
              "        0.70833333, 0.77083333, 0.78125   , 0.76041667, 0.77083333,\n",
              "        0.77083333, 0.78125   , 0.73958333, 0.76041667, 0.76041667,\n",
              "        0.75      , 0.70833333, 0.76041667, 0.73958333, 0.76041667,\n",
              "        0.73958333, 0.76041667, 0.75      , 0.75      , 0.77083333,\n",
              "        0.65625   , 0.70833333, 0.75      , 0.76041667, 0.76041667,\n",
              "        0.76041667, 0.79166667, 0.75      , 0.77083333, 0.79166667,\n",
              "        0.73958333, 0.72916667, 0.75      , 0.76041667, 0.79166667,\n",
              "        0.71875   , 0.77083333, 0.71875   , 0.72916667, 0.72916667,\n",
              "        0.6875    , 0.70833333, 0.77083333, 0.69791667, 0.78125   ,\n",
              "        0.72916667, 0.73958333, 0.75      , 0.73958333, 0.73958333,\n",
              "        0.75      , 0.75      , 0.72916667, 0.80208333, 0.73958333,\n",
              "        0.72916667, 0.75      , 0.76041667, 0.75      , 0.80208333,\n",
              "        0.80208333, 0.78125   , 0.79166667, 0.76041667, 0.75      ,\n",
              "        0.71875   , 0.73958333, 0.73958333, 0.75      , 0.76041667,\n",
              "        0.75      , 0.76041667, 0.75      , 0.72916667, 0.77083333,\n",
              "        0.72916667, 0.6875    , 0.71875   , 0.76041667, 0.75      ,\n",
              "        0.69791667, 0.75      , 0.71875   , 0.70833333, 0.72916667,\n",
              "        0.6875    , 0.75      , 0.78125   , 0.76041667, 0.75      ,\n",
              "        0.66666667, 0.76041667, 0.77083333, 0.76041667, 0.77083333,\n",
              "        0.78125   , 0.72916667, 0.76041667, 0.77083333, 0.76041667,\n",
              "        0.6875    , 0.77083333, 0.76041667, 0.79166667, 0.78125   ,\n",
              "        0.71875   , 0.73958333, 0.76041667, 0.79166667, 0.77083333,\n",
              "        0.76041667, 0.69791667, 0.70833333, 0.77083333, 0.79166667,\n",
              "        0.71875   , 0.80208333, 0.73958333, 0.75      , 0.73958333,\n",
              "        0.72916667, 0.6875    , 0.69791667, 0.73958333, 0.77083333,\n",
              "        0.72916667, 0.70833333, 0.72916667, 0.70833333, 0.75      ,\n",
              "        0.70833333, 0.76041667, 0.76041667, 0.78125   , 0.73958333,\n",
              "        0.75      , 0.70833333, 0.78125   , 0.73958333, 0.75      ,\n",
              "        0.69791667, 0.69791667, 0.76041667, 0.75      , 0.75      ,\n",
              "        0.67708333, 0.70833333, 0.73958333, 0.73958333, 0.72916667,\n",
              "        0.72916667, 0.75      , 0.8125    , 0.73958333, 0.75      ]),\n",
              " 'split4_test_score': array([0.63541667, 0.71875   , 0.66666667, 0.71875   , 0.70833333,\n",
              "        0.6875    , 0.72916667, 0.6875    , 0.67708333, 0.71875   ,\n",
              "        0.66666667, 0.65625   , 0.73958333, 0.6875    , 0.6875    ,\n",
              "        0.69791667, 0.71875   , 0.70833333, 0.70833333, 0.69791667,\n",
              "        0.73958333, 0.72916667, 0.72916667, 0.72916667, 0.71875   ,\n",
              "        0.73958333, 0.6875    , 0.71875   , 0.71875   , 0.69791667,\n",
              "        0.69791667, 0.69791667, 0.75      , 0.71875   , 0.71875   ,\n",
              "        0.69791667, 0.71875   , 0.71875   , 0.70833333, 0.72916667,\n",
              "        0.6875    , 0.71875   , 0.71875   , 0.73958333, 0.75      ,\n",
              "        0.6875    , 0.66666667, 0.72916667, 0.67708333, 0.72916667,\n",
              "        0.67708333, 0.71875   , 0.72916667, 0.76041667, 0.72916667,\n",
              "        0.63541667, 0.72916667, 0.6875    , 0.75      , 0.70833333,\n",
              "        0.6875    , 0.66666667, 0.63541667, 0.71875   , 0.71875   ,\n",
              "        0.59375   , 0.70833333, 0.69791667, 0.70833333, 0.70833333,\n",
              "        0.59375   , 0.58333333, 0.66666667, 0.73958333, 0.71875   ,\n",
              "        0.72916667, 0.67708333, 0.72916667, 0.67708333, 0.71875   ,\n",
              "        0.6875    , 0.72916667, 0.66666667, 0.72916667, 0.6875    ,\n",
              "        0.58333333, 0.69791667, 0.67708333, 0.66666667, 0.6875    ,\n",
              "        0.67708333, 0.71875   , 0.69791667, 0.71875   , 0.69791667,\n",
              "        0.76041667, 0.73958333, 0.69791667, 0.69791667, 0.67708333,\n",
              "        0.69791667, 0.69791667, 0.70833333, 0.6875    , 0.69791667,\n",
              "        0.73958333, 0.61458333, 0.6875    , 0.69791667, 0.75      ,\n",
              "        0.67708333, 0.72916667, 0.72916667, 0.73958333, 0.71875   ,\n",
              "        0.73958333, 0.625     , 0.72916667, 0.69791667, 0.71875   ,\n",
              "        0.69791667, 0.69791667, 0.6875    , 0.6875    , 0.71875   ,\n",
              "        0.66666667, 0.63541667, 0.73958333, 0.72916667, 0.66666667,\n",
              "        0.6875    , 0.70833333, 0.70833333, 0.71875   , 0.70833333,\n",
              "        0.72916667, 0.78125   , 0.71875   , 0.71875   , 0.65625   ,\n",
              "        0.69791667, 0.60416667, 0.69791667, 0.64583333, 0.69791667,\n",
              "        0.66666667, 0.64583333, 0.73958333, 0.72916667, 0.77083333,\n",
              "        0.6875    , 0.73958333, 0.6875    , 0.75      , 0.70833333,\n",
              "        0.6875    , 0.6875    , 0.67708333, 0.73958333, 0.71875   ,\n",
              "        0.65625   , 0.71875   , 0.67708333, 0.6875    , 0.69791667,\n",
              "        0.65625   , 0.75      , 0.6875    , 0.70833333, 0.71875   ,\n",
              "        0.78125   , 0.625     , 0.71875   , 0.69791667, 0.70833333,\n",
              "        0.70833333, 0.64583333, 0.70833333, 0.71875   , 0.67708333,\n",
              "        0.72916667, 0.70833333, 0.71875   , 0.71875   , 0.72916667,\n",
              "        0.70833333, 0.69791667, 0.72916667, 0.69791667, 0.70833333,\n",
              "        0.67708333, 0.70833333, 0.76041667, 0.69791667, 0.71875   ,\n",
              "        0.71875   , 0.72916667, 0.70833333, 0.71875   , 0.70833333,\n",
              "        0.66666667, 0.70833333, 0.73958333, 0.72916667, 0.67708333,\n",
              "        0.71875   , 0.72916667, 0.6875    , 0.71875   , 0.72916667,\n",
              "        0.66666667, 0.73958333, 0.76041667, 0.71875   , 0.75      ,\n",
              "        0.72916667, 0.6875    , 0.70833333, 0.69791667, 0.72916667,\n",
              "        0.72916667, 0.64583333, 0.70833333, 0.71875   , 0.70833333,\n",
              "        0.6875    , 0.70833333, 0.71875   , 0.67708333, 0.72916667,\n",
              "        0.65625   , 0.71875   , 0.69791667, 0.6875    , 0.6875    ,\n",
              "        0.73958333, 0.65625   , 0.71875   , 0.67708333, 0.73958333,\n",
              "        0.63541667, 0.66666667, 0.70833333, 0.69791667, 0.70833333,\n",
              "        0.70833333, 0.70833333, 0.71875   , 0.72916667, 0.70833333,\n",
              "        0.70833333, 0.70833333, 0.6875    , 0.70833333, 0.69791667,\n",
              "        0.67708333, 0.71875   , 0.67708333, 0.70833333, 0.69791667,\n",
              "        0.70833333, 0.71875   , 0.70833333, 0.69791667, 0.71875   ,\n",
              "        0.71875   , 0.67708333, 0.72916667, 0.70833333, 0.69791667,\n",
              "        0.6875    , 0.70833333, 0.70833333, 0.73958333, 0.72916667,\n",
              "        0.69791667, 0.69791667, 0.64583333, 0.70833333, 0.69791667,\n",
              "        0.72916667, 0.77083333, 0.65625   , 0.72916667, 0.71875   ,\n",
              "        0.61458333, 0.71875   , 0.63541667, 0.6875    , 0.72916667,\n",
              "        0.65625   , 0.70833333, 0.69791667, 0.6875    , 0.70833333,\n",
              "        0.6875    , 0.60416667, 0.76041667, 0.71875   , 0.72916667,\n",
              "        0.63541667, 0.71875   , 0.69791667, 0.71875   , 0.70833333,\n",
              "        0.75      , 0.61458333, 0.70833333, 0.67708333, 0.69791667,\n",
              "        0.58333333, 0.73958333, 0.71875   , 0.63541667, 0.69791667,\n",
              "        0.67708333, 0.66666667, 0.69791667, 0.69791667, 0.71875   ,\n",
              "        0.65625   , 0.76041667, 0.71875   , 0.70833333, 0.69791667,\n",
              "        0.72916667, 0.75      , 0.69791667, 0.6875    , 0.69791667,\n",
              "        0.69791667, 0.71875   , 0.69791667, 0.6875    , 0.67708333,\n",
              "        0.625     , 0.70833333, 0.67708333, 0.70833333, 0.70833333,\n",
              "        0.69791667, 0.77083333, 0.72916667, 0.70833333, 0.72916667,\n",
              "        0.69791667, 0.70833333, 0.71875   , 0.72916667, 0.71875   ,\n",
              "        0.75      , 0.72916667, 0.6875    , 0.6875    , 0.70833333,\n",
              "        0.72916667, 0.67708333, 0.70833333, 0.73958333, 0.69791667,\n",
              "        0.70833333, 0.77083333, 0.72916667, 0.73958333, 0.71875   ,\n",
              "        0.67708333, 0.72916667, 0.67708333, 0.73958333, 0.71875   ,\n",
              "        0.63541667, 0.70833333, 0.73958333, 0.6875    , 0.72916667,\n",
              "        0.70833333, 0.72916667, 0.70833333, 0.66666667, 0.70833333,\n",
              "        0.63541667, 0.71875   , 0.69791667, 0.65625   , 0.71875   ,\n",
              "        0.65625   , 0.625     , 0.71875   , 0.72916667, 0.71875   ,\n",
              "        0.77083333, 0.67708333, 0.70833333, 0.6875    , 0.6875    ,\n",
              "        0.77083333, 0.58333333, 0.70833333, 0.67708333, 0.71875   ,\n",
              "        0.625     , 0.70833333, 0.70833333, 0.69791667, 0.69791667,\n",
              "        0.70833333, 0.72916667, 0.69791667, 0.72916667, 0.70833333,\n",
              "        0.65625   , 0.71875   , 0.69791667, 0.66666667, 0.70833333,\n",
              "        0.625     , 0.73958333, 0.6875    , 0.73958333, 0.72916667,\n",
              "        0.71875   , 0.76041667, 0.71875   , 0.71875   , 0.71875   ,\n",
              "        0.69791667, 0.73958333, 0.70833333, 0.73958333, 0.70833333,\n",
              "        0.69791667, 0.77083333, 0.73958333, 0.71875   , 0.70833333,\n",
              "        0.77083333, 0.6875    , 0.72916667, 0.71875   , 0.70833333,\n",
              "        0.65625   , 0.73958333, 0.72916667, 0.75      , 0.73958333,\n",
              "        0.69791667, 0.72916667, 0.72916667, 0.70833333, 0.70833333,\n",
              "        0.71875   , 0.67708333, 0.72916667, 0.71875   , 0.70833333,\n",
              "        0.73958333, 0.64583333, 0.6875    , 0.70833333, 0.72916667,\n",
              "        0.64583333, 0.67708333, 0.66666667, 0.69791667, 0.75      ,\n",
              "        0.70833333, 0.5625    , 0.72916667, 0.70833333, 0.70833333,\n",
              "        0.66666667, 0.70833333, 0.76041667, 0.6875    , 0.66666667,\n",
              "        0.69791667, 0.72916667, 0.75      , 0.73958333, 0.70833333,\n",
              "        0.69791667, 0.70833333, 0.69791667, 0.72916667, 0.6875    ,\n",
              "        0.69791667, 0.70833333, 0.71875   , 0.71875   , 0.70833333,\n",
              "        0.66666667, 0.625     , 0.70833333, 0.71875   , 0.71875   ,\n",
              "        0.64583333, 0.75      , 0.69791667, 0.72916667, 0.71875   ,\n",
              "        0.70833333, 0.73958333, 0.73958333, 0.71875   , 0.72916667,\n",
              "        0.73958333, 0.70833333, 0.69791667, 0.69791667, 0.70833333,\n",
              "        0.70833333, 0.70833333, 0.72916667, 0.70833333, 0.72916667,\n",
              "        0.65625   , 0.72916667, 0.64583333, 0.6875    , 0.72916667,\n",
              "        0.57291667, 0.6875    , 0.71875   , 0.72916667, 0.70833333,\n",
              "        0.69791667, 0.72916667, 0.70833333, 0.70833333, 0.70833333,\n",
              "        0.72916667, 0.63541667, 0.70833333, 0.72916667, 0.71875   ,\n",
              "        0.6875    , 0.71875   , 0.71875   , 0.73958333, 0.72916667,\n",
              "        0.61458333, 0.71875   , 0.64583333, 0.77083333, 0.70833333,\n",
              "        0.625     , 0.75      , 0.66666667, 0.72916667, 0.75      ,\n",
              "        0.76041667, 0.6875    , 0.64583333, 0.70833333, 0.73958333,\n",
              "        0.73958333, 0.69791667, 0.76041667, 0.71875   , 0.71875   ,\n",
              "        0.64583333, 0.64583333, 0.70833333, 0.6875    , 0.69791667,\n",
              "        0.70833333, 0.72916667, 0.73958333, 0.69791667, 0.70833333,\n",
              "        0.67708333, 0.71875   , 0.71875   , 0.71875   , 0.72916667,\n",
              "        0.71875   , 0.71875   , 0.67708333, 0.73958333, 0.70833333,\n",
              "        0.75      , 0.73958333, 0.70833333, 0.72916667, 0.67708333,\n",
              "        0.69791667, 0.6875    , 0.73958333, 0.75      , 0.72916667,\n",
              "        0.70833333, 0.73958333, 0.70833333, 0.67708333, 0.69791667,\n",
              "        0.78125   , 0.70833333, 0.70833333, 0.71875   , 0.71875   ,\n",
              "        0.67708333, 0.66666667, 0.70833333, 0.6875    , 0.70833333,\n",
              "        0.65625   , 0.69791667, 0.75      , 0.71875   , 0.69791667,\n",
              "        0.6875    , 0.73958333, 0.69791667, 0.72916667, 0.71875   ,\n",
              "        0.69791667, 0.70833333, 0.73958333, 0.71875   , 0.69791667,\n",
              "        0.70833333, 0.71875   , 0.72916667, 0.71875   , 0.70833333,\n",
              "        0.57291667, 0.67708333, 0.65625   , 0.67708333, 0.72916667,\n",
              "        0.67708333, 0.72916667, 0.69791667, 0.73958333, 0.71875   ,\n",
              "        0.65625   , 0.72916667, 0.70833333, 0.69791667, 0.72916667]),\n",
              " 'mean_test_score': array([0.62708333, 0.67083333, 0.66875   , 0.6875    , 0.69166667,\n",
              "        0.67083333, 0.6875    , 0.68333333, 0.67291667, 0.67916667,\n",
              "        0.65      , 0.68541667, 0.71041667, 0.69166667, 0.6875    ,\n",
              "        0.675     , 0.69583333, 0.7       , 0.6875    , 0.68958333,\n",
              "        0.69166667, 0.70833333, 0.69375   , 0.70208333, 0.70833333,\n",
              "        0.68125   , 0.7       , 0.69791667, 0.69791667, 0.68958333,\n",
              "        0.70208333, 0.68333333, 0.70833333, 0.69375   , 0.69583333,\n",
              "        0.69583333, 0.68125   , 0.71666667, 0.68958333, 0.69791667,\n",
              "        0.65416667, 0.69583333, 0.68541667, 0.70416667, 0.7       ,\n",
              "        0.66666667, 0.66875   , 0.69791667, 0.68958333, 0.69791667,\n",
              "        0.71666667, 0.70416667, 0.71666667, 0.7       , 0.6875    ,\n",
              "        0.68333333, 0.69791667, 0.70416667, 0.71458333, 0.70625   ,\n",
              "        0.6625    , 0.68541667, 0.67916667, 0.68541667, 0.70833333,\n",
              "        0.67708333, 0.72291667, 0.72083333, 0.6875    , 0.70416667,\n",
              "        0.6625    , 0.65625   , 0.67916667, 0.68125   , 0.69166667,\n",
              "        0.68125   , 0.70416667, 0.67916667, 0.69375   , 0.69583333,\n",
              "        0.64375   , 0.69375   , 0.67916667, 0.68333333, 0.69791667,\n",
              "        0.64791667, 0.66875   , 0.67708333, 0.68125   , 0.67916667,\n",
              "        0.6875    , 0.67291667, 0.69583333, 0.71041667, 0.68541667,\n",
              "        0.68125   , 0.67291667, 0.68958333, 0.70625   , 0.69375   ,\n",
              "        0.67708333, 0.68958333, 0.67708333, 0.69375   , 0.69166667,\n",
              "        0.65416667, 0.65      , 0.67708333, 0.6875    , 0.71666667,\n",
              "        0.67708333, 0.68958333, 0.68958333, 0.70833333, 0.71458333,\n",
              "        0.68541667, 0.6375    , 0.70208333, 0.70416667, 0.69375   ,\n",
              "        0.67291667, 0.68125   , 0.69375   , 0.68125   , 0.69375   ,\n",
              "        0.67708333, 0.71041667, 0.69791667, 0.68541667, 0.69583333,\n",
              "        0.725     , 0.68541667, 0.6875    , 0.69583333, 0.68333333,\n",
              "        0.68541667, 0.69583333, 0.70416667, 0.69375   , 0.68958333,\n",
              "        0.65416667, 0.64791667, 0.69375   , 0.68958333, 0.6875    ,\n",
              "        0.71666667, 0.67291667, 0.68333333, 0.70625   , 0.7       ,\n",
              "        0.68541667, 0.6875    , 0.70625   , 0.69375   , 0.70416667,\n",
              "        0.68541667, 0.68333333, 0.6875    , 0.69375   , 0.7       ,\n",
              "        0.65416667, 0.68958333, 0.6625    , 0.68125   , 0.66666667,\n",
              "        0.65625   , 0.70416667, 0.69791667, 0.69583333, 0.68958333,\n",
              "        0.68541667, 0.66458333, 0.69166667, 0.70208333, 0.6875    ,\n",
              "        0.67916667, 0.68541667, 0.68541667, 0.69166667, 0.68958333,\n",
              "        0.6875    , 0.70208333, 0.69166667, 0.69791667, 0.70416667,\n",
              "        0.67291667, 0.69166667, 0.69166667, 0.69791667, 0.68541667,\n",
              "        0.65416667, 0.69166667, 0.69791667, 0.67916667, 0.69166667,\n",
              "        0.67083333, 0.69166667, 0.67708333, 0.71041667, 0.6875    ,\n",
              "        0.65833333, 0.67916667, 0.69791667, 0.68958333, 0.69583333,\n",
              "        0.69166667, 0.7       , 0.6875    , 0.69375   , 0.71041667,\n",
              "        0.6875    , 0.69375   , 0.70208333, 0.68541667, 0.70208333,\n",
              "        0.69375   , 0.6875    , 0.68541667, 0.70208333, 0.69791667,\n",
              "        0.69166667, 0.68125   , 0.68958333, 0.68541667, 0.7       ,\n",
              "        0.66458333, 0.67916667, 0.69583333, 0.69166667, 0.7       ,\n",
              "        0.69375   , 0.67083333, 0.675     , 0.67083333, 0.69375   ,\n",
              "        0.67708333, 0.65      , 0.69791667, 0.69375   , 0.69375   ,\n",
              "        0.63541667, 0.66041667, 0.67291667, 0.675     , 0.6875    ,\n",
              "        0.67916667, 0.67708333, 0.69583333, 0.69583333, 0.68958333,\n",
              "        0.68958333, 0.69791667, 0.67291667, 0.67291667, 0.70208333,\n",
              "        0.6375    , 0.69166667, 0.68125   , 0.71458333, 0.69166667,\n",
              "        0.66666667, 0.68958333, 0.68541667, 0.69375   , 0.69375   ,\n",
              "        0.67916667, 0.68125   , 0.68541667, 0.69166667, 0.67916667,\n",
              "        0.65833333, 0.68125   , 0.70833333, 0.70208333, 0.69791667,\n",
              "        0.67083333, 0.70208333, 0.68333333, 0.67916667, 0.69375   ,\n",
              "        0.7       , 0.70208333, 0.69166667, 0.70833333, 0.7       ,\n",
              "        0.675     , 0.69375   , 0.67708333, 0.70416667, 0.70208333,\n",
              "        0.70208333, 0.675     , 0.69583333, 0.68125   , 0.69791667,\n",
              "        0.71666667, 0.67291667, 0.72916667, 0.70416667, 0.70416667,\n",
              "        0.67916667, 0.69583333, 0.6875    , 0.7       , 0.67916667,\n",
              "        0.68333333, 0.66875   , 0.68541667, 0.675     , 0.67708333,\n",
              "        0.65      , 0.6875    , 0.69375   , 0.6625    , 0.68958333,\n",
              "        0.7       , 0.6625    , 0.68333333, 0.69166667, 0.69791667,\n",
              "        0.63125   , 0.7       , 0.675     , 0.675     , 0.675     ,\n",
              "        0.6875    , 0.68541667, 0.66875   , 0.67916667, 0.67291667,\n",
              "        0.66458333, 0.70833333, 0.67083333, 0.69583333, 0.6875    ,\n",
              "        0.67291667, 0.675     , 0.71458333, 0.68333333, 0.69791667,\n",
              "        0.65416667, 0.73333333, 0.71041667, 0.69166667, 0.69166667,\n",
              "        0.69166667, 0.67291667, 0.68958333, 0.70208333, 0.70208333,\n",
              "        0.67708333, 0.7       , 0.6875    , 0.68958333, 0.69375   ,\n",
              "        0.68333333, 0.70625   , 0.69791667, 0.70208333, 0.69166667,\n",
              "        0.67916667, 0.68958333, 0.69583333, 0.69791667, 0.68333333,\n",
              "        0.68541667, 0.68958333, 0.68958333, 0.69166667, 0.68541667,\n",
              "        0.67083333, 0.6875    , 0.7       , 0.66666667, 0.69583333,\n",
              "        0.7125    , 0.6875    , 0.68541667, 0.675     , 0.67708333,\n",
              "        0.66666667, 0.70833333, 0.6875    , 0.66875   , 0.68958333,\n",
              "        0.68125   , 0.67916667, 0.71875   , 0.70625   , 0.68958333,\n",
              "        0.70416667, 0.6875    , 0.68958333, 0.6875    , 0.675     ,\n",
              "        0.68958333, 0.66875   , 0.70625   , 0.68125   , 0.7125    ,\n",
              "        0.62291667, 0.69375   , 0.66666667, 0.67083333, 0.68125   ,\n",
              "        0.66875   , 0.71041667, 0.69791667, 0.68541667, 0.66875   ,\n",
              "        0.67083333, 0.67916667, 0.67916667, 0.69166667, 0.69166667,\n",
              "        0.68541667, 0.69791667, 0.69166667, 0.69375   , 0.69375   ,\n",
              "        0.69375   , 0.70416667, 0.70416667, 0.70208333, 0.68958333,\n",
              "        0.68125   , 0.69166667, 0.69375   , 0.6875    , 0.69166667,\n",
              "        0.66041667, 0.69583333, 0.68958333, 0.67916667, 0.68541667,\n",
              "        0.725     , 0.69375   , 0.69791667, 0.70416667, 0.68541667,\n",
              "        0.69375   , 0.70833333, 0.67916667, 0.69791667, 0.69166667,\n",
              "        0.66666667, 0.68125   , 0.70416667, 0.675     , 0.68333333,\n",
              "        0.66458333, 0.69791667, 0.69375   , 0.70625   , 0.68958333,\n",
              "        0.71041667, 0.67291667, 0.6625    , 0.68333333, 0.69375   ,\n",
              "        0.66041667, 0.69375   , 0.68958333, 0.7       , 0.70208333,\n",
              "        0.66666667, 0.67291667, 0.68958333, 0.70833333, 0.69583333,\n",
              "        0.65416667, 0.69375   , 0.71666667, 0.68125   , 0.67708333,\n",
              "        0.7       , 0.7125    , 0.70208333, 0.69166667, 0.6875    ,\n",
              "        0.66875   , 0.68333333, 0.69166667, 0.69375   , 0.68125   ,\n",
              "        0.69375   , 0.6875    , 0.7       , 0.68333333, 0.69166667,\n",
              "        0.67291667, 0.68125   , 0.68125   , 0.68333333, 0.69375   ,\n",
              "        0.65833333, 0.70416667, 0.69375   , 0.7       , 0.68958333,\n",
              "        0.68958333, 0.68958333, 0.69583333, 0.69583333, 0.68958333,\n",
              "        0.675     , 0.66666667, 0.69375   , 0.68333333, 0.6875    ,\n",
              "        0.71041667, 0.68333333, 0.70625   , 0.70625   , 0.69583333,\n",
              "        0.6875    , 0.67708333, 0.69791667, 0.6875    , 0.69583333,\n",
              "        0.65      , 0.69166667, 0.6875    , 0.67083333, 0.68333333,\n",
              "        0.65625   , 0.6875    , 0.69791667, 0.68958333, 0.69583333,\n",
              "        0.68125   , 0.66041667, 0.68541667, 0.67291667, 0.70416667,\n",
              "        0.7       , 0.7       , 0.69166667, 0.71041667, 0.69166667,\n",
              "        0.67708333, 0.69791667, 0.68541667, 0.71666667, 0.68541667,\n",
              "        0.69166667, 0.71041667, 0.69583333, 0.6875    , 0.69375   ,\n",
              "        0.70208333, 0.67291667, 0.7       , 0.6875    , 0.7       ,\n",
              "        0.70833333, 0.68958333, 0.72708333, 0.69166667, 0.68958333,\n",
              "        0.65625   , 0.65208333, 0.67916667, 0.67916667, 0.68958333,\n",
              "        0.66875   , 0.66875   , 0.68541667, 0.69166667, 0.68333333,\n",
              "        0.6625    , 0.7       , 0.70416667, 0.69583333, 0.69166667,\n",
              "        0.66041667, 0.70416667, 0.67291667, 0.69791667, 0.69583333,\n",
              "        0.70833333, 0.67083333, 0.70208333, 0.7       , 0.68333333,\n",
              "        0.675     , 0.68958333, 0.70208333, 0.69375   , 0.69583333,\n",
              "        0.66458333, 0.7125    , 0.69375   , 0.69791667, 0.68958333,\n",
              "        0.69375   , 0.6625    , 0.67083333, 0.69791667, 0.69791667,\n",
              "        0.69166667, 0.69166667, 0.69583333, 0.69583333, 0.69166667,\n",
              "        0.68958333, 0.67708333, 0.67916667, 0.69583333, 0.6875    ,\n",
              "        0.68333333, 0.67708333, 0.675     , 0.69166667, 0.69375   ,\n",
              "        0.67083333, 0.69791667, 0.70833333, 0.69375   , 0.69166667,\n",
              "        0.675     , 0.6875    , 0.70833333, 0.69791667, 0.69166667,\n",
              "        0.65208333, 0.66458333, 0.6875    , 0.68541667, 0.68958333,\n",
              "        0.68125   , 0.71041667, 0.67291667, 0.69166667, 0.68541667,\n",
              "        0.68333333, 0.70208333, 0.70833333, 0.69375   , 0.69375   ]),\n",
              " 'std_test_score': array([0.02019867, 0.02763854, 0.04389856, 0.05965759, 0.06305311,\n",
              "        0.02684187, 0.02946278, 0.02763854, 0.04299952, 0.03320287,\n",
              "        0.04956407, 0.04991312, 0.04135299, 0.03644345, 0.04419417,\n",
              "        0.03864008, 0.03510896, 0.01792151, 0.04218428, 0.04028975,\n",
              "        0.03930825, 0.03159531, 0.02916667, 0.05212498, 0.04269563,\n",
              "        0.06130808, 0.03632416, 0.05392575, 0.05432669, 0.04439016,\n",
              "        0.01932004, 0.03267581, 0.03547789, 0.03523236, 0.03632416,\n",
              "        0.04535738, 0.05043216, 0.03254271, 0.05204165, 0.06387379,\n",
              "        0.05368374, 0.03510896, 0.04238956, 0.0477806 , 0.0601647 ,\n",
              "        0.04007372, 0.04135299, 0.04007372, 0.02825971, 0.05551214,\n",
              "        0.04135299, 0.05376453, 0.04439016, 0.05605677, 0.05432669,\n",
              "        0.04912428, 0.04061164, 0.03875224, 0.03930825, 0.04991312,\n",
              "        0.05128556, 0.02319902, 0.03632416, 0.05245699, 0.04320092,\n",
              "        0.06588078, 0.03200477, 0.02975595, 0.02716334, 0.04299952,\n",
              "        0.06705615, 0.05743354, 0.03691676, 0.05043216, 0.02763854,\n",
              "        0.04868051, 0.02763854, 0.05566829, 0.04039733, 0.04187448,\n",
              "        0.03047654, 0.04823265, 0.03572173, 0.06640574, 0.04516559,\n",
              "        0.04768968, 0.03864008, 0.04218428, 0.02602082, 0.06366961,\n",
              "        0.04007372, 0.03333333, 0.04238956, 0.02585349, 0.04238956,\n",
              "        0.05613414, 0.04299952, 0.02319902, 0.05644257, 0.04686342,\n",
              "        0.03294039, 0.02748105, 0.02946278, 0.05613414, 0.02763854,\n",
              "        0.05448624, 0.041978  , 0.03159531, 0.0186339 , 0.03807431,\n",
              "        0.02871677, 0.03385016, 0.03807431, 0.04611655, 0.03397814,\n",
              "        0.05368374, 0.00779512, 0.03131937, 0.02684187, 0.05128556,\n",
              "        0.04823265, 0.02841288, 0.0477806 , 0.04639804, 0.05376453,\n",
              "        0.02551552, 0.05758448, 0.05628857, 0.05034602, 0.04135299,\n",
              "        0.03875224, 0.05605677, 0.01473139, 0.04289846, 0.03985651,\n",
              "        0.0743607 , 0.05077524, 0.03584302, 0.05      , 0.05796012,\n",
              "        0.06763618, 0.03974747, 0.01412985, 0.04991312, 0.04658475,\n",
              "        0.06298424, 0.03200477, 0.05416667, 0.0463044 , 0.04903584,\n",
              "        0.02748105, 0.04930066, 0.0344853 , 0.03985651, 0.041978  ,\n",
              "        0.05162297, 0.00833333, 0.06319063, 0.05376453, 0.03320287,\n",
              "        0.06501869, 0.0344853 , 0.04823265, 0.05416667, 0.0488585 ,\n",
              "        0.03784563, 0.04039733, 0.04007372, 0.04439016, 0.04859127,\n",
              "        0.06159061, 0.06568284, 0.05212498, 0.04592793, 0.04611655,\n",
              "        0.04028975, 0.04583333, 0.04583333, 0.04823265, 0.04135299,\n",
              "        0.03159531, 0.02144923, 0.06737901, 0.03423266, 0.05043216,\n",
              "        0.05335937, 0.02041241, 0.04249183, 0.04419417, 0.03632416,\n",
              "        0.03807431, 0.02916667, 0.06144951, 0.04187448, 0.03875224,\n",
              "        0.02517301, 0.05496211, 0.04007372, 0.04340139, 0.05229125,\n",
              "        0.07944032, 0.02585349, 0.0497389 , 0.04340139, 0.04859127,\n",
              "        0.03930825, 0.03632416, 0.02795085, 0.06130808, 0.03807431,\n",
              "        0.03784563, 0.03761556, 0.05914612, 0.03919768, 0.04399732,\n",
              "        0.041978  , 0.05392575, 0.03691676, 0.041978  , 0.0535218 ,\n",
              "        0.04093101, 0.03061862, 0.05720638, 0.04289846, 0.04340139,\n",
              "        0.05720638, 0.03118048, 0.03510896, 0.05416667, 0.05162297,\n",
              "        0.05376453, 0.03703414, 0.04947643, 0.04399732, 0.03397814,\n",
              "        0.0488585 , 0.06236096, 0.04166667, 0.04732424, 0.03761556,\n",
              "        0.04007372, 0.05043216, 0.03523236, 0.0375    , 0.04564355,\n",
              "        0.0669914 , 0.03841477, 0.05077524, 0.06501869, 0.04340139,\n",
              "        0.04187448, 0.05017331, 0.03930825, 0.04350128, 0.05335937,\n",
              "        0.03632416, 0.04350128, 0.041978  , 0.04497299, 0.04299952,\n",
              "        0.05311479, 0.04859127, 0.03919768, 0.03761556, 0.03875224,\n",
              "        0.04535738, 0.02517301, 0.04487637, 0.05170697, 0.0463044 ,\n",
              "        0.05980292, 0.04039733, 0.0488585 , 0.05651942, 0.04114254,\n",
              "        0.06865524, 0.01559024, 0.06407732, 0.03385016, 0.04093101,\n",
              "        0.04028975, 0.06270799, 0.04299952, 0.04611655, 0.03047654,\n",
              "        0.05605677, 0.01692508, 0.03159531, 0.04399732, 0.02990146,\n",
              "        0.03761556, 0.05120086, 0.03047654, 0.04350128, 0.04419417,\n",
              "        0.01792151, 0.04639804, 0.04269563, 0.04350128, 0.03061862,\n",
              "        0.02319902, 0.04768968, 0.04930066, 0.02585349, 0.04535738,\n",
              "        0.07643307, 0.06666667, 0.04583333, 0.03320287, 0.0389756 ,\n",
              "        0.05803495, 0.03090083, 0.0477806 , 0.04249183, 0.0344853 ,\n",
              "        0.04947643, 0.06640574, 0.06201198, 0.02517301, 0.05060399,\n",
              "        0.05987545, 0.06984606, 0.06601241, 0.05408648, 0.04289846,\n",
              "        0.05781015, 0.04487637, 0.0344853 , 0.05408648, 0.04592793,\n",
              "        0.02585349, 0.02946278, 0.03523236, 0.03864008, 0.04370037,\n",
              "        0.04448783, 0.03186887, 0.04823265, 0.01932004, 0.04796194,\n",
              "        0.04340139, 0.04299952, 0.05408648, 0.04399732, 0.05212498,\n",
              "        0.03644345, 0.02602082, 0.03320287, 0.05416667, 0.02841288,\n",
              "        0.03952847, 0.01792151, 0.06002025, 0.02019867, 0.0529511 ,\n",
              "        0.03818813, 0.02901748, 0.03090083, 0.060596  , 0.02990146,\n",
              "        0.03118048, 0.05120086, 0.05720638, 0.0389756 , 0.03200477,\n",
              "        0.02019867, 0.02124591, 0.02585349, 0.06130808, 0.0375    ,\n",
              "        0.03523236, 0.03294039, 0.03118048, 0.03294039, 0.05796012,\n",
              "        0.03131937, 0.04611655, 0.0463044 , 0.05488308, 0.03019037,\n",
              "        0.05892557, 0.02946278, 0.01976424, 0.02411633, 0.04289846,\n",
              "        0.03267581, 0.04135299, 0.03423266, 0.02825971, 0.03118048,\n",
              "        0.03761556, 0.07034143, 0.03632416, 0.02185018, 0.02411633,\n",
              "        0.04389856, 0.05408648, 0.03320287, 0.05535554, 0.03703414,\n",
              "        0.05120086, 0.03761556, 0.05472469, 0.04732424, 0.04732424,\n",
              "        0.04903584, 0.05245699, 0.03294039, 0.04238956, 0.04535738,\n",
              "        0.05212498, 0.04187448, 0.04187448, 0.05128556, 0.0529511 ,\n",
              "        0.06298424, 0.04516559, 0.04093101, 0.04039733, 0.03818813,\n",
              "        0.05043216, 0.03061862, 0.05212498, 0.03523236, 0.05408648,\n",
              "        0.03131937, 0.04093101, 0.03200477, 0.0497389 , 0.03523236,\n",
              "        0.06607813, 0.05077524, 0.05605677, 0.04028975, 0.04389856,\n",
              "        0.041978  , 0.00833333, 0.04166667, 0.03930825, 0.04389856,\n",
              "        0.05128556, 0.0372678 , 0.04135299, 0.04796194, 0.05651942,\n",
              "        0.0372678 , 0.06475113, 0.04497299, 0.03572173, 0.03267581,\n",
              "        0.03807431, 0.04320092, 0.03584302, 0.03807431, 0.04028975,\n",
              "        0.03864008, 0.03333333, 0.04093101, 0.03523236, 0.04912428,\n",
              "        0.02243819, 0.04448783, 0.02585349, 0.02748105, 0.05803495,\n",
              "        0.04419417, 0.06407732, 0.04187448, 0.03784563, 0.04028975,\n",
              "        0.05204165, 0.05376453, 0.03186887, 0.05      , 0.03784563,\n",
              "        0.05644257, 0.02990146, 0.03131937, 0.04686342, 0.04704829,\n",
              "        0.04238956, 0.06095308, 0.06990817, 0.03333333, 0.04497299,\n",
              "        0.03523236, 0.0497389 , 0.04859127, 0.05456584, 0.04823265,\n",
              "        0.05803495, 0.0529511 , 0.04545297, 0.04912428, 0.05      ,\n",
              "        0.05034602, 0.03584302, 0.03761556, 0.03118048, 0.04439016,\n",
              "        0.04723243, 0.05034602, 0.04135299, 0.03919768, 0.05204165,\n",
              "        0.04187448, 0.03952847, 0.03267581, 0.04299952, 0.04218428,\n",
              "        0.04439016, 0.06270799, 0.02975595, 0.03919768, 0.05796012,\n",
              "        0.0389756 , 0.04750731, 0.03547789, 0.04061164, 0.05682576,\n",
              "        0.06802012, 0.04093101, 0.04320092, 0.0477806 , 0.04039733,\n",
              "        0.06353313, 0.03294039, 0.04061164, 0.01530931, 0.04903584,\n",
              "        0.03985651, 0.04299952, 0.0463044 , 0.0529511 , 0.02429563,\n",
              "        0.02825971, 0.03254271, 0.02990146, 0.05327797, 0.03584302,\n",
              "        0.04704829, 0.03486083, 0.0463044 , 0.03691676, 0.06731456,\n",
              "        0.07174656, 0.05034602, 0.06123724, 0.05667279, 0.04912428,\n",
              "        0.04686342, 0.041978  , 0.03807431, 0.04218428, 0.04340139,\n",
              "        0.06073908, 0.04439016, 0.03320287, 0.02990146, 0.04814258,\n",
              "        0.04370037, 0.02684187, 0.03047654, 0.04814258, 0.0463044 ,\n",
              "        0.04439016, 0.0590727 , 0.03691676, 0.01816208, 0.03131937,\n",
              "        0.01816208, 0.03807431, 0.0557462 , 0.04187448, 0.04399732,\n",
              "        0.03267581, 0.03818813, 0.05335937, 0.04611655, 0.04135299,\n",
              "        0.06002025, 0.05456584, 0.03200477, 0.04340139, 0.04039733,\n",
              "        0.02901748, 0.04947643, 0.04399732, 0.06770032, 0.05162297,\n",
              "        0.05245699, 0.02990146, 0.04399732, 0.05781015, 0.04535738,\n",
              "        0.06673174, 0.03397814, 0.03131937, 0.04516559, 0.05432669,\n",
              "        0.02684187, 0.06166104, 0.03186887, 0.02748105, 0.02990146,\n",
              "        0.02667968, 0.02185018, 0.04439016, 0.04340139, 0.05060399,\n",
              "        0.02990146, 0.04166667, 0.03864008, 0.02517301, 0.04145781,\n",
              "        0.03333333, 0.03668087, 0.03608439, 0.0529511 , 0.02602082,\n",
              "        0.07523113, 0.02716334, 0.04930066, 0.02946278, 0.04039733,\n",
              "        0.05      , 0.03572173, 0.04061164, 0.03807431, 0.05034602,\n",
              "        0.03644345, 0.02124591, 0.04448783, 0.04545297, 0.03572173,\n",
              "        0.02684187, 0.04093101, 0.05743354, 0.02517301, 0.04639804]),\n",
              " 'rank_test_score': array([639, 560, 572, 357, 257, 557, 357, 425, 538, 475, 627, 392,  25,\n",
              "        257, 387, 520, 184, 111, 357, 318, 257,  43, 245,  89,  37, 452,\n",
              "        111, 135, 135, 318,  89, 425,  43, 212, 184, 184, 452,  15, 318,\n",
              "        159, 618, 184, 414,  63, 111, 590, 572, 159, 303, 135,   9,  78,\n",
              "         15, 111, 357, 449, 135,  64,  17,  53, 598, 414, 492, 414,  43,\n",
              "        509,   6,   7, 357,  64, 598, 615, 475, 452, 257, 466,  64, 492,\n",
              "        212, 184, 634, 212, 492, 425, 135, 632, 572, 509, 466, 492, 357,\n",
              "        538, 184,  26, 414, 466, 538, 346,  53, 212, 501, 318, 509, 204,\n",
              "        257, 618, 627, 509, 357,   9, 501, 318, 303,  37,  17, 390, 635,\n",
              "         89,  78, 212, 538, 466, 212, 452, 212, 509,  26, 159, 392, 171,\n",
              "          5, 392, 357, 171, 425, 392, 171,  64, 204, 303, 624, 633, 212,\n",
              "        303, 357,   9, 538, 425,  53, 111, 414, 357,  53, 245,  78, 392,\n",
              "        425, 357, 204, 111, 618, 318, 598, 452, 590, 614,  64, 159, 171,\n",
              "        318, 392, 592, 257,  89, 357, 475, 390, 414, 257, 303, 357,  85,\n",
              "        257, 159,  78, 538, 257, 257, 159, 414, 618, 257, 135, 475, 257,\n",
              "        560, 257, 501,  26, 348, 611, 475, 135, 318, 171, 257, 111, 348,\n",
              "        212,  34, 387, 212,  89, 414,  89, 245, 357, 392,  89, 159, 257,\n",
              "        450, 303, 392, 111, 592, 475, 184, 257, 111, 204, 560, 535, 560,\n",
              "        212, 501, 627, 159, 204, 212, 637, 606, 538, 535, 348, 475, 501,\n",
              "        171, 184, 318, 318, 135, 538, 537,  89, 635, 257, 452,  17, 257,\n",
              "        583, 318, 392, 212, 212, 492, 452, 392, 254, 475, 611, 452,  37,\n",
              "         85, 159, 560,  89, 425, 475, 212, 111,  85, 257,  43, 111, 520,\n",
              "        245, 509,  64,  89,  89, 520, 171, 452, 135,   9, 551,   2,  64,\n",
              "         78, 492, 184, 357, 111, 475, 425, 572, 392, 520, 509, 627, 348,\n",
              "        212, 598, 346, 109, 598, 425, 257, 135, 638, 111, 520, 520, 520,\n",
              "        357, 392, 572, 475, 551, 595,  43, 560, 184, 357, 551, 520,  17,\n",
              "        425, 135, 618,   1,  26, 257, 257, 257, 538, 318, 108,  85, 501,\n",
              "        111, 357, 318, 212, 425,  53, 135,  89, 257, 475, 303, 203, 135,\n",
              "        425, 414, 318, 303, 257, 414, 557, 348, 111, 583, 184,  21, 357,\n",
              "        392, 520, 501, 583,  43, 387, 572, 318, 466, 475,   8,  53, 318,\n",
              "         64, 348, 303, 357, 520, 303, 572,  53, 452,  21, 640, 212, 583,\n",
              "        560, 466, 572,  34, 159, 392, 571, 560, 475, 475, 257, 254, 392,\n",
              "        135, 257, 204, 245, 212,  64,  64,  89, 318, 466, 257, 212, 348,\n",
              "        254, 606, 171, 303, 475, 392,   4, 212, 159,  64, 392, 245,  43,\n",
              "        492, 135, 257, 583, 466,  78, 520, 425, 595, 135, 212,  53, 318,\n",
              "         26, 551, 598, 425, 212, 606, 204, 303, 111,  89, 583, 551, 318,\n",
              "         37, 184, 618, 204,   9, 452, 509, 111,  21,  89, 257, 348, 572,\n",
              "        425, 257, 245, 452, 212, 348, 111, 425, 257, 538, 452, 452, 425,\n",
              "        212, 611,  64, 212, 111, 318, 303, 318, 171, 171, 318, 520, 583,\n",
              "        245, 425, 357,  34, 425,  62,  53, 184, 357, 509, 135, 357, 184,\n",
              "        627, 257, 357, 570, 425, 617, 357, 135, 318, 184, 466, 606, 392,\n",
              "        551,  64, 111, 111, 257,  26, 257, 509, 135, 392,   9, 392, 257,\n",
              "         26, 184, 357, 212,  89, 538, 109, 357, 111,  37, 318,   3, 257,\n",
              "        303, 615, 625, 475, 492, 318, 572, 572, 392, 257, 425, 598, 111,\n",
              "         64, 184, 257, 606,  78, 538, 135, 171,  43, 560,  89, 111, 425,\n",
              "        520, 303,  89, 245, 184, 592,  21, 212, 135, 318, 212, 598, 557,\n",
              "        135, 135, 257, 257, 171, 171, 257, 318, 509, 492, 184, 357, 425,\n",
              "        501, 520, 257, 212, 560, 159,  43, 212, 257, 520, 357,  43, 135,\n",
              "        257, 625, 595, 357, 392, 318, 450,  26, 538, 257, 414, 425,  89,\n",
              "         37, 212, 212], dtype=int32)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMstuJy4mp8J"
      },
      "source": [
        "**Melhores parâmetros**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psp5vHV6mp8K",
        "outputId": "c91330c7-b5b3-4aba-b708-fb4d4d856f3c"
      },
      "source": [
        "grid.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'entropy',\n",
              " 'max_depth': 10,\n",
              " 'min_samples_leaf': 5,\n",
              " 'min_samples_split': 2,\n",
              " 'n_estimators': 20}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1ILIPHkmp8O"
      },
      "source": [
        "**Melhores scores**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-e1t9eSBmp8P",
        "outputId": "db867799-e116-4d8b-aa5c-0db088d39bfc"
      },
      "source": [
        "grid.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7333333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-saCeuJ8nUGI"
      },
      "source": [
        "# Obrigado!\n",
        "\n",
        "Obrigado por ter disponibilizado um pouco do seu tempo e atenção aqui. Espero que, de alguma forma, tenha sido útil para seu crescimento. Se houver qualquer dúvida ou sugestão, não hesite em entrar em contato no [LinkedIn](https://www.linkedin.com/in/daniel-sousa-amador) e verificar meus outros projetos no [GitHub](https://github.com/amadords).\n",
        "\n",
        "[![LinkedIn](https://img.shields.io/badge/LinkedIn-DanielSousaAmador-purple.svg)](https://www.linkedin.com/in/daniel-sousa-amador)\n",
        "[![GitHub](https://img.shields.io/badge/GitHub-amadords-darkblue.svg)](https://github.com/amadords)\n",
        "[![Medium](https://img.shields.io/badge/Medium-DanielSousaAmador-darkorange.svg)](https://medium.com/@daniel.s.amador)\n",
        "\n",
        "\n",
        "\n",
        "<center><img width=\"90%\" src=\"https://raw.githubusercontent.com/danielamador12/Portfolio/master/github.png\"></center>"
      ]
    }
  ]
}