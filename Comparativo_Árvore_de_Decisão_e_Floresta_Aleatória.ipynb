{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Comparativo - Árvore de Decisão e Floresta Aleatória",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amadords/Projetos-Publicos/blob/master/Comparativo_%C3%81rvore_de_Decis%C3%A3o_e_Floresta_Aleat%C3%B3ria.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-VjrUThmp6E"
      },
      "source": [
        "# **Então... Árvore ou Floresta?**\n",
        "---\n",
        "\n",
        "\n",
        "[![LinkedIn](https://img.shields.io/badge/LinkedIn-DanielSousaAmador-cyan.svg)](https://www.linkedin.com/in/daniel-sousa-amador)\n",
        "[![GitHub](https://img.shields.io/badge/GitHub-amadords-darkblue.svg)](https://github.com/amadords)\n",
        "[![Medium](https://img.shields.io/badge/Medium-DanielSousaAmador-white.svg)](https://daniel-s-amador.medium.com/)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Se você leu sobre as **[Árvores](https://bit.ly/2Guqmcd)** e **[Florestas](https://bit.ly/2Sg9LM7)** deve ter ficado tentado a utilizar sempre o *Random Forest*, pois é uma melhoria das Árvores e, via de regra, evita mais facilmente problemas como o *sobreajuste*.\n",
        "\n",
        "Geralmente, sim! o *Random Forest* vai se sair melhor, pois ele vai ter um pouco mais de maleabilidade, já que cria várias árvores, contudo nem sempre as árvores se sairão piores. \n",
        "\n",
        "Veja, quando estudantes aprendem técnicas de **Deep Learning** (Aprendizagem Profunda) é comum querer utilizar em tudo, até em problemas que o mais simples dos algoritmos (algoritmos lineares) podem resolver, então muitas vezes as árvores podem já resolver o problema, principalmente porque serve, muitas vezes, de *baseline*, ou seja, serve como ponto de partida o qual os algoritmos devem tentar minimamente ultrapassar seu resultado final. \n",
        "\n",
        "Muitas vezes você irá querer somente *extrair regras* e/ou tentar buscar quais são as *features mais importantes* para o seu modelo e, nesses casos, *normalmente é melhor utilizar Árvore*, pois as florestas irão criar várias árvores, com várias regras diferentes e, caso você necessite somente desse suporte, talvez seja melhor utilizar a Árvore.\n",
        "\n",
        "**Dica**: Comece sempre pela *Árvore*, depois utilize também as *Florestas*, mas não comece diretamente pelas Florestas. Isso é apenas um *conselho* e *boa prática*.\n",
        "\n",
        "![comparativo](https://image.freepik.com/fotos-gratis/boxe-profissional-dois-boxe-no-espaco-preto-esfumacado_155003-12726.jpg)\n",
        "\n",
        "## O que faremos aqui?\n",
        "\n",
        "**Comparativo** entre os dois algoritmos!\n",
        "\n",
        "Já adianto que, o *Random Forest* se sairá melhor no exemplo abaixo, contudo, como dito acima, nem sempre isso acontece e cabe ao **Cientista de Dados** avaliar **SEMPRE** os resultados, inclusive fazendo **Tuning** do modelo.\n",
        "\n",
        "## Tuning?\n",
        "\n",
        "Calma, vamos fazer os comparativos e, quando chegarmos nele eu te explico, mas tuning é basicamente alterar os parâmetros do algoritmo para tentar melhorá-lo!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fmAJWZpmp6H"
      },
      "source": [
        "## Checklist\n",
        "1. Leitura e Preparação de Dados\n",
        "2. Random Forest\n",
        "3. Decision Tree\n",
        "4. Verificando Overfitting\n",
        "5. Tuning do Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFB7Twhnmp6K"
      },
      "source": [
        "**Importação das bibliotecas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5SdwJbVmp6M"
      },
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmtMzXtcmp6X"
      },
      "source": [
        "# 1. Leitura e Preparação de Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nQnUS9Qmp6Z"
      },
      "source": [
        "**Leitura dos dados**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xK5kqiosmp6a"
      },
      "source": [
        "df_edu = pd.read_csv('https://raw.githubusercontent.com/amadords/data/main/xAPI-Edu-Data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "B0czeHuump6f",
        "outputId": "b0973382-0d3f-4e73-c70f-33fc2c4247b4"
      },
      "source": [
        "df_edu.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>NationalITy</th>\n",
              "      <th>PlaceofBirth</th>\n",
              "      <th>StageID</th>\n",
              "      <th>GradeID</th>\n",
              "      <th>SectionID</th>\n",
              "      <th>Topic</th>\n",
              "      <th>Semester</th>\n",
              "      <th>Relation</th>\n",
              "      <th>raisedhands</th>\n",
              "      <th>VisITedResources</th>\n",
              "      <th>AnnouncementsView</th>\n",
              "      <th>Discussion</th>\n",
              "      <th>ParentAnsweringSurvey</th>\n",
              "      <th>ParentschoolSatisfaction</th>\n",
              "      <th>StudentAbsenceDays</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>KW</td>\n",
              "      <td>KuwaIT</td>\n",
              "      <td>lowerlevel</td>\n",
              "      <td>G-04</td>\n",
              "      <td>A</td>\n",
              "      <td>IT</td>\n",
              "      <td>F</td>\n",
              "      <td>Father</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Good</td>\n",
              "      <td>Under-7</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M</td>\n",
              "      <td>KW</td>\n",
              "      <td>KuwaIT</td>\n",
              "      <td>lowerlevel</td>\n",
              "      <td>G-04</td>\n",
              "      <td>A</td>\n",
              "      <td>IT</td>\n",
              "      <td>F</td>\n",
              "      <td>Father</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>25</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Good</td>\n",
              "      <td>Under-7</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>KW</td>\n",
              "      <td>KuwaIT</td>\n",
              "      <td>lowerlevel</td>\n",
              "      <td>G-04</td>\n",
              "      <td>A</td>\n",
              "      <td>IT</td>\n",
              "      <td>F</td>\n",
              "      <td>Father</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>No</td>\n",
              "      <td>Bad</td>\n",
              "      <td>Above-7</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  gender NationalITy  ... StudentAbsenceDays Class\n",
              "0      M          KW  ...            Under-7     M\n",
              "1      M          KW  ...            Under-7     M\n",
              "2      M          KW  ...            Above-7     L\n",
              "\n",
              "[3 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3SqKh8Qmp6n"
      },
      "source": [
        "**Verificando classes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FK0IImUBmp6o",
        "outputId": "24647798-a554-459f-cd5a-dae25128d565"
      },
      "source": [
        "df_edu['Class'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "M    211\n",
              "H    142\n",
              "L    127\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vP0Ro8agmp6u"
      },
      "source": [
        "**Verificando registros nulos**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckKDcUbFmp6v",
        "outputId": "f07d7f4c-cdca-4b4f-86d9-523419442444"
      },
      "source": [
        "df_edu.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gender                      0\n",
              "NationalITy                 0\n",
              "PlaceofBirth                0\n",
              "StageID                     0\n",
              "GradeID                     0\n",
              "SectionID                   0\n",
              "Topic                       0\n",
              "Semester                    0\n",
              "Relation                    0\n",
              "raisedhands                 0\n",
              "VisITedResources            0\n",
              "AnnouncementsView           0\n",
              "Discussion                  0\n",
              "ParentAnsweringSurvey       0\n",
              "ParentschoolSatisfaction    0\n",
              "StudentAbsenceDays          0\n",
              "Class                       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjOF86qhmp60"
      },
      "source": [
        "**Codificando os atributos numéricos**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0XuFrc3mp62"
      },
      "source": [
        "Features = df_edu\n",
        "Cat_Colums = Features.dtypes.pipe(lambda Features: Features[Features=='object']).index\n",
        "for col in Cat_Colums:\n",
        "    label = LabelEncoder()\n",
        "    Features[col] = label.fit_transform(Features[col])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7pXEws6mp66"
      },
      "source": [
        "**Separando dados**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-b4Gs2f0mp66"
      },
      "source": [
        "dataset = df_edu.drop('Class',axis=1)\n",
        "classes = df_edu['Class']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PiotRvFmp6_"
      },
      "source": [
        "# 2. Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8inhSsgamp6_"
      },
      "source": [
        "**Instanciando o classificador**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6d_cJKJmp7A"
      },
      "source": [
        "# random_state=1 para garantir o mesmo resultado em cada algoritmo (na separação dos dados)\n",
        "# n_estimator=100\n",
        "random_clf = RandomForestClassifier(random_state=1,n_estimators=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp_Rt0Hrmp7E"
      },
      "source": [
        "**Cross Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iq1XhSPYmp7F",
        "outputId": "bded870e-60fb-4009-8fe8-3c707f7e54ed"
      },
      "source": [
        "resultados_random = cross_val_predict(random_clf, dataset, classes, cv=5)\n",
        "print(classification_report(classes,resultados_random))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.64      0.65       142\n",
            "           1       0.77      0.78      0.77       127\n",
            "           2       0.63      0.63      0.63       211\n",
            "\n",
            "    accuracy                           0.67       480\n",
            "   macro avg       0.68      0.68      0.68       480\n",
            "weighted avg       0.67      0.67      0.67       480\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NhusOIimp7J"
      },
      "source": [
        "# 3. Decision Tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n92vHTRbmp7L"
      },
      "source": [
        "**Métricas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aT_THT8xmp7M",
        "scrolled": true,
        "outputId": "dc6324ef-d4ab-44ac-906a-2cc7088b3f81"
      },
      "source": [
        "tree_clf = DecisionTreeClassifier(random_state=1) # random_state=1 para garantir a mesma semente\n",
        "resultados_tree = cross_val_predict(tree_clf,dataset,classes,cv=5)\n",
        "print(classification_report(classes,resultados_tree))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.61      0.55       142\n",
            "           1       0.74      0.68      0.70       127\n",
            "           2       0.54      0.49      0.52       211\n",
            "\n",
            "    accuracy                           0.57       480\n",
            "   macro avg       0.59      0.59      0.59       480\n",
            "weighted avg       0.58      0.57      0.58       480\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idUwWdPZmp7Q"
      },
      "source": [
        "### Cross Validation?\n",
        "Ou **Validação Cruzada**...\n",
        "\n",
        "Sim! Em ambos algoritmos o utilizamos e ele serve para tentar avaliar a capacidade de um modelo em generalizar os dados e deve sempre ser usado em *modelagens preditavas*!\n",
        "\n",
        "O **cross validation** particiona, ou seja, divide um conjunto de dados em partes a ser definido pelo *Cientista de Dados* em conjuntos menores ou subconjuntos onde, nenhum dado está repetido em nenhum outro subconjunto e o algoritmo utilizará parte dos dados para treinar, parte para testar. \n",
        "\n",
        "Exemplo: Se o **K-fold**, ou seja, a quantidade de particionamento dos dados for igual a 5, o algoritmo fará 5 testes e retornará o resultado para cada um deles.\n",
        "* Teste 1: Treino com subconjuntos 1,2,3 e 4 e teste com o 5.\n",
        "* Teste 2:Treino com subconjuntos 2,3,4 e 5 e teste com o 1.\n",
        "* Teste 3: Treino com subconjuntos 1,3,4 e 5 e teste com o 2.\n",
        "* Teste 4: Treino com subconjuntos 1,2,4 e 5 e teste com o 3.\n",
        "* Teste 5:Treino com subconjuntos 1,2,3 e 5 e teste com o 4.\n",
        "\n",
        "Isso mostra um resultado mais fiel do algoritmo, para evitar mascaração de resultados para melhor ou para pior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVGipT3Amp7R"
      },
      "source": [
        "# 4. Verificando Overfitting\n",
        "\n",
        "Para verificar o overfitting, ou sobreajuste, iremos criar duas funções, uma para o *Random Forest* e outro para a *Decision Tree* que irão comparar vários modelos com o parâmetro **max_depth** e retornará a **acurárica** entre os dados de *treino* e *teste* e, assim vamos ver onde os modelos começam e terminam o sobreajuste."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMonxCiSmp7S"
      },
      "source": [
        "**Dividindo os dados**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC2E8Dmxmp7S"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_edu.drop('Class',axis=1),df_edu['Class'],test_size=0.3,random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sin8xXrQmp7W"
      },
      "source": [
        "**Criando função para comparar os modelos de random forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC03v6NBmp7X"
      },
      "source": [
        "def compara_modelos_random_forest(maxdepth):\n",
        "    if maxdepth == 0:\n",
        "        rf = RandomForestClassifier(n_estimators=100,random_state=1)\n",
        "    else: \n",
        "        rf = RandomForestClassifier(n_estimators=100,random_state=1, max_depth=maxdepth)\n",
        "    rf.fit(X_train, y_train)\n",
        "    train_score = rf.score(X_train, y_train)\n",
        "    test_score = rf.score(X_test, y_test)\n",
        "    return train_score,test_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrp-VGS0mp7b",
        "outputId": "632e64ea-5650-4cbd-e69d-754980d364b0"
      },
      "source": [
        "print('{:10} {:20} {:20}'.format('depth', 'Training score','Testing score'))\n",
        "print('{:10} {:20} {:20}'.format('-----', '--------------','-------------'))\n",
        "print('{:1}         {} '.format(2,str(compara_modelos_random_forest(2))))\n",
        "print('{:1}         {} '.format(3,str(compara_modelos_random_forest(3))))\n",
        "print('{:1}         {} '.format(4,str(compara_modelos_random_forest(4))))\n",
        "print('{:1}         {} '.format(10,str(compara_modelos_random_forest(10))))\n",
        "print('{:1}         {} '.format(15,str(compara_modelos_random_forest(15))))\n",
        "print('{:1}         {} '.format('Full',str(compara_modelos_random_forest(0))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "depth      Training score       Testing score       \n",
            "-----      --------------       -------------       \n",
            "2         (0.75, 0.6180555555555556) \n",
            "3         (0.8244047619047619, 0.6805555555555556) \n",
            "4         (0.8720238095238095, 0.7152777777777778) \n",
            "10         (1.0, 0.7569444444444444) \n",
            "15         (1.0, 0.7986111111111112) \n",
            "Full         (1.0, 0.7986111111111112) \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6QV9o7Mmp7f"
      },
      "source": [
        "A partir de **max_depth=10** já está totalmente enviesado, aparentemente o melhor resultado é com o valor **max_depth=3**, pois a diferença entre a acertividade de *treino* e *teste* é de aproximadamente **14%**, enquanto os demais passam disso, ou, no caso do **max_depth=2** que também está no mesmo valor, a acertividade está mais baixa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOniUEX1mp7g"
      },
      "source": [
        "**Criando função para comparar os modelos de decision tree**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-RFJ6Shmp7h"
      },
      "source": [
        "def compara_modelos_decision_tree(maxdepth):\n",
        "    if maxdepth == 0:\n",
        "        df = DecisionTreeClassifier(random_state=1)\n",
        "    else: \n",
        "        df = DecisionTreeClassifier(random_state=1, max_depth=maxdepth)\n",
        "    df.fit(X_train, y_train)\n",
        "    train_score = df.score(X_train, y_train)\n",
        "    test_score = df.score(X_test, y_test)\n",
        "    return train_score,test_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_lQBCi6mp7m",
        "outputId": "6a7b42f7-d338-4998-a265-16b5f78fcfef"
      },
      "source": [
        "print('{:10} {:20} {:20}'.format('depth', 'Training score','Testing score'))\n",
        "print('{:10} {:20} {:20}'.format('-----', '--------------','-------------'))\n",
        "print('{:1}         {} '.format(2,str(compara_modelos_decision_tree(2))))\n",
        "print('{:1}         {} '.format(3,str(compara_modelos_decision_tree(3))))\n",
        "print('{:1}         {} '.format(4,str(compara_modelos_decision_tree(4))))\n",
        "print('{:1}         {} '.format(10,str(compara_modelos_decision_tree(10))))\n",
        "print('{:1}         {} '.format(15,str(compara_modelos_decision_tree(15))))\n",
        "print('{:1}         {} '.format('Full',str(compara_modelos_decision_tree(0))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "depth      Training score       Testing score       \n",
            "-----      --------------       -------------       \n",
            "2         (0.6398809523809523, 0.6805555555555556) \n",
            "3         (0.7321428571428571, 0.7013888888888888) \n",
            "4         (0.7916666666666666, 0.7430555555555556) \n",
            "10         (0.9910714285714286, 0.6875) \n",
            "15         (1.0, 0.6944444444444444) \n",
            "Full         (1.0, 0.6944444444444444) \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2pHJrNUmp7q"
      },
      "source": [
        "A partir de **max_depth=10** já está totalmente enviesado, aparentemente o melhor resultado está entre os valores **max_depth=3** e **max_depth=4**, pois a diferença entre a acertividade de *treino* e *teste* é de aproximadamente **3%** e **5%**, respectivamente, enquanto os demais passam disso. Aquele tem uma difença menor em relação aos dados de *treino* e *teste*, contudo com acertividade inferior, então vale a pena cogitar utilizar o *max_depth=4*, uma vez que sua *acertividade* é melhor, embora o *erro* também seja maior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grMpWsGDmp7t"
      },
      "source": [
        "# 5. Tuning do Modelo\n",
        "Como expliquei, Tunning do modelo é a alteração dos parâmetros do algoritmo para que haja alguma melhora no seu resultado final.\n",
        "\n",
        "O **Tuning** deve **SEMPRE** ser feito para que você possa tentar extrair o melhor do seu modelo.\n",
        "\n",
        "Aqui utilizaremos o **GridSearchCV** da **sklearn.model_selection** para fazer o tuning. O Grid nos permite testar os parâmetros em várias combinações e irá nos permitir realmente encontrar os melhores parâmetros.\n",
        "\n",
        "### Quando utilizar?\n",
        "* Após você encontrar o melhor algoritmo e a razão disso é o custo computacional e temporal.\n",
        "* Quanto *mais parâmetros* você colocar dentro do Grid, *mais demorado* será para o Grid retornar, então usá-lo com todos os parâmetros e todos os algoritmos não é uma boa prática, embora você possa querer fazer.\n",
        "\n",
        "### Como usar?\n",
        "* Para cada parâmetro você cria uma **lista de valores** que o algoritmo irá testar através de uma *análise combinatória* com os demais parâmetros.\n",
        "* Após criar todas as listas, cria-se o **Dicionário** unindo todas as listas.\n",
        "* O dicionário é bem intuitivo e utiliza o padrão **chave:valor**, assim como um dicionário onde se tem **palavra:explicação da palavra**.\n",
        "* No dicionário a **chave** (key) será o nome do parâmetro do algoritmo e o **valor** (value) será a lista criada para aquele parâmetro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwbJOQmvmp7t"
      },
      "source": [
        "**GridSearchCV para testes de Hyperparametros**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2oDUaU1mp7u"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLp-5O4Nmp7y"
      },
      "source": [
        "# lista de possíveis valores de estimators ou quantidade de árvores da floresta.\n",
        "valores_estimators = [10, 20, 50, 100, 150]\n",
        "# lista de possíveis valores para o critério de divisão.\n",
        "valores_criterion = ['gini','entropy']\n",
        "# lista de possíveis valores para a profundidade máxima de cada árvore\n",
        "valores_max_depth = [10, 20, 50, 100]\n",
        "# lista de possíveis valores para os parametros min_samples_split e min_samples_leaf.\n",
        "valores_min_samples_split = [2, 5, 10,15]\n",
        "valores_min_samples_leaf = [1, 5, 10,15]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcJXWMc7mp71"
      },
      "source": [
        "# definindo um dicionário que recebe as listas de parâmetros e valores\n",
        "parametros_grid = dict(n_estimators=valores_estimators,\n",
        "                       criterion=valores_criterion,\n",
        "                       max_depth=valores_max_depth,\n",
        "                       min_samples_split=valores_min_samples_split,\n",
        "                       min_samples_leaf=valores_min_samples_leaf \n",
        "                      )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmwN-UKcmp75",
        "outputId": "105634c5-df0b-4969-b336-ae03b5fdbe57"
      },
      "source": [
        "# visualizando o dicionário\n",
        "parametros_grid"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': ['gini', 'entropy'],\n",
              " 'max_depth': [10, 20, 50, 100],\n",
              " 'min_samples_leaf': [1, 5, 10, 15],\n",
              " 'min_samples_split': [2, 5, 10, 15],\n",
              " 'n_estimators': [10, 20, 50, 100, 150]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hdc_0vwRmp78"
      },
      "source": [
        "**Instanciando o GridSearch**\n",
        "\n",
        "Passamos o modelo a ser utilizado, parametros, número de folds e scoring."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_G9PPkYmp79"
      },
      "source": [
        "rf = RandomForestClassifier()\n",
        "grid = GridSearchCV(rf, parametros_grid, cv=5, scoring='accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JQ9Mr7Jmp8A"
      },
      "source": [
        "**Aplicando o GridSearch passando as features e classes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1gZfY1ZImp8B",
        "outputId": "b50770fc-ac55-45e3-c43c-e83e3c7eb16b"
      },
      "source": [
        "grid.fit(df_edu.drop('Class',axis=1),df_edu['Class'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              oob_score=False,\n",
              "                                              random_state=None, verbose=0,\n",
              "                                              warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'criterion': ['gini', 'entropy'],\n",
              "                         'max_depth': [10, 20, 50, 100],\n",
              "                         'min_samples_leaf': [1, 5, 10, 15],\n",
              "                         'min_samples_split': [2, 5, 10, 15],\n",
              "                         'n_estimators': [10, 20, 50, 100, 150]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsB3hRGOmp8G"
      },
      "source": [
        "### Retornos\n",
        "* **grid.cv_results_**: trará todos os *resultados*.\n",
        "* **grid.best_params_**: retornará os *melhores parâmetros* dentro dos definidos para o *tunning*.\n",
        "* **grid.best_score_**: retorna o *melhor score*, ou seja, a melhor acurácia do modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRksh08jmp8G"
      },
      "source": [
        "**Resultados**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nV-9qGLsmp8H",
        "outputId": "a2c305b6-0c47-48d3-d712-15c0485a0ae6"
      },
      "source": [
        "grid.cv_results_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([0.01833577, 0.02829838, 0.06594701, 0.1283946 , 0.18915715,\n",
              "        0.01360168, 0.02670889, 0.06264515, 0.12474227, 0.18555307,\n",
              "        0.01425366, 0.02506995, 0.0610867 , 0.12179561, 0.18202548,\n",
              "        0.01300745, 0.02495756, 0.05991263, 0.11987729, 0.1903172 ,\n",
              "        0.01342387, 0.02484183, 0.05972137, 0.11960592, 0.1771461 ,\n",
              "        0.01309304, 0.02485433, 0.05996194, 0.12089462, 0.17704763,\n",
              "        0.01309185, 0.02469759, 0.06087494, 0.1177597 , 0.17865787,\n",
              "        0.0128428 , 0.02429032, 0.06008339, 0.11688786, 0.17624679,\n",
              "        0.01267581, 0.02412977, 0.06235704, 0.13290181, 0.18257022,\n",
              "        0.01281085, 0.02464528, 0.06155815, 0.11530566, 0.17289486,\n",
              "        0.01314936, 0.02548509, 0.05962615, 0.11704512, 0.17458377,\n",
              "        0.01372313, 0.02399955, 0.06075935, 0.11948581, 0.1706037 ,\n",
              "        0.01348505, 0.02352324, 0.05634246, 0.11272035, 0.16617498,\n",
              "        0.01312699, 0.02327175, 0.05662251, 0.1132834 , 0.16717787,\n",
              "        0.01315417, 0.02319818, 0.05820994, 0.11277823, 0.16687951,\n",
              "        0.01264563, 0.02371812, 0.0574594 , 0.11404281, 0.16814399,\n",
              "        0.01475844, 0.02644668, 0.06481299, 0.12917328, 0.19178371,\n",
              "        0.01376281, 0.02638927, 0.06352391, 0.12564797, 0.18885875,\n",
              "        0.0135962 , 0.0259438 , 0.06221805, 0.12353778, 0.18729196,\n",
              "        0.0135716 , 0.02539177, 0.06199174, 0.12057762, 0.18045554,\n",
              "        0.01297321, 0.0250525 , 0.06097941, 0.11971712, 0.17943873,\n",
              "        0.01320138, 0.02591624, 0.06002207, 0.12030497, 0.17924919,\n",
              "        0.01324353, 0.02573247, 0.06012526, 0.11928177, 0.17980766,\n",
              "        0.01305003, 0.02696609, 0.06879163, 0.13447971, 0.18974938,\n",
              "        0.0126411 , 0.02430296, 0.05809846, 0.11606464, 0.17296028,\n",
              "        0.01287179, 0.02560158, 0.0582448 , 0.11593981, 0.1710989 ,\n",
              "        0.01289721, 0.02407446, 0.05778332, 0.11452899, 0.17133574,\n",
              "        0.01273189, 0.02388725, 0.0571589 , 0.1149796 , 0.19537539,\n",
              "        0.01264729, 0.02335382, 0.05734587, 0.11176777, 0.16781139,\n",
              "        0.01226296, 0.02329187, 0.05631618, 0.11181946, 0.16870189,\n",
              "        0.01242986, 0.02345843, 0.05622196, 0.11310067, 0.16719007,\n",
              "        0.01217275, 0.0230123 , 0.05546412, 0.11274619, 0.16797972,\n",
              "        0.01386933, 0.0262362 , 0.06359239, 0.1280035 , 0.19021444,\n",
              "        0.01350932, 0.02574968, 0.06362381, 0.12514362, 0.18927193,\n",
              "        0.01336384, 0.02609386, 0.06154718, 0.12263722, 0.18309059,\n",
              "        0.01416631, 0.02499886, 0.06138048, 0.11945591, 0.17970042,\n",
              "        0.01305676, 0.02505999, 0.05971651, 0.11895175, 0.17693286,\n",
              "        0.0131918 , 0.02470655, 0.06009336, 0.11995058, 0.17870278,\n",
              "        0.01339793, 0.02936006, 0.06935153, 0.13475375, 0.18496423,\n",
              "        0.01303554, 0.02434425, 0.06001487, 0.11916027, 0.1766161 ,\n",
              "        0.01266179, 0.02390079, 0.05877523, 0.11634059, 0.17224579,\n",
              "        0.01264067, 0.02386436, 0.05893331, 0.11334085, 0.17178602,\n",
              "        0.01265359, 0.0237287 , 0.05867362, 0.11419439, 0.17135816,\n",
              "        0.01256156, 0.02368693, 0.05917201, 0.11417933, 0.17135038,\n",
              "        0.01224313, 0.02325435, 0.0575274 , 0.111443  , 0.16698732,\n",
              "        0.01234641, 0.02337255, 0.05800428, 0.11200562, 0.16908598,\n",
              "        0.01244245, 0.02335644, 0.05688958, 0.11077461, 0.16734543,\n",
              "        0.01230087, 0.02339945, 0.05758867, 0.11095805, 0.16767454,\n",
              "        0.0138535 , 0.02635317, 0.06500063, 0.12768879, 0.18996105,\n",
              "        0.01366453, 0.02661314, 0.0629571 , 0.12551746, 0.18876772,\n",
              "        0.01337357, 0.02548718, 0.06161089, 0.122543  , 0.18367877,\n",
              "        0.01329298, 0.02487435, 0.06032987, 0.12025404, 0.18368511,\n",
              "        0.01306314, 0.02475238, 0.06014161, 0.12035494, 0.17804413,\n",
              "        0.01345496, 0.02779155, 0.06403799, 0.11934438, 0.18240767,\n",
              "        0.01318307, 0.02543836, 0.06177826, 0.11940947, 0.18058515,\n",
              "        0.01314754, 0.02508416, 0.06093535, 0.11859827, 0.17708011,\n",
              "        0.01281219, 0.02668457, 0.05798688, 0.11497936, 0.17294302,\n",
              "        0.01277075, 0.02461967, 0.05827441, 0.11546698, 0.17361612,\n",
              "        0.0126544 , 0.02476506, 0.05901628, 0.11538892, 0.17046041,\n",
              "        0.01261253, 0.02501221, 0.05846405, 0.11576142, 0.17084479,\n",
              "        0.0133461 , 0.02341876, 0.05641208, 0.11672235, 0.17028246,\n",
              "        0.0134172 , 0.02344284, 0.05701938, 0.11373038, 0.17383704,\n",
              "        0.01348996, 0.02345386, 0.05674267, 0.11223273, 0.1652421 ,\n",
              "        0.01305699, 0.0233788 , 0.05595345, 0.11233344, 0.16618581,\n",
              "        0.0155242 , 0.03039827, 0.0715086 , 0.14271355, 0.21323867,\n",
              "        0.01535544, 0.02928219, 0.0719276 , 0.14066505, 0.2100904 ,\n",
              "        0.01487584, 0.02888894, 0.06817651, 0.13626695, 0.20266852,\n",
              "        0.01420455, 0.02726879, 0.06713281, 0.13228669, 0.2013834 ,\n",
              "        0.01655469, 0.03072448, 0.0738483 , 0.12938452, 0.19451928,\n",
              "        0.01406999, 0.02789378, 0.06528401, 0.12873325, 0.19353614,\n",
              "        0.01410031, 0.02680016, 0.06522613, 0.12984085, 0.19357224,\n",
              "        0.01413231, 0.02661576, 0.06442637, 0.12808857, 0.19097557,\n",
              "        0.01319046, 0.0251555 , 0.06180358, 0.12105627, 0.18290033,\n",
              "        0.01342545, 0.02518129, 0.06200132, 0.12030239, 0.18095984,\n",
              "        0.01339779, 0.02603745, 0.06114616, 0.1216764 , 0.18282127,\n",
              "        0.01326251, 0.02505631, 0.06108136, 0.12122054, 0.18207917,\n",
              "        0.01288929, 0.02459302, 0.05907111, 0.11793656, 0.17722297,\n",
              "        0.01293917, 0.02462926, 0.05906105, 0.11668115, 0.17421718,\n",
              "        0.01293902, 0.02430081, 0.05856676, 0.11678348, 0.17443299,\n",
              "        0.0131144 , 0.02446985, 0.05905728, 0.11966624, 0.17480412,\n",
              "        0.01573539, 0.02962594, 0.07370901, 0.14395542, 0.24609241,\n",
              "        0.01552539, 0.0303452 , 0.07389259, 0.14601946, 0.21111941,\n",
              "        0.01470327, 0.02824326, 0.07243066, 0.1598505 , 0.23112326,\n",
              "        0.01447568, 0.03070617, 0.07815633, 0.13559666, 0.1988656 ,\n",
              "        0.01405406, 0.02673407, 0.06593719, 0.12945695, 0.19773736,\n",
              "        0.01420403, 0.02827759, 0.06536732, 0.13050623, 0.19378662,\n",
              "        0.0141223 , 0.02727046, 0.06579685, 0.13117428, 0.19501066,\n",
              "        0.01402173, 0.02636218, 0.0650526 , 0.1274878 , 0.19029641,\n",
              "        0.01309671, 0.0249598 , 0.06273799, 0.12034259, 0.18130965,\n",
              "        0.01321626, 0.02651501, 0.06233325, 0.12324924, 0.18209181,\n",
              "        0.01444507, 0.02555752, 0.06133285, 0.12238274, 0.18280253,\n",
              "        0.01352267, 0.02541223, 0.06179013, 0.12285256, 0.18351703,\n",
              "        0.01299114, 0.02470212, 0.05997262, 0.11912012, 0.17634301,\n",
              "        0.01318679, 0.02460485, 0.05945964, 0.11946807, 0.17747922,\n",
              "        0.01276522, 0.02428441, 0.05881362, 0.11933494, 0.17529016,\n",
              "        0.0127749 , 0.02422862, 0.05938268, 0.11629815, 0.18548899,\n",
              "        0.01843467, 0.03532863, 0.08510618, 0.15166521, 0.21408215,\n",
              "        0.01520691, 0.02924008, 0.07095714, 0.14052539, 0.21173415,\n",
              "        0.01493301, 0.02851872, 0.06940517, 0.13598089, 0.20400004,\n",
              "        0.01440215, 0.02747445, 0.06656098, 0.13342338, 0.19842739,\n",
              "        0.01399608, 0.02691393, 0.06471477, 0.13015614, 0.19444299,\n",
              "        0.01428528, 0.02722301, 0.06606421, 0.12946687, 0.19460654,\n",
              "        0.01471305, 0.02720823, 0.06516476, 0.13006635, 0.19558229,\n",
              "        0.01388917, 0.02636733, 0.0639266 , 0.1284411 , 0.19218526,\n",
              "        0.01346445, 0.02549229, 0.06171126, 0.12155771, 0.18197999,\n",
              "        0.01345367, 0.02547235, 0.06187162, 0.12114472, 0.18120537,\n",
              "        0.01351442, 0.02519598, 0.06156058, 0.12036772, 0.18132758,\n",
              "        0.01321044, 0.02621369, 0.06134982, 0.12525854, 0.18181357,\n",
              "        0.01349683, 0.02440267, 0.0587852 , 0.11691685, 0.17483501,\n",
              "        0.0127913 , 0.02427998, 0.05879822, 0.11677113, 0.20206547,\n",
              "        0.01435099, 0.02607031, 0.0635427 , 0.12349224, 0.17467961,\n",
              "        0.01288586, 0.02419381, 0.05851054, 0.11864471, 0.17537622,\n",
              "        0.01560416, 0.02980785, 0.0734602 , 0.14328661, 0.21578331,\n",
              "        0.01593809, 0.0290853 , 0.0703742 , 0.14057999, 0.21264176,\n",
              "        0.01500216, 0.02850475, 0.06869812, 0.13714561, 0.20482345,\n",
              "        0.01456804, 0.02762671, 0.06801615, 0.13212714, 0.19777436,\n",
              "        0.01398439, 0.02693043, 0.06653295, 0.13023267, 0.19493809,\n",
              "        0.01408157, 0.02705703, 0.06517534, 0.12987118, 0.1939549 ,\n",
              "        0.01417542, 0.02690778, 0.06619434, 0.12904801, 0.19376106,\n",
              "        0.01385956, 0.02702575, 0.06373334, 0.12718525, 0.18953671,\n",
              "        0.01333103, 0.02530212, 0.06112494, 0.12336483, 0.18239255,\n",
              "        0.01344576, 0.02554255, 0.0611002 , 0.12136235, 0.18104939,\n",
              "        0.01338253, 0.02517395, 0.06129456, 0.12140703, 0.18168826,\n",
              "        0.013378  , 0.02538447, 0.06245542, 0.1325285 , 0.20585999,\n",
              "        0.01307106, 0.0253139 , 0.05840468, 0.11556277, 0.17564111,\n",
              "        0.01313319, 0.02618837, 0.05970984, 0.11702266, 0.1764811 ,\n",
              "        0.0130362 , 0.02514868, 0.05902686, 0.11830573, 0.1748651 ,\n",
              "        0.01377201, 0.02434363, 0.05946822, 0.11804967, 0.17625394]),\n",
              " 'mean_score_time': array([0.00199223, 0.00232821, 0.00466862, 0.00738072, 0.01058049,\n",
              "        0.00160279, 0.00227613, 0.0041491 , 0.00730925, 0.01038527,\n",
              "        0.00167694, 0.00217552, 0.00403171, 0.00709057, 0.01017804,\n",
              "        0.00158896, 0.00218906, 0.0040298 , 0.00712171, 0.01021595,\n",
              "        0.00162067, 0.00235128, 0.00401478, 0.00719709, 0.01098924,\n",
              "        0.00157647, 0.00218449, 0.00406704, 0.00708771, 0.01020088,\n",
              "        0.00155778, 0.0022047 , 0.00467329, 0.00702238, 0.01075439,\n",
              "        0.00156846, 0.00217919, 0.00394135, 0.00706606, 0.01012993,\n",
              "        0.00157003, 0.00217147, 0.00429373, 0.0081213 , 0.01054044,\n",
              "        0.00162048, 0.00249724, 0.00403166, 0.00704126, 0.01061187,\n",
              "        0.00160785, 0.00233626, 0.00399065, 0.0071641 , 0.01002407,\n",
              "        0.00154996, 0.00224862, 0.00430555, 0.00724907, 0.01009908,\n",
              "        0.00158353, 0.00216455, 0.00394182, 0.00691228, 0.00998068,\n",
              "        0.00175929, 0.00215211, 0.00387282, 0.00690093, 0.00994201,\n",
              "        0.00155182, 0.00214295, 0.00391808, 0.00701628, 0.0099668 ,\n",
              "        0.00173812, 0.00217495, 0.00399737, 0.00694723, 0.01020937,\n",
              "        0.00163565, 0.00224695, 0.0041769 , 0.00753484, 0.01058092,\n",
              "        0.00164189, 0.00238967, 0.00412583, 0.00783277, 0.01085167,\n",
              "        0.00163655, 0.00221534, 0.00421453, 0.0074275 , 0.0105567 ,\n",
              "        0.00162783, 0.00226874, 0.00408869, 0.00744696, 0.01026988,\n",
              "        0.00156074, 0.00222287, 0.00406899, 0.00726099, 0.01030631,\n",
              "        0.00159383, 0.00220289, 0.00399499, 0.0079545 , 0.01031795,\n",
              "        0.00160289, 0.00219069, 0.00404344, 0.00706248, 0.01036735,\n",
              "        0.00156741, 0.00243535, 0.00467873, 0.00802121, 0.01069298,\n",
              "        0.00157466, 0.0022759 , 0.00401678, 0.00701857, 0.01004801,\n",
              "        0.00160575, 0.00224886, 0.00399146, 0.00703993, 0.0105752 ,\n",
              "        0.00161281, 0.00217891, 0.00398421, 0.00755076, 0.00996127,\n",
              "        0.00159473, 0.002175  , 0.00395584, 0.0070735 , 0.01096768,\n",
              "        0.00158105, 0.00217652, 0.00392652, 0.00697145, 0.0099813 ,\n",
              "        0.00157762, 0.00214453, 0.0044991 , 0.00701942, 0.00991998,\n",
              "        0.00157642, 0.00212607, 0.00389762, 0.00698261, 0.00981493,\n",
              "        0.00152736, 0.00213881, 0.00387387, 0.00690465, 0.00993576,\n",
              "        0.00160818, 0.00220709, 0.00410414, 0.00736899, 0.01050372,\n",
              "        0.00159984, 0.00221353, 0.00410676, 0.0072475 , 0.01044598,\n",
              "        0.00159507, 0.00224428, 0.00404944, 0.00718565, 0.01030526,\n",
              "        0.00161242, 0.00218749, 0.00403075, 0.00706363, 0.01017118,\n",
              "        0.00158854, 0.00227389, 0.00409045, 0.00734563, 0.01144156,\n",
              "        0.00158424, 0.00220609, 0.00403004, 0.00716448, 0.01035953,\n",
              "        0.00165052, 0.00258169, 0.00463977, 0.00797   , 0.01155186,\n",
              "        0.00160251, 0.00220308, 0.00400362, 0.00710135, 0.01011605,\n",
              "        0.00157423, 0.00220685, 0.00396857, 0.00720587, 0.01004052,\n",
              "        0.00158625, 0.00217252, 0.00398021, 0.00699172, 0.01005611,\n",
              "        0.00156274, 0.00220394, 0.00400553, 0.00719156, 0.01006222,\n",
              "        0.00157118, 0.00216169, 0.004002  , 0.00695486, 0.01003289,\n",
              "        0.00159378, 0.00218387, 0.00392852, 0.00691323, 0.01058273,\n",
              "        0.00156002, 0.00216413, 0.00396276, 0.00690193, 0.00996485,\n",
              "        0.00156388, 0.00216713, 0.00394635, 0.00697136, 0.00989218,\n",
              "        0.00156093, 0.00215855, 0.00394378, 0.00696878, 0.0103066 ,\n",
              "        0.00160809, 0.00220265, 0.00420427, 0.0081151 , 0.01057224,\n",
              "        0.00160484, 0.0024663 , 0.0040976 , 0.00732074, 0.0108016 ,\n",
              "        0.00158191, 0.00220675, 0.00405364, 0.00761065, 0.01037903,\n",
              "        0.00159545, 0.0022049 , 0.00404501, 0.0073369 , 0.0102025 ,\n",
              "        0.00159092, 0.00217977, 0.00400243, 0.00763779, 0.0102807 ,\n",
              "        0.00158453, 0.00252323, 0.00421543, 0.00713301, 0.01066489,\n",
              "        0.0015656 , 0.00230293, 0.00415173, 0.00720978, 0.01034918,\n",
              "        0.00162239, 0.00220494, 0.00413084, 0.00712314, 0.01034942,\n",
              "        0.00155263, 0.00237827, 0.00404925, 0.00695543, 0.01004667,\n",
              "        0.00155358, 0.00249143, 0.00401354, 0.00709205, 0.01018052,\n",
              "        0.00157647, 0.00220113, 0.00397658, 0.00716476, 0.00997391,\n",
              "        0.00156937, 0.00220499, 0.00401688, 0.00708408, 0.01005154,\n",
              "        0.00159416, 0.00224705, 0.00392327, 0.00762701, 0.01034503,\n",
              "        0.00169821, 0.00222712, 0.00415487, 0.00710225, 0.01072598,\n",
              "        0.00160365, 0.00219212, 0.00403323, 0.00690856, 0.00987039,\n",
              "        0.00175323, 0.00215945, 0.00395222, 0.00683832, 0.0098783 ,\n",
              "        0.00160213, 0.00224128, 0.00410194, 0.00725675, 0.01156549,\n",
              "        0.00161109, 0.00224481, 0.0044508 , 0.00735459, 0.01051965,\n",
              "        0.0015923 , 0.00216637, 0.00408278, 0.00726357, 0.0111361 ,\n",
              "        0.00159273, 0.00218148, 0.00407825, 0.00712314, 0.01137819,\n",
              "        0.00184674, 0.00252542, 0.00452414, 0.00715127, 0.01028066,\n",
              "        0.00157638, 0.00218296, 0.00406833, 0.00769248, 0.01014557,\n",
              "        0.00157728, 0.00217566, 0.00401616, 0.00716496, 0.01125731,\n",
              "        0.00160894, 0.00219641, 0.00402164, 0.00713582, 0.01020131,\n",
              "        0.00155048, 0.00211887, 0.00392113, 0.00704031, 0.0108325 ,\n",
              "        0.00157738, 0.00214667, 0.0040318 , 0.00719805, 0.0099596 ,\n",
              "        0.00156999, 0.00217838, 0.00395246, 0.00702577, 0.01017599,\n",
              "        0.00157976, 0.00217338, 0.00395236, 0.00696602, 0.01012492,\n",
              "        0.00155644, 0.00214567, 0.00393453, 0.00694027, 0.00990887,\n",
              "        0.00157518, 0.00217085, 0.00394392, 0.00743976, 0.01000156,\n",
              "        0.00158854, 0.00214968, 0.00394535, 0.00685902, 0.00983925,\n",
              "        0.00158277, 0.00215158, 0.00393491, 0.00695581, 0.00988035,\n",
              "        0.00161295, 0.00222383, 0.00413713, 0.00735083, 0.01210237,\n",
              "        0.00166187, 0.00223813, 0.00413756, 0.00824699, 0.01042542,\n",
              "        0.00157456, 0.00221071, 0.00443716, 0.00882344, 0.01112809,\n",
              "        0.00158839, 0.00250173, 0.00468979, 0.00757513, 0.0102529 ,\n",
              "        0.00157957, 0.00219965, 0.00402107, 0.00712447, 0.01051173,\n",
              "        0.00160961, 0.00223379, 0.00405345, 0.0071372 , 0.01033273,\n",
              "        0.0016367 , 0.0021965 , 0.00406332, 0.00736599, 0.01048155,\n",
              "        0.0015902 , 0.00218291, 0.00410194, 0.00707126, 0.01017027,\n",
              "        0.00156193, 0.00216393, 0.00401816, 0.00707083, 0.01007848,\n",
              "        0.00157876, 0.00226169, 0.00407972, 0.00809236, 0.01017241,\n",
              "        0.00158854, 0.00221114, 0.00402021, 0.00710945, 0.01025481,\n",
              "        0.00160804, 0.00219059, 0.0039978 , 0.0071743 , 0.01015205,\n",
              "        0.00157547, 0.00222692, 0.00399981, 0.00712948, 0.01002126,\n",
              "        0.00164886, 0.00220962, 0.00398593, 0.00710626, 0.00997696,\n",
              "        0.00156116, 0.00215244, 0.00394101, 0.00749784, 0.00996337,\n",
              "        0.00158935, 0.00214615, 0.00424314, 0.00696697, 0.01087723,\n",
              "        0.00188646, 0.002634  , 0.00474896, 0.00754967, 0.01099215,\n",
              "        0.00164523, 0.00222449, 0.00414758, 0.00812583, 0.01053114,\n",
              "        0.00159092, 0.00222006, 0.00418816, 0.00750465, 0.01032228,\n",
              "        0.00163388, 0.00220337, 0.00405812, 0.00706134, 0.0101923 ,\n",
              "        0.00158329, 0.0021646 , 0.00402331, 0.00714788, 0.01030955,\n",
              "        0.00159302, 0.00218272, 0.00404963, 0.00711241, 0.01025057,\n",
              "        0.00178008, 0.0022191 , 0.0040926 , 0.00722656, 0.01024189,\n",
              "        0.00157137, 0.00217447, 0.00404115, 0.00720291, 0.01016631,\n",
              "        0.00158315, 0.00218444, 0.0040288 , 0.00700073, 0.0102798 ,\n",
              "        0.00157833, 0.00216975, 0.00401936, 0.0069973 , 0.01002975,\n",
              "        0.00157781, 0.00217581, 0.00394797, 0.00718298, 0.00996232,\n",
              "        0.00156655, 0.00219908, 0.00399275, 0.00810385, 0.01002097,\n",
              "        0.00177994, 0.00213895, 0.00395436, 0.00726347, 0.01006279,\n",
              "        0.00155382, 0.00214577, 0.00396667, 0.00692797, 0.01308913,\n",
              "        0.0017436 , 0.0023407 , 0.00426941, 0.00730901, 0.00980992,\n",
              "        0.00156159, 0.00213437, 0.00391173, 0.00700369, 0.00992599,\n",
              "        0.00160146, 0.0023663 , 0.00442352, 0.00725541, 0.01059737,\n",
              "        0.0018115 , 0.0022285 , 0.00402732, 0.00713472, 0.01047688,\n",
              "        0.00175586, 0.00234265, 0.00402603, 0.00718722, 0.01036   ,\n",
              "        0.00158043, 0.00219979, 0.00399313, 0.00710807, 0.01015892,\n",
              "        0.00159459, 0.00218334, 0.00408325, 0.00720153, 0.0104394 ,\n",
              "        0.00158873, 0.00220232, 0.00403876, 0.00711675, 0.01023989,\n",
              "        0.00160928, 0.00219731, 0.00405173, 0.00710592, 0.01021075,\n",
              "        0.0015717 , 0.00227923, 0.0040072 , 0.00727324, 0.01017528,\n",
              "        0.00158477, 0.00225511, 0.00402684, 0.00722666, 0.01012263,\n",
              "        0.00160985, 0.00219202, 0.0039947 , 0.00696373, 0.01000648,\n",
              "        0.00160809, 0.00216799, 0.00396385, 0.00699453, 0.01019874,\n",
              "        0.00158305, 0.00219216, 0.00406537, 0.00788541, 0.01144352,\n",
              "        0.00159492, 0.0022912 , 0.00388594, 0.00684443, 0.00984907,\n",
              "        0.00163279, 0.00223832, 0.00397773, 0.00726509, 0.01001749,\n",
              "        0.00178347, 0.00221157, 0.00398307, 0.00700011, 0.01014357,\n",
              "        0.00155692, 0.0021419 , 0.00402737, 0.00716305, 0.01009688]),\n",
              " 'mean_test_score': array([0.64583333, 0.66875   , 0.66458333, 0.675     , 0.68333333,\n",
              "        0.65833333, 0.69583333, 0.69583333, 0.675     , 0.68125   ,\n",
              "        0.68958333, 0.67708333, 0.69375   , 0.69166667, 0.70625   ,\n",
              "        0.69583333, 0.68125   , 0.69791667, 0.68541667, 0.70208333,\n",
              "        0.67083333, 0.67708333, 0.69166667, 0.69375   , 0.69583333,\n",
              "        0.68125   , 0.67916667, 0.68541667, 0.68333333, 0.69166667,\n",
              "        0.6875    , 0.69583333, 0.67916667, 0.70208333, 0.69791667,\n",
              "        0.65208333, 0.67916667, 0.68333333, 0.72291667, 0.70208333,\n",
              "        0.67083333, 0.67291667, 0.69791667, 0.69791667, 0.70208333,\n",
              "        0.67708333, 0.70416667, 0.69791667, 0.70625   , 0.7       ,\n",
              "        0.675     , 0.70625   , 0.71041667, 0.69375   , 0.70833333,\n",
              "        0.70416667, 0.67916667, 0.68333333, 0.7       , 0.69166667,\n",
              "        0.69791667, 0.68333333, 0.67916667, 0.69375   , 0.68541667,\n",
              "        0.68958333, 0.67916667, 0.68541667, 0.70416667, 0.68125   ,\n",
              "        0.71458333, 0.6875    , 0.69791667, 0.67916667, 0.68541667,\n",
              "        0.67708333, 0.7125    , 0.68333333, 0.68333333, 0.6875    ,\n",
              "        0.64791667, 0.66041667, 0.67708333, 0.6875    , 0.68333333,\n",
              "        0.67083333, 0.67708333, 0.69791667, 0.69166667, 0.69375   ,\n",
              "        0.65      , 0.70416667, 0.68958333, 0.675     , 0.68333333,\n",
              "        0.66458333, 0.66666667, 0.69791667, 0.69791667, 0.68333333,\n",
              "        0.68333333, 0.7125    , 0.69583333, 0.70833333, 0.71041667,\n",
              "        0.6625    , 0.70208333, 0.66041667, 0.69375   , 0.69375   ,\n",
              "        0.65208333, 0.67916667, 0.7       , 0.71458333, 0.71041667,\n",
              "        0.68125   , 0.68125   , 0.68125   , 0.69583333, 0.69583333,\n",
              "        0.66041667, 0.69375   , 0.66458333, 0.69583333, 0.69583333,\n",
              "        0.69791667, 0.69583333, 0.69375   , 0.67291667, 0.69583333,\n",
              "        0.675     , 0.66458333, 0.68125   , 0.6875    , 0.68541667,\n",
              "        0.68125   , 0.68125   , 0.69375   , 0.71041667, 0.69791667,\n",
              "        0.65625   , 0.71666667, 0.70833333, 0.71041667, 0.675     ,\n",
              "        0.68125   , 0.67083333, 0.65833333, 0.71041667, 0.67916667,\n",
              "        0.6375    , 0.67916667, 0.67708333, 0.67083333, 0.68958333,\n",
              "        0.69583333, 0.7       , 0.7       , 0.69583333, 0.68541667,\n",
              "        0.67916667, 0.64583333, 0.7       , 0.68541667, 0.67708333,\n",
              "        0.71875   , 0.66458333, 0.69166667, 0.70208333, 0.7       ,\n",
              "        0.68125   , 0.71041667, 0.67291667, 0.69375   , 0.69166667,\n",
              "        0.70625   , 0.68958333, 0.69166667, 0.67916667, 0.69583333,\n",
              "        0.67291667, 0.71041667, 0.69375   , 0.71041667, 0.68958333,\n",
              "        0.675     , 0.68541667, 0.70416667, 0.70416667, 0.69166667,\n",
              "        0.69791667, 0.68333333, 0.70208333, 0.69375   , 0.7       ,\n",
              "        0.65625   , 0.68958333, 0.70208333, 0.69583333, 0.70625   ,\n",
              "        0.71666667, 0.67916667, 0.69375   , 0.7       , 0.69375   ,\n",
              "        0.69166667, 0.67291667, 0.69375   , 0.70416667, 0.70833333,\n",
              "        0.68333333, 0.70208333, 0.7       , 0.67083333, 0.68958333,\n",
              "        0.70625   , 0.69583333, 0.68333333, 0.72708333, 0.7       ,\n",
              "        0.67708333, 0.68333333, 0.67916667, 0.67916667, 0.68958333,\n",
              "        0.65      , 0.69583333, 0.69583333, 0.6875    , 0.675     ,\n",
              "        0.71875   , 0.66041667, 0.66458333, 0.69375   , 0.69375   ,\n",
              "        0.69375   , 0.6875    , 0.68333333, 0.67916667, 0.7       ,\n",
              "        0.6625    , 0.65      , 0.65833333, 0.67916667, 0.675     ,\n",
              "        0.64375   , 0.675     , 0.68125   , 0.68125   , 0.6875    ,\n",
              "        0.70625   , 0.70625   , 0.7       , 0.69375   , 0.69375   ,\n",
              "        0.64583333, 0.68958333, 0.71041667, 0.69166667, 0.6875    ,\n",
              "        0.65      , 0.68958333, 0.70833333, 0.69583333, 0.70625   ,\n",
              "        0.69166667, 0.68541667, 0.69791667, 0.70833333, 0.69583333,\n",
              "        0.69375   , 0.66666667, 0.70208333, 0.69166667, 0.68125   ,\n",
              "        0.69166667, 0.70416667, 0.69375   , 0.69583333, 0.71041667,\n",
              "        0.70833333, 0.66666667, 0.70208333, 0.70416667, 0.6875    ,\n",
              "        0.68333333, 0.6875    , 0.71458333, 0.69583333, 0.68541667,\n",
              "        0.67291667, 0.69583333, 0.69166667, 0.69375   , 0.68333333,\n",
              "        0.7       , 0.67083333, 0.69791667, 0.6875    , 0.69166667,\n",
              "        0.69166667, 0.69583333, 0.70625   , 0.68958333, 0.6875    ,\n",
              "        0.68125   , 0.67291667, 0.67291667, 0.66458333, 0.68958333,\n",
              "        0.66666667, 0.6875    , 0.68333333, 0.68958333, 0.70416667,\n",
              "        0.68333333, 0.69791667, 0.7       , 0.70833333, 0.7       ,\n",
              "        0.64583333, 0.6625    , 0.67916667, 0.69166667, 0.68125   ,\n",
              "        0.62708333, 0.6625    , 0.68958333, 0.68125   , 0.68125   ,\n",
              "        0.63333333, 0.70416667, 0.7       , 0.67708333, 0.69583333,\n",
              "        0.6875    , 0.69166667, 0.67916667, 0.69583333, 0.7       ,\n",
              "        0.69166667, 0.7125    , 0.675     , 0.69375   , 0.69583333,\n",
              "        0.70416667, 0.69791667, 0.68958333, 0.68333333, 0.7       ,\n",
              "        0.62708333, 0.675     , 0.7125    , 0.67916667, 0.68333333,\n",
              "        0.675     , 0.7       , 0.70625   , 0.70625   , 0.70416667,\n",
              "        0.68958333, 0.6875    , 0.70833333, 0.6875    , 0.69583333,\n",
              "        0.66666667, 0.68333333, 0.70416667, 0.69375   , 0.69166667,\n",
              "        0.67708333, 0.7125    , 0.68333333, 0.70833333, 0.68125   ,\n",
              "        0.68958333, 0.69166667, 0.69375   , 0.69583333, 0.70416667,\n",
              "        0.64791667, 0.68541667, 0.68541667, 0.69375   , 0.69166667,\n",
              "        0.68958333, 0.69166667, 0.71458333, 0.68541667, 0.67708333,\n",
              "        0.6875    , 0.68958333, 0.67083333, 0.68333333, 0.69166667,\n",
              "        0.67708333, 0.69375   , 0.70625   , 0.7       , 0.68958333,\n",
              "        0.63958333, 0.64583333, 0.67291667, 0.6875    , 0.7       ,\n",
              "        0.66041667, 0.69375   , 0.69166667, 0.68125   , 0.68958333,\n",
              "        0.69166667, 0.7       , 0.69166667, 0.68958333, 0.6875    ,\n",
              "        0.6375    , 0.7       , 0.69166667, 0.68958333, 0.68333333,\n",
              "        0.68958333, 0.67916667, 0.7       , 0.7       , 0.6875    ,\n",
              "        0.68333333, 0.68541667, 0.69166667, 0.68958333, 0.7       ,\n",
              "        0.69375   , 0.66458333, 0.7       , 0.68958333, 0.69583333,\n",
              "        0.71041667, 0.675     , 0.68958333, 0.7       , 0.68125   ,\n",
              "        0.67083333, 0.6875    , 0.68958333, 0.68958333, 0.7       ,\n",
              "        0.67916667, 0.70833333, 0.67291667, 0.70208333, 0.70208333,\n",
              "        0.65833333, 0.68125   , 0.70625   , 0.68333333, 0.69791667,\n",
              "        0.66875   , 0.7       , 0.68958333, 0.7       , 0.6875    ,\n",
              "        0.69791667, 0.72708333, 0.6625    , 0.67916667, 0.68958333,\n",
              "        0.63333333, 0.68958333, 0.68333333, 0.70833333, 0.69375   ,\n",
              "        0.63958333, 0.71041667, 0.6875    , 0.67916667, 0.69166667,\n",
              "        0.69166667, 0.7125    , 0.69166667, 0.69791667, 0.68958333,\n",
              "        0.65      , 0.65833333, 0.68333333, 0.68333333, 0.68541667,\n",
              "        0.66875   , 0.64375   , 0.67083333, 0.67708333, 0.68541667,\n",
              "        0.65625   , 0.68541667, 0.68958333, 0.6875    , 0.69166667,\n",
              "        0.68541667, 0.7125    , 0.69583333, 0.68958333, 0.70208333,\n",
              "        0.69791667, 0.67916667, 0.70833333, 0.69583333, 0.71875   ,\n",
              "        0.70833333, 0.7       , 0.7125    , 0.68125   , 0.69166667,\n",
              "        0.64375   , 0.6875    , 0.68541667, 0.69583333, 0.69583333,\n",
              "        0.69375   , 0.68541667, 0.68541667, 0.68333333, 0.69791667,\n",
              "        0.66666667, 0.69375   , 0.725     , 0.68125   , 0.69375   ,\n",
              "        0.65625   , 0.69375   , 0.7       , 0.6875    , 0.69791667,\n",
              "        0.67291667, 0.71041667, 0.70416667, 0.68958333, 0.69791667,\n",
              "        0.67083333, 0.71666667, 0.70208333, 0.69583333, 0.68125   ,\n",
              "        0.68541667, 0.6875    , 0.69375   , 0.6875    , 0.71458333,\n",
              "        0.69791667, 0.68125   , 0.70833333, 0.70208333, 0.7       ,\n",
              "        0.67291667, 0.68125   , 0.68541667, 0.69375   , 0.67708333,\n",
              "        0.64583333, 0.68125   , 0.67916667, 0.68958333, 0.68125   ,\n",
              "        0.66041667, 0.66875   , 0.675     , 0.66666667, 0.68333333,\n",
              "        0.66458333, 0.69166667, 0.69375   , 0.67291667, 0.68958333,\n",
              "        0.67916667, 0.68125   , 0.69583333, 0.68958333, 0.69375   ,\n",
              "        0.67291667, 0.68958333, 0.6875    , 0.7       , 0.70208333,\n",
              "        0.66875   , 0.66875   , 0.69791667, 0.69375   , 0.69791667,\n",
              "        0.66875   , 0.6875    , 0.67916667, 0.70416667, 0.6875    ,\n",
              "        0.6625    , 0.68958333, 0.7125    , 0.69375   , 0.70208333,\n",
              "        0.675     , 0.68333333, 0.69791667, 0.69791667, 0.69166667,\n",
              "        0.67708333, 0.69166667, 0.67083333, 0.68125   , 0.68958333,\n",
              "        0.67708333, 0.68541667, 0.69791667, 0.6875    , 0.69375   ,\n",
              "        0.65      , 0.67291667, 0.66666667, 0.70208333, 0.68541667,\n",
              "        0.62708333, 0.70833333, 0.69791667, 0.68541667, 0.70625   ,\n",
              "        0.7125    , 0.67083333, 0.7       , 0.67708333, 0.69791667,\n",
              "        0.68333333, 0.67708333, 0.68125   , 0.68958333, 0.69583333,\n",
              "        0.67291667, 0.68541667, 0.67291667, 0.69166667, 0.69583333,\n",
              "        0.66875   , 0.69583333, 0.69583333, 0.68125   , 0.6875    ]),\n",
              " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_max_depth': masked_array(data=[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20,\n",
              "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
              "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
              "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
              "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
              "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
              "                    20, 20, 20, 20, 20, 20, 50, 50, 50, 50, 50, 50, 50, 50,\n",
              "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
              "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
              "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
              "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
              "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
              "                    50, 50, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
              "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
              "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
              "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
              "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
              "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 50,\n",
              "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
              "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
              "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
              "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
              "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
              "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_min_samples_leaf': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15,\n",
              "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
              "                    15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15, 15, 15, 15,\n",
              "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
              "                    15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15, 15, 15,\n",
              "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
              "                    15, 15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15, 15,\n",
              "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
              "                    15, 15, 15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15,\n",
              "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
              "                    15, 15, 15, 15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
              "                    15, 15, 15, 15, 15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
              "                    15, 15, 15, 15, 15, 15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
              "                    15, 15, 15, 15, 15, 15, 15, 15],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_min_samples_split': masked_array(data=[2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15,\n",
              "                    15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10,\n",
              "                    10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5,\n",
              "                    5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2,\n",
              "                    2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15,\n",
              "                    15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
              "                    10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
              "                    10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2,\n",
              "                    5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15,\n",
              "                    2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15,\n",
              "                    15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10,\n",
              "                    10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5,\n",
              "                    5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2,\n",
              "                    2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15,\n",
              "                    15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
              "                    10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
              "                    10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2,\n",
              "                    5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15,\n",
              "                    2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15,\n",
              "                    15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10,\n",
              "                    10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5,\n",
              "                    5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2,\n",
              "                    2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15,\n",
              "                    15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
              "                    10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
              "                    10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2,\n",
              "                    5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15,\n",
              "                    2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15,\n",
              "                    15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10,\n",
              "                    10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5,\n",
              "                    5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2,\n",
              "                    2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15,\n",
              "                    15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
              "                    10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
              "                    10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2,\n",
              "                    5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15,\n",
              "                    2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15,\n",
              "                    15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10,\n",
              "                    10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5,\n",
              "                    5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2,\n",
              "                    2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15,\n",
              "                    15, 15],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_n_estimators': masked_array(data=[10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
              "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
              "                    100, 150],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'gini',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 10,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 20,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 10,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 2,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 5,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 10,\n",
              "   'n_estimators': 150},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 10},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 20},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 50},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 100},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 100,\n",
              "   'min_samples_leaf': 15,\n",
              "   'min_samples_split': 15,\n",
              "   'n_estimators': 150}],\n",
              " 'rank_test_score': array([626, 567, 583, 521, 405, 605, 176, 176, 521, 446, 313, 506, 255,\n",
              "        262,  56, 191, 440, 144, 378,  88, 554, 502, 262, 220, 191, 446,\n",
              "        475, 394, 405, 262, 348, 191, 475,  93, 144, 613, 493, 405,   4,\n",
              "         88, 554, 538, 144, 144,  93, 506,  84, 144,  68, 107, 521,  56,\n",
              "         26, 255,  40,  72, 475, 405, 117, 262, 144, 405, 475, 220, 394,\n",
              "        299, 493, 394,  72, 446,  11, 348, 144, 475, 378, 506,  17, 405,\n",
              "        405, 343, 621, 599, 502, 343, 405, 554, 506, 170, 262, 220, 615,\n",
              "         72, 313, 521, 405, 583, 580, 144, 144, 405, 405,  17, 191,  46,\n",
              "         26, 593,  88, 599, 217, 220, 613, 493, 117,  11,  26, 446, 446,\n",
              "        440, 176, 191, 599, 255, 583, 176, 191, 144, 191, 220, 550, 191,\n",
              "        521, 589, 446, 348, 378, 446, 446, 217,  26, 170, 611,  10,  40,\n",
              "         26, 521, 470, 554, 604,  26, 493, 635, 474, 506, 562, 299, 176,\n",
              "        117, 117, 176, 378, 475, 626, 107, 378, 502,   5, 591, 262,  88,\n",
              "        107, 440,  26, 538, 220, 262,  56, 313, 262, 493, 191, 550,  26,\n",
              "        220,  26, 313, 521, 378,  72,  84, 262, 144, 405,  93, 220, 117,\n",
              "        609, 299,  88, 176,  68,   8, 475, 255, 117, 220, 262, 538, 220,\n",
              "         84,  46, 405,  93, 117, 562, 313,  56, 176, 405,   1, 117, 506,\n",
              "        405, 475, 475, 299, 616, 191, 191, 370, 521,   6, 598, 589, 220,\n",
              "        220, 220, 348, 405, 493, 117, 596, 616, 605, 475, 521, 629, 535,\n",
              "        440, 446, 348,  56,  68, 117, 220, 220, 623, 313,  26, 262, 348,\n",
              "        616, 313,  46, 191,  56, 262, 394, 144,  46, 191, 217, 575,  93,\n",
              "        260, 446, 262,  71, 220, 176,  26,  46, 580,  93,  72, 370, 405,\n",
              "        348,  11, 191, 378, 538, 191, 262, 220, 405, 117, 562, 144, 348,\n",
              "        262, 262, 191,  56, 313, 348, 446, 537, 538, 583, 313, 580, 348,\n",
              "        405, 313,  84, 405, 144, 117,  40, 107, 626, 592, 475, 262, 446,\n",
              "        639, 593, 313, 446, 446, 636,  72, 117, 506, 191, 348, 262, 475,\n",
              "        191, 117, 262,  17, 521, 220, 176,  72, 170, 313, 405, 107, 638,\n",
              "        535,  17, 475, 405, 521, 117,  56,  56,  72, 313, 370,  40, 348,\n",
              "        191, 575, 405,  72, 220, 262, 502,  17, 405,  40, 440, 313, 262,\n",
              "        220, 176,  72, 621, 378, 378, 220, 262, 313, 260,  11, 377, 506,\n",
              "        348, 299, 554, 405, 262, 506, 220,  56, 117, 313, 632, 623, 538,\n",
              "        348, 117, 599, 220, 262, 470, 313, 262, 117, 262, 313, 348, 634,\n",
              "        107, 262, 313, 405, 313, 493, 107, 117, 348, 405, 378, 262, 313,\n",
              "        117, 220, 583, 117, 299, 191,  26, 521, 299, 107, 446, 554, 348,\n",
              "        313, 313, 117, 475,  46, 538,  93,  93, 605, 446,  56, 405, 170,\n",
              "        567, 117, 313, 117, 348, 144,   1, 596, 475, 299, 637, 299, 405,\n",
              "         46, 220, 633,  39, 348, 475, 262, 262,  24, 262, 170, 299, 620,\n",
              "        605, 405, 405, 378, 567, 629, 562, 506, 394, 609, 394, 299, 348,\n",
              "        262, 394,  17, 216, 299,  93, 144, 493,  46, 191,   7,  46, 117,\n",
              "         24, 446, 262, 629, 343, 378, 176, 176, 220, 378, 394, 405, 144,\n",
              "        575, 220,   3, 446, 255, 611, 220, 107, 343, 144, 550,  26,  72,\n",
              "        313, 170, 554,   9,  93, 191, 446, 378, 348, 220, 370,  15, 144,\n",
              "        446,  46,  93, 117, 538, 446, 378, 220, 506, 623, 440, 475, 313,\n",
              "        446, 599, 567, 521, 575, 405, 583, 262, 220, 550, 313, 475, 446,\n",
              "        191, 313, 220, 538, 299, 370, 117, 106, 567, 567, 144, 220, 144,\n",
              "        567, 343, 493,  72, 370, 593, 313,  16, 220,  93, 521, 405, 144,\n",
              "        144, 262, 506, 262, 554, 470, 313, 506, 394, 144, 370, 220, 616,\n",
              "        538, 575,  93, 378, 639,  40, 144, 394,  56,  17, 562, 107, 506,\n",
              "        144, 405, 506, 470, 299, 191, 538, 394, 538, 262, 176, 567, 191,\n",
              "        176, 446, 348], dtype=int32),\n",
              " 'split0_test_score': array([0.58333333, 0.58333333, 0.60416667, 0.65625   , 0.625     ,\n",
              "        0.63541667, 0.59375   , 0.63541667, 0.64583333, 0.625     ,\n",
              "        0.69791667, 0.59375   , 0.64583333, 0.64583333, 0.65625   ,\n",
              "        0.63541667, 0.61458333, 0.625     , 0.64583333, 0.64583333,\n",
              "        0.58333333, 0.70833333, 0.65625   , 0.60416667, 0.65625   ,\n",
              "        0.63541667, 0.67708333, 0.63541667, 0.61458333, 0.63541667,\n",
              "        0.65625   , 0.64583333, 0.625     , 0.64583333, 0.64583333,\n",
              "        0.58333333, 0.61458333, 0.61458333, 0.6875    , 0.64583333,\n",
              "        0.5625    , 0.59375   , 0.66666667, 0.625     , 0.63541667,\n",
              "        0.63541667, 0.66666667, 0.625     , 0.625     , 0.64583333,\n",
              "        0.59375   , 0.67708333, 0.70833333, 0.625     , 0.63541667,\n",
              "        0.67708333, 0.61458333, 0.65625   , 0.67708333, 0.625     ,\n",
              "        0.61458333, 0.60416667, 0.60416667, 0.61458333, 0.61458333,\n",
              "        0.67708333, 0.65625   , 0.65625   , 0.66666667, 0.61458333,\n",
              "        0.625     , 0.67708333, 0.60416667, 0.65625   , 0.63541667,\n",
              "        0.59375   , 0.66666667, 0.69791667, 0.61458333, 0.625     ,\n",
              "        0.58333333, 0.67708333, 0.66666667, 0.65625   , 0.6875    ,\n",
              "        0.64583333, 0.60416667, 0.63541667, 0.66666667, 0.6875    ,\n",
              "        0.64583333, 0.67708333, 0.65625   , 0.63541667, 0.64583333,\n",
              "        0.61458333, 0.65625   , 0.66666667, 0.625     , 0.64583333,\n",
              "        0.63541667, 0.66666667, 0.625     , 0.65625   , 0.65625   ,\n",
              "        0.64583333, 0.67708333, 0.59375   , 0.64583333, 0.64583333,\n",
              "        0.61458333, 0.66666667, 0.625     , 0.64583333, 0.64583333,\n",
              "        0.6875    , 0.66666667, 0.64583333, 0.65625   , 0.65625   ,\n",
              "        0.59375   , 0.69791667, 0.60416667, 0.64583333, 0.65625   ,\n",
              "        0.71875   , 0.61458333, 0.66666667, 0.60416667, 0.63541667,\n",
              "        0.67708333, 0.61458333, 0.63541667, 0.625     , 0.60416667,\n",
              "        0.61458333, 0.63541667, 0.625     , 0.67708333, 0.60416667,\n",
              "        0.66666667, 0.63541667, 0.59375   , 0.625     , 0.60416667,\n",
              "        0.71875   , 0.61458333, 0.58333333, 0.66666667, 0.625     ,\n",
              "        0.57291667, 0.67708333, 0.59375   , 0.60416667, 0.63541667,\n",
              "        0.625     , 0.65625   , 0.60416667, 0.64583333, 0.61458333,\n",
              "        0.61458333, 0.5625    , 0.64583333, 0.61458333, 0.61458333,\n",
              "        0.70833333, 0.63541667, 0.64583333, 0.66666667, 0.64583333,\n",
              "        0.67708333, 0.69791667, 0.63541667, 0.63541667, 0.63541667,\n",
              "        0.64583333, 0.66666667, 0.625     , 0.63541667, 0.63541667,\n",
              "        0.69791667, 0.65625   , 0.67708333, 0.67708333, 0.63541667,\n",
              "        0.64583333, 0.65625   , 0.61458333, 0.6875    , 0.63541667,\n",
              "        0.67708333, 0.625     , 0.64583333, 0.63541667, 0.64583333,\n",
              "        0.67708333, 0.64583333, 0.67708333, 0.63541667, 0.65625   ,\n",
              "        0.70833333, 0.5625    , 0.65625   , 0.625     , 0.61458333,\n",
              "        0.61458333, 0.65625   , 0.67708333, 0.65625   , 0.64583333,\n",
              "        0.64583333, 0.64583333, 0.61458333, 0.60416667, 0.61458333,\n",
              "        0.72916667, 0.67708333, 0.625     , 0.64583333, 0.60416667,\n",
              "        0.625     , 0.59375   , 0.625     , 0.61458333, 0.61458333,\n",
              "        0.60416667, 0.66666667, 0.6875    , 0.60416667, 0.625     ,\n",
              "        0.65625   , 0.70833333, 0.63541667, 0.625     , 0.625     ,\n",
              "        0.72916667, 0.67708333, 0.61458333, 0.63541667, 0.625     ,\n",
              "        0.66666667, 0.61458333, 0.60416667, 0.64583333, 0.65625   ,\n",
              "        0.64583333, 0.65625   , 0.61458333, 0.64583333, 0.65625   ,\n",
              "        0.70833333, 0.63541667, 0.67708333, 0.64583333, 0.61458333,\n",
              "        0.64583333, 0.67708333, 0.65625   , 0.625     , 0.63541667,\n",
              "        0.5625    , 0.61458333, 0.69791667, 0.67708333, 0.65625   ,\n",
              "        0.65625   , 0.59375   , 0.65625   , 0.66666667, 0.63541667,\n",
              "        0.70833333, 0.64583333, 0.65625   , 0.61458333, 0.63541667,\n",
              "        0.67708333, 0.625     , 0.64583333, 0.61458333, 0.65625   ,\n",
              "        0.72916667, 0.625     , 0.60416667, 0.64583333, 0.63541667,\n",
              "        0.6875    , 0.66666667, 0.61458333, 0.64583333, 0.63541667,\n",
              "        0.625     , 0.66666667, 0.65625   , 0.61458333, 0.61458333,\n",
              "        0.67708333, 0.63541667, 0.64583333, 0.65625   , 0.625     ,\n",
              "        0.625     , 0.66666667, 0.63541667, 0.625     , 0.625     ,\n",
              "        0.51041667, 0.58333333, 0.625     , 0.625     , 0.61458333,\n",
              "        0.60416667, 0.58333333, 0.60416667, 0.63541667, 0.65625   ,\n",
              "        0.60416667, 0.67708333, 0.65625   , 0.625     , 0.65625   ,\n",
              "        0.55208333, 0.59375   , 0.66666667, 0.63541667, 0.65625   ,\n",
              "        0.57291667, 0.64583333, 0.63541667, 0.61458333, 0.61458333,\n",
              "        0.625     , 0.67708333, 0.65625   , 0.67708333, 0.63541667,\n",
              "        0.57291667, 0.65625   , 0.66666667, 0.66666667, 0.67708333,\n",
              "        0.67708333, 0.71875   , 0.66666667, 0.61458333, 0.64583333,\n",
              "        0.70833333, 0.64583333, 0.67708333, 0.63541667, 0.64583333,\n",
              "        0.54166667, 0.66666667, 0.67708333, 0.61458333, 0.61458333,\n",
              "        0.61458333, 0.69791667, 0.65625   , 0.69791667, 0.65625   ,\n",
              "        0.57291667, 0.625     , 0.64583333, 0.63541667, 0.65625   ,\n",
              "        0.625     , 0.65625   , 0.63541667, 0.67708333, 0.625     ,\n",
              "        0.64583333, 0.63541667, 0.65625   , 0.65625   , 0.61458333,\n",
              "        0.60416667, 0.70833333, 0.63541667, 0.61458333, 0.64583333,\n",
              "        0.70833333, 0.65625   , 0.69791667, 0.63541667, 0.66666667,\n",
              "        0.69791667, 0.67708333, 0.67708333, 0.64583333, 0.6875    ,\n",
              "        0.60416667, 0.58333333, 0.61458333, 0.64583333, 0.63541667,\n",
              "        0.65625   , 0.64583333, 0.63541667, 0.65625   , 0.61458333,\n",
              "        0.67708333, 0.61458333, 0.64583333, 0.61458333, 0.64583333,\n",
              "        0.59375   , 0.66666667, 0.66666667, 0.625     , 0.63541667,\n",
              "        0.625     , 0.67708333, 0.66666667, 0.66666667, 0.67708333,\n",
              "        0.6875    , 0.6875    , 0.64583333, 0.63541667, 0.65625   ,\n",
              "        0.71875   , 0.63541667, 0.67708333, 0.64583333, 0.63541667,\n",
              "        0.6875    , 0.63541667, 0.64583333, 0.65625   , 0.66666667,\n",
              "        0.625     , 0.67708333, 0.67708333, 0.63541667, 0.63541667,\n",
              "        0.69791667, 0.72916667, 0.66666667, 0.65625   , 0.63541667,\n",
              "        0.59375   , 0.63541667, 0.625     , 0.63541667, 0.67708333,\n",
              "        0.64583333, 0.64583333, 0.58333333, 0.65625   , 0.67708333,\n",
              "        0.63541667, 0.59375   , 0.65625   , 0.67708333, 0.66666667,\n",
              "        0.61458333, 0.625     , 0.63541667, 0.65625   , 0.63541667,\n",
              "        0.65625   , 0.70833333, 0.57291667, 0.58333333, 0.625     ,\n",
              "        0.61458333, 0.65625   , 0.60416667, 0.66666667, 0.63541667,\n",
              "        0.59375   , 0.625     , 0.66666667, 0.61458333, 0.63541667,\n",
              "        0.625     , 0.63541667, 0.65625   , 0.66666667, 0.66666667,\n",
              "        0.63541667, 0.63541667, 0.65625   , 0.625     , 0.64583333,\n",
              "        0.64583333, 0.60416667, 0.6875    , 0.60416667, 0.64583333,\n",
              "        0.64583333, 0.66666667, 0.67708333, 0.64583333, 0.64583333,\n",
              "        0.63541667, 0.6875    , 0.65625   , 0.67708333, 0.65625   ,\n",
              "        0.70833333, 0.63541667, 0.69791667, 0.64583333, 0.66666667,\n",
              "        0.71875   , 0.625     , 0.71875   , 0.60416667, 0.61458333,\n",
              "        0.58333333, 0.625     , 0.61458333, 0.64583333, 0.64583333,\n",
              "        0.66666667, 0.60416667, 0.63541667, 0.625     , 0.64583333,\n",
              "        0.58333333, 0.66666667, 0.66666667, 0.625     , 0.63541667,\n",
              "        0.5625    , 0.67708333, 0.6875    , 0.59375   , 0.63541667,\n",
              "        0.63541667, 0.70833333, 0.66666667, 0.65625   , 0.625     ,\n",
              "        0.61458333, 0.66666667, 0.63541667, 0.63541667, 0.625     ,\n",
              "        0.69791667, 0.66666667, 0.60416667, 0.625     , 0.66666667,\n",
              "        0.59375   , 0.69791667, 0.63541667, 0.69791667, 0.66666667,\n",
              "        0.64583333, 0.63541667, 0.61458333, 0.63541667, 0.59375   ,\n",
              "        0.59375   , 0.66666667, 0.61458333, 0.66666667, 0.59375   ,\n",
              "        0.61458333, 0.64583333, 0.63541667, 0.61458333, 0.64583333,\n",
              "        0.65625   , 0.70833333, 0.63541667, 0.60416667, 0.61458333,\n",
              "        0.64583333, 0.6875    , 0.67708333, 0.63541667, 0.63541667,\n",
              "        0.63541667, 0.625     , 0.60416667, 0.66666667, 0.65625   ,\n",
              "        0.61458333, 0.65625   , 0.65625   , 0.67708333, 0.67708333,\n",
              "        0.66666667, 0.64583333, 0.625     , 0.67708333, 0.63541667,\n",
              "        0.625     , 0.6875    , 0.67708333, 0.64583333, 0.63541667,\n",
              "        0.625     , 0.63541667, 0.70833333, 0.65625   , 0.66666667,\n",
              "        0.69791667, 0.66666667, 0.61458333, 0.60416667, 0.65625   ,\n",
              "        0.59375   , 0.63541667, 0.61458333, 0.63541667, 0.61458333,\n",
              "        0.61458333, 0.61458333, 0.5625    , 0.67708333, 0.61458333,\n",
              "        0.66666667, 0.6875    , 0.64583333, 0.65625   , 0.70833333,\n",
              "        0.71875   , 0.625     , 0.65625   , 0.63541667, 0.61458333,\n",
              "        0.63541667, 0.66666667, 0.61458333, 0.65625   , 0.65625   ,\n",
              "        0.69791667, 0.60416667, 0.63541667, 0.64583333, 0.63541667,\n",
              "        0.64583333, 0.625     , 0.65625   , 0.63541667, 0.65625   ]),\n",
              " 'split1_test_score': array([0.64583333, 0.6875    , 0.61458333, 0.59375   , 0.64583333,\n",
              "        0.58333333, 0.70833333, 0.64583333, 0.63541667, 0.63541667,\n",
              "        0.69791667, 0.67708333, 0.63541667, 0.67708333, 0.66666667,\n",
              "        0.67708333, 0.65625   , 0.70833333, 0.65625   , 0.67708333,\n",
              "        0.65625   , 0.61458333, 0.66666667, 0.69791667, 0.66666667,\n",
              "        0.65625   , 0.66666667, 0.65625   , 0.63541667, 0.66666667,\n",
              "        0.71875   , 0.65625   , 0.65625   , 0.69791667, 0.66666667,\n",
              "        0.59375   , 0.6875    , 0.65625   , 0.70833333, 0.6875    ,\n",
              "        0.67708333, 0.6875    , 0.66666667, 0.69791667, 0.69791667,\n",
              "        0.67708333, 0.71875   , 0.69791667, 0.69791667, 0.69791667,\n",
              "        0.64583333, 0.6875    , 0.69791667, 0.69791667, 0.69791667,\n",
              "        0.625     , 0.67708333, 0.66666667, 0.66666667, 0.66666667,\n",
              "        0.70833333, 0.73958333, 0.70833333, 0.6875    , 0.69791667,\n",
              "        0.77083333, 0.71875   , 0.6875    , 0.70833333, 0.6875    ,\n",
              "        0.75      , 0.69791667, 0.70833333, 0.66666667, 0.67708333,\n",
              "        0.63541667, 0.71875   , 0.67708333, 0.70833333, 0.67708333,\n",
              "        0.57291667, 0.63541667, 0.61458333, 0.64583333, 0.58333333,\n",
              "        0.63541667, 0.64583333, 0.625     , 0.64583333, 0.63541667,\n",
              "        0.59375   , 0.65625   , 0.65625   , 0.65625   , 0.63541667,\n",
              "        0.6875    , 0.625     , 0.64583333, 0.65625   , 0.63541667,\n",
              "        0.66666667, 0.6875    , 0.66666667, 0.66666667, 0.6875    ,\n",
              "        0.69791667, 0.67708333, 0.6875    , 0.67708333, 0.63541667,\n",
              "        0.70833333, 0.65625   , 0.66666667, 0.66666667, 0.69791667,\n",
              "        0.65625   , 0.66666667, 0.6875    , 0.67708333, 0.63541667,\n",
              "        0.67708333, 0.6875    , 0.70833333, 0.67708333, 0.6875    ,\n",
              "        0.67708333, 0.71875   , 0.65625   , 0.66666667, 0.71875   ,\n",
              "        0.66666667, 0.69791667, 0.66666667, 0.65625   , 0.66666667,\n",
              "        0.67708333, 0.72916667, 0.70833333, 0.70833333, 0.67708333,\n",
              "        0.625     , 0.75      , 0.73958333, 0.73958333, 0.67708333,\n",
              "        0.76041667, 0.67708333, 0.6875    , 0.6875    , 0.66666667,\n",
              "        0.66666667, 0.67708333, 0.67708333, 0.64583333, 0.67708333,\n",
              "        0.70833333, 0.69791667, 0.75      , 0.67708333, 0.69791667,\n",
              "        0.625     , 0.60416667, 0.67708333, 0.65625   , 0.625     ,\n",
              "        0.70833333, 0.65625   , 0.66666667, 0.67708333, 0.67708333,\n",
              "        0.64583333, 0.67708333, 0.66666667, 0.64583333, 0.61458333,\n",
              "        0.67708333, 0.61458333, 0.65625   , 0.625     , 0.66666667,\n",
              "        0.65625   , 0.64583333, 0.63541667, 0.65625   , 0.66666667,\n",
              "        0.72916667, 0.67708333, 0.69791667, 0.65625   , 0.63541667,\n",
              "        0.6875    , 0.64583333, 0.66666667, 0.69791667, 0.6875    ,\n",
              "        0.65625   , 0.70833333, 0.64583333, 0.6875    , 0.69791667,\n",
              "        0.75      , 0.65625   , 0.69791667, 0.67708333, 0.6875    ,\n",
              "        0.76041667, 0.65625   , 0.65625   , 0.69791667, 0.69791667,\n",
              "        0.6875    , 0.69791667, 0.6875    , 0.65625   , 0.6875    ,\n",
              "        0.73958333, 0.64583333, 0.625     , 0.78125   , 0.6875    ,\n",
              "        0.63541667, 0.67708333, 0.65625   , 0.65625   , 0.69791667,\n",
              "        0.70833333, 0.75      , 0.6875    , 0.69791667, 0.64583333,\n",
              "        0.6875    , 0.67708333, 0.66666667, 0.67708333, 0.69791667,\n",
              "        0.69791667, 0.69791667, 0.66666667, 0.69791667, 0.72916667,\n",
              "        0.65625   , 0.6875    , 0.55208333, 0.60416667, 0.60416667,\n",
              "        0.625     , 0.625     , 0.63541667, 0.625     , 0.65625   ,\n",
              "        0.65625   , 0.6875    , 0.69791667, 0.625     , 0.63541667,\n",
              "        0.65625   , 0.64583333, 0.6875    , 0.65625   , 0.65625   ,\n",
              "        0.67708333, 0.6875    , 0.70833333, 0.67708333, 0.65625   ,\n",
              "        0.73958333, 0.69791667, 0.6875    , 0.6875    , 0.64583333,\n",
              "        0.70833333, 0.65625   , 0.70833333, 0.6875    , 0.64583333,\n",
              "        0.59375   , 0.70833333, 0.63541667, 0.66666667, 0.6875    ,\n",
              "        0.6875    , 0.71875   , 0.67708333, 0.70833333, 0.6875    ,\n",
              "        0.67708333, 0.65625   , 0.75      , 0.69791667, 0.65625   ,\n",
              "        0.69791667, 0.71875   , 0.70833333, 0.70833333, 0.67708333,\n",
              "        0.67708333, 0.6875    , 0.69791667, 0.67708333, 0.6875    ,\n",
              "        0.72916667, 0.75      , 0.72916667, 0.66666667, 0.6875    ,\n",
              "        0.64583333, 0.6875    , 0.67708333, 0.67708333, 0.67708333,\n",
              "        0.63541667, 0.69791667, 0.67708333, 0.66666667, 0.67708333,\n",
              "        0.65625   , 0.70833333, 0.69791667, 0.70833333, 0.70833333,\n",
              "        0.55208333, 0.67708333, 0.625     , 0.64583333, 0.64583333,\n",
              "        0.61458333, 0.69791667, 0.65625   , 0.70833333, 0.63541667,\n",
              "        0.61458333, 0.64583333, 0.63541667, 0.63541667, 0.67708333,\n",
              "        0.64583333, 0.625     , 0.65625   , 0.64583333, 0.64583333,\n",
              "        0.6875    , 0.69791667, 0.63541667, 0.69791667, 0.67708333,\n",
              "        0.67708333, 0.67708333, 0.65625   , 0.64583333, 0.6875    ,\n",
              "        0.65625   , 0.63541667, 0.67708333, 0.625     , 0.64583333,\n",
              "        0.6875    , 0.70833333, 0.6875    , 0.65625   , 0.6875    ,\n",
              "        0.72916667, 0.69791667, 0.66666667, 0.67708333, 0.65625   ,\n",
              "        0.70833333, 0.65625   , 0.69791667, 0.64583333, 0.64583333,\n",
              "        0.73958333, 0.77083333, 0.66666667, 0.6875    , 0.6875    ,\n",
              "        0.6875    , 0.67708333, 0.66666667, 0.67708333, 0.6875    ,\n",
              "        0.66666667, 0.65625   , 0.67708333, 0.71875   , 0.6875    ,\n",
              "        0.6875    , 0.70833333, 0.67708333, 0.67708333, 0.65625   ,\n",
              "        0.75      , 0.6875    , 0.66666667, 0.64583333, 0.66666667,\n",
              "        0.6875    , 0.65625   , 0.64583333, 0.67708333, 0.66666667,\n",
              "        0.5625    , 0.58333333, 0.60416667, 0.64583333, 0.625     ,\n",
              "        0.63541667, 0.67708333, 0.67708333, 0.63541667, 0.64583333,\n",
              "        0.69791667, 0.65625   , 0.67708333, 0.625     , 0.625     ,\n",
              "        0.61458333, 0.65625   , 0.67708333, 0.64583333, 0.66666667,\n",
              "        0.6875    , 0.6875    , 0.64583333, 0.65625   , 0.625     ,\n",
              "        0.63541667, 0.69791667, 0.66666667, 0.66666667, 0.66666667,\n",
              "        0.64583333, 0.625     , 0.65625   , 0.64583333, 0.65625   ,\n",
              "        0.67708333, 0.67708333, 0.64583333, 0.67708333, 0.66666667,\n",
              "        0.67708333, 0.64583333, 0.6875    , 0.66666667, 0.66666667,\n",
              "        0.67708333, 0.70833333, 0.6875    , 0.70833333, 0.67708333,\n",
              "        0.67708333, 0.69791667, 0.69791667, 0.66666667, 0.65625   ,\n",
              "        0.6875    , 0.69791667, 0.6875    , 0.66666667, 0.65625   ,\n",
              "        0.67708333, 0.73958333, 0.66666667, 0.64583333, 0.65625   ,\n",
              "        0.64583333, 0.67708333, 0.69791667, 0.67708333, 0.6875    ,\n",
              "        0.61458333, 0.78125   , 0.6875    , 0.65625   , 0.6875    ,\n",
              "        0.64583333, 0.72916667, 0.70833333, 0.65625   , 0.64583333,\n",
              "        0.5625    , 0.60416667, 0.61458333, 0.61458333, 0.61458333,\n",
              "        0.60416667, 0.58333333, 0.59375   , 0.63541667, 0.63541667,\n",
              "        0.63541667, 0.6875    , 0.64583333, 0.63541667, 0.63541667,\n",
              "        0.6875    , 0.75      , 0.66666667, 0.67708333, 0.66666667,\n",
              "        0.66666667, 0.65625   , 0.65625   , 0.64583333, 0.69791667,\n",
              "        0.6875    , 0.69791667, 0.63541667, 0.66666667, 0.66666667,\n",
              "        0.63541667, 0.65625   , 0.66666667, 0.65625   , 0.66666667,\n",
              "        0.6875    , 0.65625   , 0.65625   , 0.67708333, 0.66666667,\n",
              "        0.70833333, 0.67708333, 0.70833333, 0.65625   , 0.65625   ,\n",
              "        0.65625   , 0.65625   , 0.67708333, 0.67708333, 0.66666667,\n",
              "        0.73958333, 0.70833333, 0.66666667, 0.65625   , 0.66666667,\n",
              "        0.65625   , 0.73958333, 0.66666667, 0.69791667, 0.67708333,\n",
              "        0.72916667, 0.69791667, 0.69791667, 0.66666667, 0.66666667,\n",
              "        0.71875   , 0.67708333, 0.67708333, 0.66666667, 0.69791667,\n",
              "        0.66666667, 0.67708333, 0.70833333, 0.65625   , 0.66666667,\n",
              "        0.67708333, 0.70833333, 0.64583333, 0.67708333, 0.66666667,\n",
              "        0.61458333, 0.63541667, 0.625     , 0.59375   , 0.625     ,\n",
              "        0.64583333, 0.625     , 0.64583333, 0.61458333, 0.67708333,\n",
              "        0.69791667, 0.70833333, 0.65625   , 0.63541667, 0.66666667,\n",
              "        0.64583333, 0.67708333, 0.65625   , 0.66666667, 0.66666667,\n",
              "        0.64583333, 0.65625   , 0.6875    , 0.63541667, 0.66666667,\n",
              "        0.63541667, 0.6875    , 0.65625   , 0.6875    , 0.64583333,\n",
              "        0.59375   , 0.67708333, 0.71875   , 0.67708333, 0.65625   ,\n",
              "        0.64583333, 0.64583333, 0.67708333, 0.67708333, 0.66666667,\n",
              "        0.60416667, 0.67708333, 0.67708333, 0.65625   , 0.65625   ,\n",
              "        0.65625   , 0.6875    , 0.67708333, 0.65625   , 0.66666667,\n",
              "        0.6875    , 0.63541667, 0.64583333, 0.69791667, 0.64583333,\n",
              "        0.60416667, 0.66666667, 0.6875    , 0.69791667, 0.66666667,\n",
              "        0.73958333, 0.63541667, 0.70833333, 0.64583333, 0.66666667,\n",
              "        0.65625   , 0.73958333, 0.66666667, 0.6875    , 0.66666667,\n",
              "        0.73958333, 0.72916667, 0.65625   , 0.67708333, 0.71875   ,\n",
              "        0.6875    , 0.64583333, 0.67708333, 0.65625   , 0.65625   ]),\n",
              " 'split2_test_score': array([0.69791667, 0.65625   , 0.70833333, 0.67708333, 0.70833333,\n",
              "        0.61458333, 0.70833333, 0.67708333, 0.63541667, 0.67708333,\n",
              "        0.57291667, 0.625     , 0.69791667, 0.69791667, 0.70833333,\n",
              "        0.64583333, 0.64583333, 0.73958333, 0.6875    , 0.69791667,\n",
              "        0.71875   , 0.6875    , 0.6875    , 0.69791667, 0.6875    ,\n",
              "        0.67708333, 0.625     , 0.67708333, 0.6875    , 0.6875    ,\n",
              "        0.64583333, 0.69791667, 0.64583333, 0.69791667, 0.6875    ,\n",
              "        0.67708333, 0.66666667, 0.6875    , 0.69791667, 0.6875    ,\n",
              "        0.6875    , 0.66666667, 0.66666667, 0.73958333, 0.6875    ,\n",
              "        0.63541667, 0.6875    , 0.67708333, 0.71875   , 0.67708333,\n",
              "        0.64583333, 0.72916667, 0.67708333, 0.6875    , 0.69791667,\n",
              "        0.69791667, 0.66666667, 0.65625   , 0.69791667, 0.70833333,\n",
              "        0.6875    , 0.625     , 0.625     , 0.6875    , 0.69791667,\n",
              "        0.59375   , 0.69791667, 0.6875    , 0.70833333, 0.69791667,\n",
              "        0.70833333, 0.64583333, 0.70833333, 0.65625   , 0.70833333,\n",
              "        0.69791667, 0.69791667, 0.66666667, 0.67708333, 0.64583333,\n",
              "        0.65625   , 0.64583333, 0.70833333, 0.6875    , 0.69791667,\n",
              "        0.64583333, 0.76041667, 0.70833333, 0.70833333, 0.6875    ,\n",
              "        0.6875    , 0.70833333, 0.70833333, 0.66666667, 0.69791667,\n",
              "        0.70833333, 0.60416667, 0.71875   , 0.70833333, 0.64583333,\n",
              "        0.6875    , 0.71875   , 0.6875    , 0.71875   , 0.70833333,\n",
              "        0.60416667, 0.64583333, 0.60416667, 0.6875    , 0.71875   ,\n",
              "        0.60416667, 0.69791667, 0.71875   , 0.73958333, 0.70833333,\n",
              "        0.66666667, 0.64583333, 0.61458333, 0.70833333, 0.70833333,\n",
              "        0.59375   , 0.65625   , 0.67708333, 0.66666667, 0.66666667,\n",
              "        0.65625   , 0.6875    , 0.66666667, 0.625     , 0.69791667,\n",
              "        0.65625   , 0.66666667, 0.61458333, 0.70833333, 0.6875    ,\n",
              "        0.61458333, 0.69791667, 0.6875    , 0.69791667, 0.71875   ,\n",
              "        0.66666667, 0.69791667, 0.69791667, 0.69791667, 0.67708333,\n",
              "        0.63541667, 0.65625   , 0.66666667, 0.70833333, 0.67708333,\n",
              "        0.58333333, 0.71875   , 0.65625   , 0.6875    , 0.6875    ,\n",
              "        0.64583333, 0.72916667, 0.72916667, 0.66666667, 0.67708333,\n",
              "        0.71875   , 0.63541667, 0.71875   , 0.6875    , 0.70833333,\n",
              "        0.6875    , 0.66666667, 0.70833333, 0.71875   , 0.69791667,\n",
              "        0.65625   , 0.70833333, 0.63541667, 0.69791667, 0.75      ,\n",
              "        0.66666667, 0.6875    , 0.70833333, 0.66666667, 0.67708333,\n",
              "        0.60416667, 0.71875   , 0.66666667, 0.71875   , 0.6875    ,\n",
              "        0.71875   , 0.70833333, 0.67708333, 0.69791667, 0.69791667,\n",
              "        0.67708333, 0.71875   , 0.70833333, 0.66666667, 0.69791667,\n",
              "        0.55208333, 0.6875    , 0.71875   , 0.67708333, 0.69791667,\n",
              "        0.67708333, 0.71875   , 0.66666667, 0.69791667, 0.70833333,\n",
              "        0.6875    , 0.67708333, 0.6875    , 0.67708333, 0.69791667,\n",
              "        0.69791667, 0.64583333, 0.69791667, 0.6875    , 0.69791667,\n",
              "        0.70833333, 0.69791667, 0.66666667, 0.67708333, 0.72916667,\n",
              "        0.64583333, 0.64583333, 0.64583333, 0.67708333, 0.70833333,\n",
              "        0.61458333, 0.71875   , 0.6875    , 0.6875    , 0.66666667,\n",
              "        0.67708333, 0.65625   , 0.64583333, 0.69791667, 0.6875    ,\n",
              "        0.65625   , 0.66666667, 0.70833333, 0.71875   , 0.70833333,\n",
              "        0.63541667, 0.625     , 0.67708333, 0.70833333, 0.67708333,\n",
              "        0.55208333, 0.66666667, 0.70833333, 0.65625   , 0.6875    ,\n",
              "        0.6875    , 0.72916667, 0.67708333, 0.6875    , 0.70833333,\n",
              "        0.55208333, 0.65625   , 0.70833333, 0.69791667, 0.67708333,\n",
              "        0.67708333, 0.6875    , 0.6875    , 0.70833333, 0.70833333,\n",
              "        0.61458333, 0.72916667, 0.70833333, 0.71875   , 0.6875    ,\n",
              "        0.625     , 0.66666667, 0.66666667, 0.70833333, 0.67708333,\n",
              "        0.72916667, 0.67708333, 0.70833333, 0.67708333, 0.71875   ,\n",
              "        0.625     , 0.59375   , 0.69791667, 0.6875    , 0.69791667,\n",
              "        0.63541667, 0.67708333, 0.70833333, 0.66666667, 0.67708333,\n",
              "        0.64583333, 0.60416667, 0.65625   , 0.67708333, 0.67708333,\n",
              "        0.60416667, 0.63541667, 0.67708333, 0.65625   , 0.6875    ,\n",
              "        0.69791667, 0.625     , 0.6875    , 0.6875    , 0.67708333,\n",
              "        0.71875   , 0.64583333, 0.69791667, 0.69791667, 0.69791667,\n",
              "        0.77083333, 0.67708333, 0.67708333, 0.66666667, 0.69791667,\n",
              "        0.70833333, 0.67708333, 0.6875    , 0.69791667, 0.67708333,\n",
              "        0.66666667, 0.625     , 0.67708333, 0.71875   , 0.65625   ,\n",
              "        0.65625   , 0.67708333, 0.66666667, 0.64583333, 0.69791667,\n",
              "        0.61458333, 0.71875   , 0.71875   , 0.65625   , 0.6875    ,\n",
              "        0.69791667, 0.71875   , 0.625     , 0.6875    , 0.67708333,\n",
              "        0.67708333, 0.64583333, 0.64583333, 0.66666667, 0.69791667,\n",
              "        0.63541667, 0.70833333, 0.63541667, 0.6875    , 0.67708333,\n",
              "        0.67708333, 0.64583333, 0.70833333, 0.6875    , 0.69791667,\n",
              "        0.69791667, 0.66666667, 0.70833333, 0.67708333, 0.69791667,\n",
              "        0.6875    , 0.71875   , 0.70833333, 0.6875    , 0.6875    ,\n",
              "        0.64583333, 0.6875    , 0.69791667, 0.64583333, 0.6875    ,\n",
              "        0.63541667, 0.69791667, 0.63541667, 0.65625   , 0.6875    ,\n",
              "        0.70833333, 0.67708333, 0.6875    , 0.69791667, 0.6875    ,\n",
              "        0.59375   , 0.63541667, 0.66666667, 0.66666667, 0.67708333,\n",
              "        0.6875    , 0.625     , 0.69791667, 0.6875    , 0.66666667,\n",
              "        0.65625   , 0.67708333, 0.6875    , 0.69791667, 0.6875    ,\n",
              "        0.65625   , 0.71875   , 0.70833333, 0.66666667, 0.69791667,\n",
              "        0.59375   , 0.69791667, 0.67708333, 0.69791667, 0.72916667,\n",
              "        0.67708333, 0.71875   , 0.66666667, 0.69791667, 0.71875   ,\n",
              "        0.69791667, 0.6875    , 0.67708333, 0.6875    , 0.66666667,\n",
              "        0.58333333, 0.70833333, 0.66666667, 0.70833333, 0.64583333,\n",
              "        0.63541667, 0.66666667, 0.6875    , 0.69791667, 0.67708333,\n",
              "        0.66666667, 0.66666667, 0.69791667, 0.64583333, 0.71875   ,\n",
              "        0.64583333, 0.66666667, 0.66666667, 0.70833333, 0.6875    ,\n",
              "        0.6875    , 0.65625   , 0.67708333, 0.6875    , 0.66666667,\n",
              "        0.67708333, 0.65625   , 0.6875    , 0.67708333, 0.6875    ,\n",
              "        0.61458333, 0.70833333, 0.65625   , 0.66666667, 0.67708333,\n",
              "        0.66666667, 0.66666667, 0.70833333, 0.65625   , 0.6875    ,\n",
              "        0.67708333, 0.69791667, 0.67708333, 0.72916667, 0.6875    ,\n",
              "        0.70833333, 0.69791667, 0.6875    , 0.71875   , 0.6875    ,\n",
              "        0.58333333, 0.67708333, 0.625     , 0.69791667, 0.67708333,\n",
              "        0.60416667, 0.69791667, 0.69791667, 0.63541667, 0.70833333,\n",
              "        0.75      , 0.64583333, 0.66666667, 0.69791667, 0.6875    ,\n",
              "        0.66666667, 0.625     , 0.69791667, 0.70833333, 0.69791667,\n",
              "        0.71875   , 0.63541667, 0.6875    , 0.71875   , 0.66666667,\n",
              "        0.64583333, 0.64583333, 0.625     , 0.71875   , 0.69791667,\n",
              "        0.625     , 0.64583333, 0.69791667, 0.67708333, 0.6875    ,\n",
              "        0.67708333, 0.6875    , 0.6875    , 0.67708333, 0.70833333,\n",
              "        0.63541667, 0.70833333, 0.6875    , 0.67708333, 0.6875    ,\n",
              "        0.64583333, 0.70833333, 0.67708333, 0.67708333, 0.67708333,\n",
              "        0.65625   , 0.64583333, 0.66666667, 0.66666667, 0.6875    ,\n",
              "        0.67708333, 0.66666667, 0.72916667, 0.69791667, 0.69791667,\n",
              "        0.63541667, 0.69791667, 0.64583333, 0.6875    , 0.6875    ,\n",
              "        0.65625   , 0.65625   , 0.67708333, 0.67708333, 0.6875    ,\n",
              "        0.66666667, 0.6875    , 0.69791667, 0.6875    , 0.66666667,\n",
              "        0.63541667, 0.70833333, 0.69791667, 0.69791667, 0.71875   ,\n",
              "        0.71875   , 0.65625   , 0.72916667, 0.6875    , 0.67708333,\n",
              "        0.625     , 0.6875    , 0.6875    , 0.6875    , 0.66666667,\n",
              "        0.57291667, 0.67708333, 0.6875    , 0.65625   , 0.65625   ,\n",
              "        0.64583333, 0.64583333, 0.67708333, 0.67708333, 0.69791667,\n",
              "        0.625     , 0.67708333, 0.70833333, 0.69791667, 0.69791667,\n",
              "        0.625     , 0.63541667, 0.66666667, 0.67708333, 0.66666667,\n",
              "        0.67708333, 0.67708333, 0.66666667, 0.67708333, 0.69791667,\n",
              "        0.66666667, 0.625     , 0.67708333, 0.6875    , 0.6875    ,\n",
              "        0.65625   , 0.65625   , 0.6875    , 0.6875    , 0.66666667,\n",
              "        0.61458333, 0.69791667, 0.6875    , 0.67708333, 0.6875    ,\n",
              "        0.66666667, 0.71875   , 0.63541667, 0.67708333, 0.65625   ,\n",
              "        0.61458333, 0.69791667, 0.63541667, 0.6875    , 0.69791667,\n",
              "        0.63541667, 0.63541667, 0.71875   , 0.66666667, 0.6875    ,\n",
              "        0.60416667, 0.67708333, 0.69791667, 0.69791667, 0.66666667,\n",
              "        0.61458333, 0.70833333, 0.67708333, 0.66666667, 0.69791667,\n",
              "        0.67708333, 0.65625   , 0.67708333, 0.69791667, 0.6875    ,\n",
              "        0.625     , 0.66666667, 0.69791667, 0.67708333, 0.6875    ,\n",
              "        0.63541667, 0.67708333, 0.625     , 0.6875    , 0.70833333,\n",
              "        0.65625   , 0.72916667, 0.6875    , 0.65625   , 0.6875    ]),\n",
              " 'split3_test_score': array([0.69791667, 0.69791667, 0.6875    , 0.73958333, 0.72916667,\n",
              "        0.72916667, 0.78125   , 0.80208333, 0.75      , 0.77083333,\n",
              "        0.75      , 0.76041667, 0.76041667, 0.76041667, 0.77083333,\n",
              "        0.82291667, 0.78125   , 0.70833333, 0.73958333, 0.80208333,\n",
              "        0.73958333, 0.6875    , 0.73958333, 0.76041667, 0.75      ,\n",
              "        0.69791667, 0.73958333, 0.76041667, 0.76041667, 0.75      ,\n",
              "        0.76041667, 0.75      , 0.76041667, 0.77083333, 0.77083333,\n",
              "        0.65625   , 0.72916667, 0.73958333, 0.78125   , 0.78125   ,\n",
              "        0.71875   , 0.67708333, 0.77083333, 0.71875   , 0.77083333,\n",
              "        0.75      , 0.71875   , 0.75      , 0.72916667, 0.77083333,\n",
              "        0.75      , 0.72916667, 0.75      , 0.76041667, 0.77083333,\n",
              "        0.77083333, 0.75      , 0.72916667, 0.72916667, 0.73958333,\n",
              "        0.72916667, 0.77083333, 0.80208333, 0.72916667, 0.75      ,\n",
              "        0.70833333, 0.69791667, 0.72916667, 0.73958333, 0.69791667,\n",
              "        0.71875   , 0.72916667, 0.75      , 0.73958333, 0.73958333,\n",
              "        0.78125   , 0.77083333, 0.72916667, 0.73958333, 0.75      ,\n",
              "        0.71875   , 0.69791667, 0.71875   , 0.73958333, 0.75      ,\n",
              "        0.70833333, 0.69791667, 0.82291667, 0.75      , 0.75      ,\n",
              "        0.64583333, 0.72916667, 0.72916667, 0.73958333, 0.72916667,\n",
              "        0.64583333, 0.78125   , 0.73958333, 0.78125   , 0.79166667,\n",
              "        0.70833333, 0.71875   , 0.79166667, 0.79166667, 0.78125   ,\n",
              "        0.6875    , 0.77083333, 0.6875    , 0.73958333, 0.77083333,\n",
              "        0.67708333, 0.75      , 0.76041667, 0.79166667, 0.76041667,\n",
              "        0.6875    , 0.6875    , 0.75      , 0.72916667, 0.78125   ,\n",
              "        0.77083333, 0.72916667, 0.70833333, 0.77083333, 0.73958333,\n",
              "        0.71875   , 0.72916667, 0.80208333, 0.70833333, 0.70833333,\n",
              "        0.6875    , 0.65625   , 0.73958333, 0.76041667, 0.76041667,\n",
              "        0.77083333, 0.69791667, 0.70833333, 0.75      , 0.76041667,\n",
              "        0.72916667, 0.8125    , 0.80208333, 0.78125   , 0.71875   ,\n",
              "        0.65625   , 0.71875   , 0.70833333, 0.78125   , 0.76041667,\n",
              "        0.65625   , 0.67708333, 0.79166667, 0.76041667, 0.73958333,\n",
              "        0.80208333, 0.75      , 0.73958333, 0.77083333, 0.76041667,\n",
              "        0.73958333, 0.6875    , 0.73958333, 0.76041667, 0.71875   ,\n",
              "        0.73958333, 0.72916667, 0.75      , 0.73958333, 0.77083333,\n",
              "        0.71875   , 0.76041667, 0.73958333, 0.80208333, 0.75      ,\n",
              "        0.76041667, 0.78125   , 0.76041667, 0.79166667, 0.79166667,\n",
              "        0.72916667, 0.79166667, 0.73958333, 0.77083333, 0.75      ,\n",
              "        0.65625   , 0.71875   , 0.8125    , 0.78125   , 0.76041667,\n",
              "        0.78125   , 0.70833333, 0.76041667, 0.77083333, 0.77083333,\n",
              "        0.72916667, 0.73958333, 0.76041667, 0.77083333, 0.76041667,\n",
              "        0.73958333, 0.70833333, 0.76041667, 0.77083333, 0.76041667,\n",
              "        0.6875    , 0.71875   , 0.75      , 0.76041667, 0.76041667,\n",
              "        0.76041667, 0.79166667, 0.78125   , 0.71875   , 0.75      ,\n",
              "        0.70833333, 0.75      , 0.75      , 0.77083333, 0.77083333,\n",
              "        0.75      , 0.77083333, 0.76041667, 0.71875   , 0.75      ,\n",
              "        0.71875   , 0.66666667, 0.75      , 0.75      , 0.75      ,\n",
              "        0.79166667, 0.64583333, 0.72916667, 0.75      , 0.75      ,\n",
              "        0.67708333, 0.75      , 0.73958333, 0.67708333, 0.71875   ,\n",
              "        0.6875    , 0.6875    , 0.76041667, 0.72916667, 0.76041667,\n",
              "        0.6875    , 0.72916667, 0.73958333, 0.75      , 0.72916667,\n",
              "        0.76041667, 0.76041667, 0.71875   , 0.79166667, 0.8125    ,\n",
              "        0.6875    , 0.73958333, 0.80208333, 0.77083333, 0.78125   ,\n",
              "        0.66666667, 0.72916667, 0.75      , 0.72916667, 0.79166667,\n",
              "        0.8125    , 0.73958333, 0.75      , 0.73958333, 0.78125   ,\n",
              "        0.70833333, 0.71875   , 0.78125   , 0.73958333, 0.76041667,\n",
              "        0.73958333, 0.77083333, 0.75      , 0.78125   , 0.77083333,\n",
              "        0.75      , 0.76041667, 0.8125    , 0.75      , 0.71875   ,\n",
              "        0.6875    , 0.70833333, 0.75      , 0.73958333, 0.73958333,\n",
              "        0.70833333, 0.80208333, 0.75      , 0.70833333, 0.75      ,\n",
              "        0.79166667, 0.73958333, 0.73958333, 0.76041667, 0.73958333,\n",
              "        0.75      , 0.73958333, 0.77083333, 0.76041667, 0.72916667,\n",
              "        0.77083333, 0.73958333, 0.75      , 0.70833333, 0.79166667,\n",
              "        0.65625   , 0.72916667, 0.72916667, 0.78125   , 0.76041667,\n",
              "        0.70833333, 0.70833333, 0.76041667, 0.73958333, 0.75      ,\n",
              "        0.72916667, 0.73958333, 0.71875   , 0.75      , 0.75      ,\n",
              "        0.65625   , 0.72916667, 0.75      , 0.72916667, 0.73958333,\n",
              "        0.69791667, 0.76041667, 0.75      , 0.71875   , 0.76041667,\n",
              "        0.77083333, 0.75      , 0.77083333, 0.76041667, 0.79166667,\n",
              "        0.75      , 0.73958333, 0.71875   , 0.77083333, 0.71875   ,\n",
              "        0.75      , 0.72916667, 0.76041667, 0.71875   , 0.77083333,\n",
              "        0.64583333, 0.69791667, 0.78125   , 0.77083333, 0.73958333,\n",
              "        0.64583333, 0.71875   , 0.72916667, 0.77083333, 0.77083333,\n",
              "        0.8125    , 0.69791667, 0.78125   , 0.71875   , 0.75      ,\n",
              "        0.71875   , 0.79166667, 0.73958333, 0.77083333, 0.75      ,\n",
              "        0.70833333, 0.77083333, 0.75      , 0.80208333, 0.70833333,\n",
              "        0.76041667, 0.70833333, 0.77083333, 0.75      , 0.77083333,\n",
              "        0.625     , 0.73958333, 0.67708333, 0.73958333, 0.72916667,\n",
              "        0.65625   , 0.77083333, 0.80208333, 0.73958333, 0.73958333,\n",
              "        0.71875   , 0.79166667, 0.73958333, 0.77083333, 0.72916667,\n",
              "        0.71875   , 0.76041667, 0.79166667, 0.77083333, 0.77083333,\n",
              "        0.70833333, 0.6875    , 0.75      , 0.78125   , 0.76041667,\n",
              "        0.72916667, 0.69791667, 0.72916667, 0.72916667, 0.72916667,\n",
              "        0.72916667, 0.78125   , 0.76041667, 0.76041667, 0.76041667,\n",
              "        0.64583333, 0.77083333, 0.75      , 0.76041667, 0.75      ,\n",
              "        0.71875   , 0.73958333, 0.75      , 0.77083333, 0.79166667,\n",
              "        0.70833333, 0.71875   , 0.73958333, 0.76041667, 0.73958333,\n",
              "        0.79166667, 0.70833333, 0.75      , 0.70833333, 0.77083333,\n",
              "        0.75      , 0.73958333, 0.73958333, 0.77083333, 0.72916667,\n",
              "        0.69791667, 0.77083333, 0.71875   , 0.75      , 0.73958333,\n",
              "        0.75      , 0.76041667, 0.73958333, 0.75      , 0.75      ,\n",
              "        0.73958333, 0.73958333, 0.75      , 0.67708333, 0.72916667,\n",
              "        0.69791667, 0.75      , 0.72916667, 0.73958333, 0.73958333,\n",
              "        0.73958333, 0.75      , 0.71875   , 0.72916667, 0.73958333,\n",
              "        0.625     , 0.73958333, 0.76041667, 0.76041667, 0.76041667,\n",
              "        0.6875    , 0.76041667, 0.67708333, 0.73958333, 0.76041667,\n",
              "        0.69791667, 0.79166667, 0.72916667, 0.72916667, 0.77083333,\n",
              "        0.65625   , 0.70833333, 0.75      , 0.75      , 0.73958333,\n",
              "        0.70833333, 0.78125   , 0.69791667, 0.73958333, 0.78125   ,\n",
              "        0.75      , 0.69791667, 0.79166667, 0.76041667, 0.79166667,\n",
              "        0.75      , 0.76041667, 0.72916667, 0.70833333, 0.78125   ,\n",
              "        0.72916667, 0.69791667, 0.76041667, 0.78125   , 0.79166667,\n",
              "        0.76041667, 0.72916667, 0.79166667, 0.73958333, 0.78125   ,\n",
              "        0.73958333, 0.70833333, 0.75      , 0.78125   , 0.77083333,\n",
              "        0.70833333, 0.77083333, 0.75      , 0.76041667, 0.77083333,\n",
              "        0.77083333, 0.77083333, 0.77083333, 0.71875   , 0.76041667,\n",
              "        0.72916667, 0.72916667, 0.77083333, 0.73958333, 0.79166667,\n",
              "        0.72916667, 0.78125   , 0.80208333, 0.72916667, 0.75      ,\n",
              "        0.73958333, 0.75      , 0.79166667, 0.75      , 0.71875   ,\n",
              "        0.75      , 0.75      , 0.73958333, 0.78125   , 0.79166667,\n",
              "        0.73958333, 0.73958333, 0.80208333, 0.75      , 0.75      ,\n",
              "        0.71875   , 0.73958333, 0.76041667, 0.77083333, 0.75      ,\n",
              "        0.67708333, 0.70833333, 0.76041667, 0.75      , 0.77083333,\n",
              "        0.73958333, 0.71875   , 0.72916667, 0.75      , 0.75      ,\n",
              "        0.70833333, 0.75      , 0.78125   , 0.75      , 0.76041667,\n",
              "        0.71875   , 0.70833333, 0.76041667, 0.78125   , 0.79166667,\n",
              "        0.78125   , 0.76041667, 0.79166667, 0.79166667, 0.76041667,\n",
              "        0.71875   , 0.69791667, 0.76041667, 0.72916667, 0.75      ,\n",
              "        0.72916667, 0.73958333, 0.72916667, 0.76041667, 0.76041667,\n",
              "        0.75      , 0.71875   , 0.77083333, 0.77083333, 0.79166667,\n",
              "        0.72916667, 0.70833333, 0.75      , 0.76041667, 0.76041667,\n",
              "        0.69791667, 0.71875   , 0.75      , 0.72916667, 0.70833333,\n",
              "        0.75      , 0.73958333, 0.73958333, 0.78125   , 0.77083333,\n",
              "        0.75      , 0.72916667, 0.75      , 0.71875   , 0.76041667,\n",
              "        0.65625   , 0.73958333, 0.75      , 0.75      , 0.75      ,\n",
              "        0.76041667, 0.71875   , 0.75      , 0.76041667, 0.77083333,\n",
              "        0.76041667, 0.72916667, 0.69791667, 0.70833333, 0.75      ,\n",
              "        0.70833333, 0.69791667, 0.73958333, 0.75      , 0.70833333,\n",
              "        0.75      , 0.76041667, 0.73958333, 0.71875   , 0.72916667]),\n",
              " 'split4_test_score': array([0.60416667, 0.71875   , 0.70833333, 0.70833333, 0.70833333,\n",
              "        0.72916667, 0.6875    , 0.71875   , 0.70833333, 0.69791667,\n",
              "        0.72916667, 0.72916667, 0.72916667, 0.67708333, 0.72916667,\n",
              "        0.69791667, 0.70833333, 0.70833333, 0.69791667, 0.6875    ,\n",
              "        0.65625   , 0.6875    , 0.70833333, 0.70833333, 0.71875   ,\n",
              "        0.73958333, 0.6875    , 0.69791667, 0.71875   , 0.71875   ,\n",
              "        0.65625   , 0.72916667, 0.70833333, 0.69791667, 0.71875   ,\n",
              "        0.75      , 0.69791667, 0.71875   , 0.73958333, 0.70833333,\n",
              "        0.70833333, 0.73958333, 0.71875   , 0.70833333, 0.71875   ,\n",
              "        0.6875    , 0.72916667, 0.73958333, 0.76041667, 0.70833333,\n",
              "        0.73958333, 0.70833333, 0.71875   , 0.69791667, 0.73958333,\n",
              "        0.75      , 0.6875    , 0.70833333, 0.72916667, 0.71875   ,\n",
              "        0.75      , 0.67708333, 0.65625   , 0.75      , 0.66666667,\n",
              "        0.69791667, 0.625     , 0.66666667, 0.69791667, 0.70833333,\n",
              "        0.77083333, 0.6875    , 0.71875   , 0.67708333, 0.66666667,\n",
              "        0.67708333, 0.70833333, 0.64583333, 0.67708333, 0.73958333,\n",
              "        0.70833333, 0.64583333, 0.67708333, 0.70833333, 0.69791667,\n",
              "        0.71875   , 0.67708333, 0.69791667, 0.6875    , 0.70833333,\n",
              "        0.67708333, 0.75      , 0.69791667, 0.67708333, 0.70833333,\n",
              "        0.66666667, 0.66666667, 0.71875   , 0.71875   , 0.69791667,\n",
              "        0.71875   , 0.77083333, 0.70833333, 0.70833333, 0.71875   ,\n",
              "        0.67708333, 0.73958333, 0.72916667, 0.71875   , 0.69791667,\n",
              "        0.65625   , 0.625     , 0.72916667, 0.72916667, 0.73958333,\n",
              "        0.70833333, 0.73958333, 0.70833333, 0.70833333, 0.69791667,\n",
              "        0.66666667, 0.69791667, 0.625     , 0.71875   , 0.72916667,\n",
              "        0.71875   , 0.72916667, 0.67708333, 0.76041667, 0.71875   ,\n",
              "        0.6875    , 0.6875    , 0.75      , 0.6875    , 0.70833333,\n",
              "        0.72916667, 0.64583333, 0.73958333, 0.71875   , 0.72916667,\n",
              "        0.59375   , 0.6875    , 0.70833333, 0.70833333, 0.69791667,\n",
              "        0.63541667, 0.6875    , 0.64583333, 0.70833333, 0.66666667,\n",
              "        0.70833333, 0.64583333, 0.66666667, 0.65625   , 0.70833333,\n",
              "        0.69791667, 0.66666667, 0.67708333, 0.71875   , 0.67708333,\n",
              "        0.69791667, 0.73958333, 0.71875   , 0.70833333, 0.71875   ,\n",
              "        0.75      , 0.63541667, 0.6875    , 0.70833333, 0.70833333,\n",
              "        0.70833333, 0.70833333, 0.6875    , 0.6875    , 0.70833333,\n",
              "        0.78125   , 0.69791667, 0.70833333, 0.67708333, 0.70833333,\n",
              "        0.67708333, 0.73958333, 0.75      , 0.72916667, 0.70833333,\n",
              "        0.625     , 0.66666667, 0.71875   , 0.69791667, 0.72916667,\n",
              "        0.66666667, 0.71875   , 0.72916667, 0.69791667, 0.69791667,\n",
              "        0.66666667, 0.66666667, 0.70833333, 0.70833333, 0.71875   ,\n",
              "        0.70833333, 0.75      , 0.6875    , 0.72916667, 0.69791667,\n",
              "        0.70833333, 0.65625   , 0.69791667, 0.72916667, 0.73958333,\n",
              "        0.625     , 0.72916667, 0.71875   , 0.6875    , 0.69791667,\n",
              "        0.64583333, 0.70833333, 0.75      , 0.76041667, 0.70833333,\n",
              "        0.72916667, 0.72916667, 0.70833333, 0.72916667, 0.67708333,\n",
              "        0.60416667, 0.67708333, 0.66666667, 0.69791667, 0.6875    ,\n",
              "        0.78125   , 0.61458333, 0.64583333, 0.71875   , 0.70833333,\n",
              "        0.70833333, 0.64583333, 0.6875    , 0.66666667, 0.71875   ,\n",
              "        0.66666667, 0.63541667, 0.69791667, 0.70833333, 0.67708333,\n",
              "        0.70833333, 0.69791667, 0.70833333, 0.72916667, 0.70833333,\n",
              "        0.71875   , 0.71875   , 0.72916667, 0.71875   , 0.69791667,\n",
              "        0.6875    , 0.72916667, 0.69791667, 0.70833333, 0.6875    ,\n",
              "        0.66666667, 0.72916667, 0.69791667, 0.6875    , 0.71875   ,\n",
              "        0.63541667, 0.66666667, 0.6875    , 0.72916667, 0.72916667,\n",
              "        0.71875   , 0.64583333, 0.69791667, 0.70833333, 0.6875    ,\n",
              "        0.71875   , 0.73958333, 0.72916667, 0.73958333, 0.71875   ,\n",
              "        0.75      , 0.63541667, 0.71875   , 0.72916667, 0.69791667,\n",
              "        0.72916667, 0.72916667, 0.75      , 0.72916667, 0.71875   ,\n",
              "        0.6875    , 0.6875    , 0.6875    , 0.76041667, 0.69791667,\n",
              "        0.75      , 0.65625   , 0.72916667, 0.6875    , 0.71875   ,\n",
              "        0.65625   , 0.69791667, 0.70833333, 0.70833333, 0.71875   ,\n",
              "        0.76041667, 0.70833333, 0.61458333, 0.61458333, 0.66666667,\n",
              "        0.66666667, 0.75      , 0.72916667, 0.69791667, 0.72916667,\n",
              "        0.73958333, 0.71875   , 0.69791667, 0.77083333, 0.70833333,\n",
              "        0.72916667, 0.67708333, 0.70833333, 0.70833333, 0.69791667,\n",
              "        0.63541667, 0.5625    , 0.73958333, 0.70833333, 0.71875   ,\n",
              "        0.61458333, 0.71875   , 0.73958333, 0.69791667, 0.71875   ,\n",
              "        0.75      , 0.70833333, 0.67708333, 0.71875   , 0.70833333,\n",
              "        0.66666667, 0.76041667, 0.70833333, 0.71875   , 0.73958333,\n",
              "        0.75      , 0.72916667, 0.71875   , 0.72916667, 0.71875   ,\n",
              "        0.61458333, 0.72916667, 0.71875   , 0.69791667, 0.71875   ,\n",
              "        0.72916667, 0.70833333, 0.75      , 0.72916667, 0.70833333,\n",
              "        0.64583333, 0.69791667, 0.73958333, 0.71875   , 0.72916667,\n",
              "        0.63541667, 0.625     , 0.75      , 0.72916667, 0.75      ,\n",
              "        0.65625   , 0.6875    , 0.70833333, 0.73958333, 0.70833333,\n",
              "        0.6875    , 0.6875    , 0.70833333, 0.73958333, 0.72916667,\n",
              "        0.64583333, 0.73958333, 0.70833333, 0.70833333, 0.69791667,\n",
              "        0.71875   , 0.67708333, 0.71875   , 0.67708333, 0.63541667,\n",
              "        0.70833333, 0.70833333, 0.64583333, 0.65625   , 0.73958333,\n",
              "        0.66666667, 0.6875    , 0.75      , 0.72916667, 0.69791667,\n",
              "        0.65625   , 0.64583333, 0.6875    , 0.69791667, 0.73958333,\n",
              "        0.66666667, 0.70833333, 0.71875   , 0.71875   , 0.71875   ,\n",
              "        0.70833333, 0.69791667, 0.67708333, 0.70833333, 0.70833333,\n",
              "        0.65625   , 0.67708333, 0.71875   , 0.69791667, 0.69791667,\n",
              "        0.6875    , 0.66666667, 0.73958333, 0.72916667, 0.70833333,\n",
              "        0.71875   , 0.70833333, 0.70833333, 0.71875   , 0.70833333,\n",
              "        0.76041667, 0.64583333, 0.75      , 0.75      , 0.72916667,\n",
              "        0.73958333, 0.57291667, 0.71875   , 0.70833333, 0.70833333,\n",
              "        0.70833333, 0.72916667, 0.72916667, 0.71875   , 0.72916667,\n",
              "        0.70833333, 0.71875   , 0.69791667, 0.72916667, 0.72916667,\n",
              "        0.57291667, 0.70833333, 0.71875   , 0.73958333, 0.75      ,\n",
              "        0.66666667, 0.72916667, 0.71875   , 0.70833333, 0.71875   ,\n",
              "        0.70833333, 0.73958333, 0.66666667, 0.71875   , 0.73958333,\n",
              "        0.69791667, 0.69791667, 0.72916667, 0.73958333, 0.70833333,\n",
              "        0.69791667, 0.6875    , 0.70833333, 0.75      , 0.66666667,\n",
              "        0.73958333, 0.76041667, 0.69791667, 0.73958333, 0.67708333,\n",
              "        0.72916667, 0.71875   , 0.69791667, 0.71875   , 0.72916667,\n",
              "        0.66666667, 0.61458333, 0.6875    , 0.6875    , 0.69791667,\n",
              "        0.60416667, 0.72916667, 0.70833333, 0.67708333, 0.6875    ,\n",
              "        0.72916667, 0.71875   , 0.72916667, 0.70833333, 0.71875   ,\n",
              "        0.70833333, 0.71875   , 0.73958333, 0.72916667, 0.72916667,\n",
              "        0.73958333, 0.73958333, 0.72916667, 0.71875   , 0.70833333,\n",
              "        0.61458333, 0.73958333, 0.71875   , 0.71875   , 0.71875   ,\n",
              "        0.75      , 0.75      , 0.71875   , 0.6875    , 0.71875   ,\n",
              "        0.59375   , 0.6875    , 0.75      , 0.70833333, 0.71875   ,\n",
              "        0.69791667, 0.70833333, 0.71875   , 0.73958333, 0.70833333,\n",
              "        0.60416667, 0.69791667, 0.70833333, 0.72916667, 0.76041667,\n",
              "        0.67708333, 0.73958333, 0.71875   , 0.70833333, 0.71875   ,\n",
              "        0.61458333, 0.61458333, 0.72916667, 0.66666667, 0.72916667,\n",
              "        0.71875   , 0.63541667, 0.69791667, 0.70833333, 0.70833333,\n",
              "        0.70833333, 0.66666667, 0.65625   , 0.71875   , 0.70833333,\n",
              "        0.70833333, 0.64583333, 0.6875    , 0.69791667, 0.71875   ,\n",
              "        0.6875    , 0.69791667, 0.70833333, 0.69791667, 0.69791667,\n",
              "        0.6875    , 0.69791667, 0.69791667, 0.69791667, 0.69791667,\n",
              "        0.70833333, 0.66666667, 0.71875   , 0.71875   , 0.70833333,\n",
              "        0.625     , 0.70833333, 0.71875   , 0.69791667, 0.72916667,\n",
              "        0.69791667, 0.70833333, 0.70833333, 0.73958333, 0.70833333,\n",
              "        0.65625   , 0.70833333, 0.69791667, 0.70833333, 0.72916667,\n",
              "        0.72916667, 0.66666667, 0.70833333, 0.69791667, 0.73958333,\n",
              "        0.70833333, 0.70833333, 0.71875   , 0.71875   , 0.70833333,\n",
              "        0.77083333, 0.69791667, 0.67708333, 0.72916667, 0.72916667,\n",
              "        0.75      , 0.72916667, 0.73958333, 0.69791667, 0.72916667,\n",
              "        0.59375   , 0.70833333, 0.67708333, 0.71875   , 0.73958333,\n",
              "        0.59375   , 0.73958333, 0.72916667, 0.65625   , 0.70833333,\n",
              "        0.66666667, 0.71875   , 0.70833333, 0.64583333, 0.75      ,\n",
              "        0.73958333, 0.58333333, 0.72916667, 0.71875   , 0.71875   ,\n",
              "        0.58333333, 0.71875   , 0.70833333, 0.69791667, 0.70833333,\n",
              "        0.60416667, 0.71875   , 0.71875   , 0.73958333, 0.70833333]),\n",
              " 'std_fit_time': array([2.78348824e-03, 1.71258681e-03, 1.89154014e-03, 3.73248913e-03,\n",
              "        1.38162406e-03, 1.25139333e-04, 1.58556105e-03, 8.69611436e-04,\n",
              "        2.44635352e-03, 1.49349747e-03, 1.69731791e-03, 1.91368422e-04,\n",
              "        4.01141464e-04, 2.26524061e-03, 2.56796563e-03, 6.96223728e-05,\n",
              "        1.90414195e-04, 2.52779307e-04, 2.21445806e-03, 2.09294977e-02,\n",
              "        1.71749397e-04, 2.30333937e-04, 5.05086946e-04, 1.78976834e-03,\n",
              "        1.12529198e-03, 7.41723840e-05, 2.19314024e-04, 6.79517488e-04,\n",
              "        2.90242509e-03, 1.87797078e-03, 1.17414932e-04, 1.11824302e-04,\n",
              "        2.17798214e-03, 5.44758124e-04, 1.22882595e-03, 1.44440626e-04,\n",
              "        5.58418864e-05, 1.72692713e-03, 7.45026853e-04, 2.24835149e-03,\n",
              "        1.39640555e-04, 4.51985151e-04, 3.73019490e-03, 1.44975531e-03,\n",
              "        8.33429091e-03, 1.45515170e-04, 8.37250969e-04, 6.90725910e-03,\n",
              "        1.35813257e-03, 3.10250455e-03, 4.76931911e-04, 1.97909738e-03,\n",
              "        2.51725991e-03, 2.38613324e-03, 2.82906848e-03, 1.81143705e-03,\n",
              "        1.43430651e-04, 3.91870308e-03, 7.23714634e-03, 1.34620830e-03,\n",
              "        1.88468997e-03, 3.32244330e-04, 2.24208487e-04, 1.99554160e-03,\n",
              "        7.28118952e-04, 1.49678454e-03, 1.70865026e-04, 1.01532207e-03,\n",
              "        1.72857066e-03, 1.41521085e-03, 1.59827989e-03, 1.24695278e-04,\n",
              "        4.68119555e-03, 2.24311071e-03, 1.10129338e-03, 8.93316697e-04,\n",
              "        3.82280561e-04, 1.65849459e-03, 1.84877942e-03, 1.12441528e-03,\n",
              "        1.64871543e-03, 3.46104643e-04, 5.88529965e-04, 2.11236435e-03,\n",
              "        2.97010033e-03, 1.95814478e-04, 3.09856828e-04, 2.71868261e-04,\n",
              "        9.60537005e-04, 3.11619846e-03, 2.02301984e-04, 4.06889352e-04,\n",
              "        4.74688639e-04, 2.24014460e-03, 4.48785862e-03, 1.62789762e-04,\n",
              "        1.87700538e-04, 1.86721897e-03, 1.15574439e-03, 3.08006137e-03,\n",
              "        8.23969366e-05, 1.46363408e-04, 1.85481000e-03, 8.99454191e-04,\n",
              "        2.43142645e-03, 5.61329900e-05, 1.68230569e-03, 2.23519136e-04,\n",
              "        2.88196801e-03, 1.38037310e-03, 1.58327357e-04, 1.80389154e-03,\n",
              "        2.14816627e-04, 1.90440532e-03, 2.02263750e-03, 1.75741982e-04,\n",
              "        3.33117757e-03, 1.19812981e-03, 2.79797317e-03, 5.88475766e-03,\n",
              "        1.50363066e-04, 5.22666928e-04, 5.88462351e-04, 2.32114807e-03,\n",
              "        2.96146729e-03, 1.42978602e-04, 2.36436612e-03, 5.37866641e-04,\n",
              "        1.88951522e-03, 5.98650877e-04, 3.71007514e-04, 2.36794884e-04,\n",
              "        1.57565960e-04, 7.93761538e-04, 2.07025142e-03, 4.56371116e-04,\n",
              "        2.51989720e-04, 4.21003991e-04, 1.71645138e-03, 1.53713102e-02,\n",
              "        2.30920947e-04, 1.23176554e-04, 1.72773533e-03, 7.95393353e-04,\n",
              "        1.99469569e-03, 1.14990109e-04, 1.49115099e-04, 3.96057579e-04,\n",
              "        9.84894025e-04, 1.58784852e-03, 4.22889238e-05, 1.74622715e-04,\n",
              "        3.49984084e-04, 2.02836336e-03, 1.59385423e-03, 6.13369781e-05,\n",
              "        1.30428047e-04, 1.25551921e-04, 2.30342175e-03, 1.78920532e-03,\n",
              "        2.37755062e-04, 1.07995311e-04, 4.75518750e-04, 1.67043011e-03,\n",
              "        1.09051241e-03, 6.44646804e-05, 1.14528801e-04, 1.91096377e-03,\n",
              "        1.31926452e-03, 3.14268114e-03, 1.12814371e-04, 1.77379179e-03,\n",
              "        5.99781988e-04, 1.50691177e-03, 1.62395743e-03, 2.07536320e-03,\n",
              "        1.44105633e-04, 1.55512639e-03, 2.09221088e-03, 1.47337684e-03,\n",
              "        1.30312974e-04, 5.82251294e-04, 8.45330749e-05, 1.45500074e-03,\n",
              "        7.00686340e-04, 1.04886899e-04, 1.40001241e-04, 2.16522476e-04,\n",
              "        1.76953785e-03, 1.95970813e-03, 3.61869391e-04, 2.92744930e-04,\n",
              "        3.12926491e-04, 4.45297892e-03, 7.05695347e-03, 8.01713448e-05,\n",
              "        1.17217631e-04, 1.78988974e-03, 3.11461424e-03, 1.98901542e-03,\n",
              "        7.95547604e-05, 1.85955328e-04, 1.81031423e-03, 3.54294103e-03,\n",
              "        2.83947226e-03, 4.89311138e-05, 4.06894957e-05, 1.55975320e-03,\n",
              "        6.02464964e-04, 2.37285876e-03, 7.63640975e-05, 1.10977905e-04,\n",
              "        1.77099944e-03, 1.31725307e-03, 2.52876077e-03, 9.10680328e-05,\n",
              "        2.19807676e-04, 2.00523504e-03, 7.46030218e-04, 1.60273943e-03,\n",
              "        7.20631110e-05, 9.35295635e-05, 2.47598065e-03, 7.49186467e-04,\n",
              "        9.73506445e-04, 1.40895303e-04, 1.66959450e-04, 2.27910601e-03,\n",
              "        3.64574536e-04, 2.68319670e-03, 9.98178156e-05, 1.00952969e-04,\n",
              "        2.00319285e-03, 2.88221048e-04, 1.92908640e-03, 7.15849312e-05,\n",
              "        1.42293321e-04, 2.25347535e-03, 7.01176766e-04, 2.14537009e-03,\n",
              "        1.28809807e-04, 2.55540294e-04, 1.93197935e-03, 7.22371431e-04,\n",
              "        2.53944220e-03, 1.68983944e-04, 6.26495755e-04, 5.18792197e-04,\n",
              "        2.36175223e-03, 5.51795890e-03, 5.59643928e-05, 2.54193163e-04,\n",
              "        2.18481062e-04, 1.40965082e-03, 3.70565715e-03, 2.07871164e-04,\n",
              "        2.57337559e-04, 3.22255759e-04, 1.39165851e-03, 5.52446697e-03,\n",
              "        5.65041771e-05, 1.81306819e-04, 5.61866440e-04, 1.69024364e-03,\n",
              "        1.09582406e-03, 3.95336121e-04, 1.75159578e-03, 3.36632749e-03,\n",
              "        4.17321839e-04, 2.81310049e-03, 5.55343151e-05, 5.03112700e-04,\n",
              "        1.37298956e-03, 4.30835675e-04, 2.62621826e-03, 1.46583450e-04,\n",
              "        5.55100605e-04, 2.16849794e-03, 1.25305695e-03, 2.16006677e-03,\n",
              "        3.60661370e-04, 2.14500487e-03, 2.96073011e-04, 1.73791992e-03,\n",
              "        2.36052512e-03, 1.19883215e-04, 7.64232413e-04, 3.14160665e-04,\n",
              "        1.63199096e-03, 2.77379484e-03, 1.22899410e-04, 1.77369396e-03,\n",
              "        1.90492560e-03, 1.45324654e-03, 7.72975998e-04, 6.72865047e-05,\n",
              "        1.66916565e-03, 7.47072601e-04, 1.68401698e-03, 1.08256961e-03,\n",
              "        1.89143138e-03, 9.22364543e-05, 1.12576557e-04, 3.19179184e-03,\n",
              "        2.55537756e-03, 1.85365576e-03, 7.56098355e-05, 2.71393057e-04,\n",
              "        1.96142933e-03, 1.23204456e-03, 1.87870671e-03, 1.74667579e-04,\n",
              "        6.98261960e-04, 1.94912503e-03, 6.49419065e-04, 1.16223572e-03,\n",
              "        1.47246851e-04, 2.88449963e-04, 2.15282461e-03, 9.56443597e-04,\n",
              "        1.19451220e-04, 2.09137820e-03, 8.27857704e-04, 3.19968762e-03,\n",
              "        2.88604628e-03, 1.74065066e-04, 6.02874341e-04, 2.30171641e-03,\n",
              "        1.78826412e-03, 2.12397347e-03, 2.00724566e-04, 1.74066994e-03,\n",
              "        3.11085105e-04, 1.56199296e-03, 1.34409153e-03, 2.06899000e-04,\n",
              "        2.07727944e-04, 4.75640718e-04, 1.79560478e-03, 4.51132380e-03,\n",
              "        4.94334200e-04, 3.02794314e-04, 3.42873885e-03, 7.78483182e-04,\n",
              "        2.01023357e-03, 7.23431904e-05, 2.12380366e-03, 4.41092388e-04,\n",
              "        1.23932813e-03, 3.57781562e-03, 6.02964310e-05, 2.35526425e-04,\n",
              "        5.69374844e-04, 2.00566915e-03, 7.37336112e-04, 1.35333526e-04,\n",
              "        2.78954775e-04, 2.61150978e-04, 2.33348913e-03, 2.95882292e-03,\n",
              "        1.08426353e-04, 8.12633770e-05, 2.41120167e-03, 5.22006781e-04,\n",
              "        4.71966385e-03, 9.30110694e-05, 1.04501232e-04, 2.48948650e-03,\n",
              "        6.43958288e-04, 1.74930410e-03, 1.22569375e-04, 1.70313695e-03,\n",
              "        5.01371101e-04, 1.86114635e-03, 3.02294744e-03, 3.07280132e-04,\n",
              "        2.57144685e-04, 2.21918825e-04, 1.83095562e-03, 1.44547357e-03,\n",
              "        2.81211479e-04, 5.51693021e-04, 3.13109571e-04, 1.89304240e-03,\n",
              "        4.71387288e-03, 3.56298851e-04, 3.58843156e-04, 3.85755160e-04,\n",
              "        1.23256375e-03, 1.92212694e-03, 2.33546662e-04, 3.91355219e-05,\n",
              "        3.12832447e-04, 2.06273691e-03, 2.60971234e-03, 4.68475907e-04,\n",
              "        2.82620342e-04, 5.21764522e-04, 4.13391790e-03, 1.63575849e-03,\n",
              "        1.81147104e-04, 2.65680656e-04, 2.40400960e-03, 3.06385274e-03,\n",
              "        5.07449554e-03, 1.81116876e-04, 9.15334229e-04, 3.23040493e-03,\n",
              "        5.02426498e-03, 1.01446434e-03, 1.56620647e-04, 2.00331395e-04,\n",
              "        5.11347821e-03, 1.10189966e-03, 2.89080382e-02, 3.98015910e-04,\n",
              "        2.09720606e-03, 1.05332591e-03, 7.02245222e-03, 2.37005942e-03,\n",
              "        1.54200025e-04, 3.54122640e-04, 1.92092300e-03, 8.09548077e-04,\n",
              "        4.40635194e-03, 2.01077090e-04, 1.89178559e-03, 5.63663809e-04,\n",
              "        2.08479733e-03, 3.17136994e-03, 8.87353339e-05, 4.30833115e-04,\n",
              "        4.46162721e-04, 1.79686958e-03, 2.95222713e-03, 1.21228437e-04,\n",
              "        1.91802612e-04, 1.88154512e-03, 1.19845253e-03, 2.96246550e-03,\n",
              "        8.00368862e-05, 1.64665065e-04, 1.93233851e-03, 4.81544826e-04,\n",
              "        2.84515537e-03, 1.34595429e-04, 2.08933087e-03, 7.24323140e-04,\n",
              "        2.46895420e-03, 9.14975320e-04, 1.79937553e-03, 2.28324101e-04,\n",
              "        4.96830010e-04, 2.59754812e-03, 2.39700922e-03, 2.16196379e-04,\n",
              "        1.78369007e-04, 5.43400592e-04, 1.89200512e-03, 2.24488570e-03,\n",
              "        1.49063551e-04, 3.95638299e-04, 1.47384425e-03, 2.40443185e-03,\n",
              "        2.20205516e-03, 2.11787727e-04, 1.88765275e-04, 4.16216687e-04,\n",
              "        2.39316241e-03, 2.28773978e-03, 2.06935241e-05, 3.05150240e-04,\n",
              "        2.02621592e-04, 2.82763788e-03, 2.04399817e-03, 8.08525738e-05,\n",
              "        1.60902649e-04, 1.55555189e-03, 2.91854975e-04, 1.10614269e-02,\n",
              "        1.25571840e-04, 3.69771367e-04, 1.75087783e-03, 5.66415235e-03,\n",
              "        2.77031371e-03, 1.98669188e-04, 3.43989493e-04, 5.16706197e-04,\n",
              "        8.92181162e-04, 2.66170501e-03, 2.01918135e-04, 4.80752402e-04,\n",
              "        1.71271057e-03, 1.65515125e-03, 2.95258790e-03, 2.15006504e-04,\n",
              "        1.18120697e-04, 3.21343883e-04, 1.96272249e-03, 2.61757478e-03,\n",
              "        5.10584172e-05, 2.39870912e-04, 7.01088755e-04, 1.68632359e-03,\n",
              "        2.55184433e-03, 9.96057240e-05, 4.44288134e-04, 1.78882932e-03,\n",
              "        5.40521591e-04, 1.94602321e-03, 9.43179138e-04, 3.42857410e-04,\n",
              "        3.50610564e-04, 1.32054564e-03, 2.66899527e-03, 1.51759192e-04,\n",
              "        7.75177377e-05, 2.90081548e-04, 1.42195782e-03, 3.73794288e-03,\n",
              "        1.72235601e-04, 2.09996107e-04, 5.35806521e-04, 2.39945140e-03,\n",
              "        1.74509732e-03, 8.08323234e-05, 5.22071917e-04, 1.80263790e-03,\n",
              "        7.11084048e-04, 1.30264951e-03, 3.49223685e-04, 1.55858191e-04,\n",
              "        1.86249241e-03, 4.37025285e-04, 2.06228720e-03, 7.61272576e-05,\n",
              "        1.57156234e-03, 4.81319045e-04, 2.96803639e-03, 1.67145213e-03,\n",
              "        1.12910711e-03, 2.65933558e-04, 2.57599596e-04, 2.06623637e-03,\n",
              "        1.26590540e-03, 9.15085915e-05, 1.69198501e-04, 1.87584890e-04,\n",
              "        1.60282532e-03, 9.00135027e-03, 3.99473971e-04, 2.01361698e-04,\n",
              "        5.44914758e-04, 4.52119779e-03, 2.40303991e-03, 1.19682935e-04,\n",
              "        1.26708778e-04, 3.72475876e-04, 2.71740509e-03, 1.81963165e-03,\n",
              "        2.60762994e-04, 2.40857496e-04, 1.90150589e-03, 1.06577908e-03,\n",
              "        1.86281018e-03, 1.24701563e-03, 2.75264946e-04, 9.28378281e-04,\n",
              "        2.25806202e-03, 2.54905502e-03, 1.30321488e-04, 1.47791106e-04,\n",
              "        6.86613095e-04, 1.81664486e-03, 1.89671192e-03, 6.79934342e-05,\n",
              "        2.16070560e-04, 2.37279054e-03, 1.59917389e-03, 2.83610126e-03,\n",
              "        5.00191497e-05, 3.26984092e-04, 1.85657350e-03, 1.47060248e-03,\n",
              "        1.83292790e-03, 1.04749804e-04, 5.68387704e-04, 2.46486689e-04,\n",
              "        1.77850819e-03, 2.23107262e-03, 1.26312804e-04, 1.54160251e-04,\n",
              "        1.74849216e-03, 1.01331067e-03, 1.90346854e-03, 1.04284886e-04,\n",
              "        1.34922623e-03, 1.55414098e-04, 1.98720357e-03, 2.22956496e-03,\n",
              "        1.97719457e-04, 8.01729614e-05, 5.16255509e-04, 2.81156943e-03,\n",
              "        3.34778980e-03, 2.00276863e-04, 4.91246643e-04, 5.93210021e-04,\n",
              "        1.58075242e-03, 2.72185590e-03, 1.86704894e-04, 1.69908689e-04,\n",
              "        2.14821993e-04, 1.97687497e-03, 2.19091381e-03, 1.80560962e-04,\n",
              "        4.38798326e-04, 1.98609601e-03, 9.60457478e-03, 7.30592713e-03,\n",
              "        1.67446377e-04, 1.56979369e-03, 5.20662421e-04, 4.55301852e-04,\n",
              "        4.14652265e-03, 4.26276381e-04, 1.41406444e-03, 6.80103419e-04,\n",
              "        4.15849535e-04, 1.84875066e-03, 2.80958321e-04, 1.32359014e-03,\n",
              "        5.79805526e-04, 2.24223330e-03, 9.18875134e-04, 1.75427338e-03,\n",
              "        1.90456461e-04, 9.78858206e-04, 1.98392154e-03, 1.88376135e-03]),\n",
              " 'std_score_time': array([2.78156571e-04, 1.26206771e-04, 1.07890790e-03, 2.10923515e-04,\n",
              "        2.12544000e-04, 4.58715363e-05, 1.13811990e-04, 1.51429818e-04,\n",
              "        1.98024185e-04, 9.58169832e-05, 2.07026671e-04, 1.57062661e-05,\n",
              "        7.87375544e-05, 6.11473706e-05, 1.13552179e-04, 2.24106362e-05,\n",
              "        1.61602076e-05, 4.80474428e-05, 7.37584935e-05, 9.00909834e-05,\n",
              "        3.46915336e-05, 3.01886204e-04, 7.89742820e-05, 9.66710636e-05,\n",
              "        1.57357615e-03, 6.96965652e-06, 3.31941686e-06, 6.90027359e-05,\n",
              "        6.13748885e-05, 6.28388519e-05, 3.09137615e-05, 3.32103987e-05,\n",
              "        1.06034522e-03, 7.38418944e-05, 9.73330017e-04, 4.25537025e-05,\n",
              "        1.99841992e-05, 4.19972551e-05, 1.09581536e-04, 9.79963588e-05,\n",
              "        1.81526589e-05, 1.05890063e-05, 2.89310052e-04, 1.78812943e-04,\n",
              "        4.36693744e-04, 5.05068025e-05, 5.57612003e-04, 1.45315527e-04,\n",
              "        1.24756257e-04, 7.26609221e-04, 2.23836322e-05, 2.24290737e-04,\n",
              "        5.39279426e-05, 1.88267641e-04, 1.23868950e-04, 1.77335989e-05,\n",
              "        1.22270253e-04, 3.20755969e-04, 4.14598691e-04, 1.81333943e-04,\n",
              "        4.60762394e-05, 2.91141790e-05, 3.55809357e-05, 3.81700327e-05,\n",
              "        1.65903633e-04, 3.29232457e-04, 1.78043614e-05, 4.06357594e-05,\n",
              "        7.36665724e-05, 1.87321483e-04, 3.55083314e-05, 1.06724210e-05,\n",
              "        4.15028062e-05, 1.08989120e-04, 1.64725769e-04, 3.56483581e-04,\n",
              "        4.14847231e-05, 1.31381176e-04, 1.27639733e-04, 4.19079708e-04,\n",
              "        3.98963698e-05, 8.61987329e-05, 1.02865767e-04, 3.66677717e-04,\n",
              "        3.08148929e-04, 1.25723938e-04, 2.37031910e-04, 1.03308396e-04,\n",
              "        7.59661203e-04, 3.01918717e-04, 2.77154394e-05, 2.53946119e-05,\n",
              "        2.05901962e-04, 2.21958882e-04, 1.69211160e-04, 4.95884509e-05,\n",
              "        1.02458470e-04, 1.16125210e-04, 5.09897993e-04, 8.92469245e-05,\n",
              "        2.36014645e-05, 3.82744923e-05, 6.64594687e-05, 9.78525617e-05,\n",
              "        1.61515761e-04, 4.65894550e-05, 1.94387041e-05, 2.81739347e-05,\n",
              "        1.46635933e-03, 1.15669884e-04, 1.61083469e-05, 3.85662521e-05,\n",
              "        7.66984231e-05, 5.00300582e-05, 1.14337895e-04, 1.54537913e-05,\n",
              "        4.02367349e-04, 8.38344276e-05, 1.88480682e-04, 3.69226949e-04,\n",
              "        1.75308842e-05, 1.46016414e-04, 5.94202240e-05, 3.16287205e-05,\n",
              "        3.94585558e-05, 3.21778533e-05, 5.60835506e-05, 3.01003244e-05,\n",
              "        6.75226672e-05, 1.15316461e-03, 4.02831738e-05, 2.97956459e-05,\n",
              "        6.02847400e-05, 1.16536309e-03, 2.01489041e-04, 4.74740186e-05,\n",
              "        5.80200516e-05, 3.05615049e-05, 2.38040940e-04, 7.72269619e-04,\n",
              "        3.81188289e-05, 1.57276769e-05, 2.53877167e-05, 8.01439151e-05,\n",
              "        1.67200595e-04, 3.92066287e-05, 3.52077003e-05, 9.89854031e-04,\n",
              "        1.40054192e-04, 5.60961172e-05, 2.34815068e-05, 3.68054043e-05,\n",
              "        5.60342299e-05, 7.87221034e-05, 1.23196525e-04, 1.16043003e-05,\n",
              "        3.19770426e-05, 6.41258936e-05, 5.57810621e-05, 1.13158250e-04,\n",
              "        4.42908058e-05, 3.17912737e-05, 8.29770644e-05, 1.48048331e-04,\n",
              "        9.32243352e-05, 3.10561226e-05, 5.78885809e-05, 4.26144115e-05,\n",
              "        9.11165067e-05, 8.78349836e-05, 1.99369260e-05, 6.99657428e-05,\n",
              "        7.33323151e-05, 7.92750057e-05, 1.32352216e-04, 5.07958043e-05,\n",
              "        3.32078654e-05, 1.13951251e-04, 6.60857424e-05, 1.06969359e-04,\n",
              "        3.60992499e-05, 1.26248939e-04, 1.01642356e-04, 5.32263642e-04,\n",
              "        2.05006700e-03, 2.86925245e-05, 1.37449913e-05, 2.72300321e-05,\n",
              "        1.45218484e-04, 1.88581651e-04, 9.38271351e-05, 1.56527562e-05,\n",
              "        3.67228391e-05, 1.73039244e-04, 1.26134816e-03, 5.00247406e-06,\n",
              "        5.75362077e-05, 6.76851156e-05, 4.77078853e-05, 2.62613059e-05,\n",
              "        1.05567482e-05, 7.79901247e-05, 9.59887057e-05, 4.86229487e-04,\n",
              "        2.13351300e-04, 3.43615354e-05, 1.29796090e-05, 6.70768374e-05,\n",
              "        6.36536708e-05, 1.26289455e-04, 2.04965667e-05, 3.77783248e-05,\n",
              "        1.12234907e-04, 3.76415192e-04, 4.13500581e-05, 2.58038964e-05,\n",
              "        2.01276122e-05, 1.71638858e-05, 4.11238254e-05, 1.35740305e-04,\n",
              "        2.98487873e-05, 4.59086474e-05, 3.19963063e-05, 8.04686405e-05,\n",
              "        1.32926196e-03, 3.21606780e-05, 3.22868408e-05, 5.12756279e-05,\n",
              "        5.08464499e-05, 9.62578925e-05, 1.22182020e-05, 2.09708624e-05,\n",
              "        9.90049219e-05, 9.83275913e-05, 5.97142928e-05, 9.05237387e-06,\n",
              "        3.20087398e-05, 5.26559941e-05, 9.01831819e-05, 7.26797192e-04,\n",
              "        1.58632765e-05, 2.30221997e-05, 1.49264122e-04, 7.51002605e-04,\n",
              "        8.24287750e-05, 1.15964601e-05, 5.33443136e-04, 4.95074558e-05,\n",
              "        1.39660353e-04, 7.63129112e-04, 2.45666023e-05, 3.06411566e-05,\n",
              "        3.62413180e-05, 6.14122010e-04, 5.82798404e-05, 3.43803890e-05,\n",
              "        2.18519440e-05, 6.92130408e-05, 5.29833063e-04, 8.05557919e-05,\n",
              "        9.84573475e-06, 2.89344693e-05, 6.20867982e-05, 1.10332719e-03,\n",
              "        1.84012108e-04, 3.79800123e-05, 1.56167729e-04, 2.24425494e-04,\n",
              "        8.74318346e-05, 2.38745532e-04, 1.63692022e-05, 6.30355278e-05,\n",
              "        1.20128199e-04, 1.18424791e-04, 2.18809947e-04, 7.64221961e-05,\n",
              "        4.49913989e-05, 1.17188104e-04, 1.63600084e-04, 3.19058744e-04,\n",
              "        2.27963074e-05, 1.97829238e-04, 1.58301563e-04, 3.93829390e-05,\n",
              "        2.21318428e-04, 2.59126667e-05, 5.29602006e-04, 9.52983845e-05,\n",
              "        8.24178785e-05, 1.60801651e-04, 1.02096615e-05, 6.10815930e-05,\n",
              "        3.28405474e-05, 2.82904974e-04, 3.72551746e-05, 2.05696519e-05,\n",
              "        4.48735436e-05, 8.81840678e-05, 2.04948327e-04, 5.08142430e-05,\n",
              "        6.47955906e-05, 1.74077658e-04, 6.04633653e-05, 3.83992644e-04,\n",
              "        2.83108441e-04, 2.16740318e-04, 9.52751667e-05, 2.50894132e-04,\n",
              "        8.84978164e-05, 1.41827596e-04, 5.52977754e-05, 4.42047849e-05,\n",
              "        1.71764700e-04, 7.77028937e-05, 1.21512255e-04, 3.04516833e-04,\n",
              "        1.96914695e-05, 1.04202110e-04, 6.10815185e-05, 1.06950185e-04,\n",
              "        1.13005376e-05, 3.78995861e-05, 5.41006167e-05, 1.02148381e-04,\n",
              "        2.20227721e-03, 1.81026126e-05, 2.64997076e-05, 5.74291774e-04,\n",
              "        9.31030626e-05, 1.81484222e-04, 4.51659693e-05, 3.66081150e-05,\n",
              "        1.22323240e-04, 1.78093770e-04, 1.45496744e-03, 1.50090887e-05,\n",
              "        2.57912928e-05, 6.73571265e-05, 1.34126300e-04, 1.48293604e-03,\n",
              "        5.78019084e-05, 6.21916315e-05, 2.62152372e-04, 4.32608787e-05,\n",
              "        6.00775839e-05, 1.08488575e-05, 1.62404884e-05, 6.32907525e-05,\n",
              "        1.07887697e-03, 6.59204909e-05, 2.85730916e-05, 2.03674784e-05,\n",
              "        2.85019415e-05, 1.76184458e-04, 2.01406485e-03, 2.69717070e-05,\n",
              "        9.08446747e-06, 1.13212027e-04, 1.20471603e-04, 1.41881660e-04,\n",
              "        2.66574575e-05, 3.20976939e-05, 7.11236789e-05, 7.40078921e-05,\n",
              "        1.45264844e-03, 1.21784994e-05, 2.30077758e-05, 8.07517216e-05,\n",
              "        3.54459698e-04, 7.90935588e-05, 6.55716113e-06, 2.54558703e-05,\n",
              "        6.01375409e-05, 5.82412036e-05, 2.14202788e-04, 3.75392305e-05,\n",
              "        1.59518957e-05, 3.08792469e-05, 1.05737777e-04, 2.83102883e-04,\n",
              "        4.10022843e-05, 2.99367163e-05, 1.25487016e-05, 1.23813190e-04,\n",
              "        1.32071532e-04, 9.57410171e-06, 1.69135424e-05, 5.76884287e-05,\n",
              "        1.00569686e-03, 6.08685201e-05, 4.43462146e-05, 2.25895030e-05,\n",
              "        4.47767611e-05, 1.07563979e-04, 3.99011567e-05, 3.30787542e-05,\n",
              "        3.17387340e-05, 2.39277247e-05, 1.77518565e-04, 1.69785127e-04,\n",
              "        3.91341856e-05, 2.29172720e-05, 7.57322797e-05, 1.02307699e-04,\n",
              "        9.21759763e-04, 7.97522941e-05, 2.62419046e-05, 5.64774111e-05,\n",
              "        1.88274286e-03, 2.64964023e-04, 3.62620159e-05, 6.22194841e-06,\n",
              "        3.50916850e-04, 7.68940650e-04, 6.10043508e-04, 3.24134947e-05,\n",
              "        1.70006457e-04, 5.34299387e-05, 7.20984494e-04, 7.06051413e-05,\n",
              "        2.12036568e-05, 6.17459012e-05, 6.66019815e-05, 7.70553799e-05,\n",
              "        4.20079318e-04, 1.95697362e-05, 4.24672683e-05, 5.44725880e-05,\n",
              "        5.68194244e-05, 5.36599594e-04, 5.64061073e-05, 2.60422072e-05,\n",
              "        6.14186621e-05, 3.35622145e-04, 3.74984705e-04, 1.79111868e-05,\n",
              "        1.15719252e-05, 1.77369027e-04, 1.29901592e-04, 1.41332185e-04,\n",
              "        1.95232064e-05, 3.73337612e-05, 6.39359507e-05, 9.15286907e-05,\n",
              "        2.55004916e-05, 2.95655958e-05, 8.81236352e-05, 2.00534636e-04,\n",
              "        1.59088844e-03, 1.53930494e-04, 2.71761206e-05, 8.71248692e-05,\n",
              "        8.98912032e-05, 9.66389530e-05, 1.17519166e-04, 5.48405438e-05,\n",
              "        7.65848574e-05, 1.15446698e-04, 1.40956435e-04, 1.28945479e-04,\n",
              "        1.59202210e-05, 7.30044697e-05, 8.30196088e-05, 2.54998112e-04,\n",
              "        1.22282042e-04, 7.18730434e-05, 9.26133157e-05, 1.65698504e-04,\n",
              "        1.07221307e-04, 8.68462510e-05, 2.73660497e-05, 3.72067452e-05,\n",
              "        1.44847087e-05, 9.62292172e-04, 9.48620279e-05, 1.20427582e-05,\n",
              "        2.68059682e-05, 6.68278201e-04, 5.97095710e-05, 7.57609099e-04,\n",
              "        7.87950860e-06, 3.59322665e-05, 8.90361854e-05, 2.88533081e-04,\n",
              "        9.34741944e-04, 9.75957186e-05, 2.90203110e-05, 1.04436743e-04,\n",
              "        1.67855320e-03, 1.33962679e-04, 1.55688610e-05, 1.62332065e-05,\n",
              "        1.52181337e-04, 6.64615682e-04, 5.40882171e-05, 9.13965114e-05,\n",
              "        1.89842281e-05, 8.48664320e-05, 1.26181654e-04, 1.44040706e-04,\n",
              "        2.77252823e-05, 3.00554966e-05, 1.13852498e-04, 1.04148113e-04,\n",
              "        1.21975150e-04, 1.41762653e-05, 3.09088332e-05, 1.20089145e-05,\n",
              "        1.78330722e-05, 4.19025655e-05, 3.69483954e-04, 1.94100254e-05,\n",
              "        1.24802468e-04, 7.60035053e-05, 1.31975794e-04, 6.60965793e-06,\n",
              "        2.95395135e-05, 5.61112744e-05, 1.23356805e-04, 7.82070507e-05,\n",
              "        1.49983290e-05, 6.18309063e-06, 7.94452778e-05, 7.78015608e-05,\n",
              "        3.10533279e-04, 2.00492873e-05, 1.76916225e-05, 4.82170793e-05,\n",
              "        2.42378724e-05, 1.08085048e-04, 1.24082154e-05, 5.49725208e-05,\n",
              "        7.20477120e-05, 2.83594048e-04, 6.02983165e-05, 2.63383369e-05,\n",
              "        3.81295641e-05, 3.68386872e-05, 1.78919669e-03, 7.13970301e-05,\n",
              "        3.88069831e-04, 1.00222051e-05, 9.82895911e-05, 6.31419969e-04,\n",
              "        1.39596112e-04, 1.65073834e-05, 2.14841467e-06, 3.13142995e-05,\n",
              "        1.19120088e-04, 2.91550239e-03, 5.61744530e-05, 6.17511668e-05,\n",
              "        1.23342796e-04, 2.96847711e-04, 9.11994416e-05, 2.11961492e-05,\n",
              "        4.89403136e-06, 4.64687536e-05, 6.09838374e-05, 8.24206648e-05,\n",
              "        2.46193015e-05, 2.82305197e-04, 6.35469122e-04, 1.23695695e-04,\n",
              "        1.23069130e-04, 3.99304786e-04, 7.56871411e-05, 8.31669348e-05,\n",
              "        7.88493749e-05, 3.05575616e-05, 2.90759628e-04, 2.18788633e-04,\n",
              "        5.03361645e-05, 5.00466892e-05, 1.72962910e-04, 2.89614890e-05,\n",
              "        1.16709243e-05, 6.61094094e-05, 1.21589885e-04, 7.87895454e-05,\n",
              "        1.57250745e-05, 3.99439290e-05, 5.76920940e-05, 7.12139334e-05,\n",
              "        3.37636839e-04, 1.78623734e-05, 9.54794226e-06, 3.95781735e-05,\n",
              "        6.59714850e-05, 1.39653011e-04, 2.28262102e-05, 1.82967581e-05,\n",
              "        3.50925584e-05, 8.00304940e-05, 9.09212307e-05, 2.16220283e-05,\n",
              "        2.24602470e-04, 3.55231202e-05, 3.10616842e-04, 9.23220528e-05,\n",
              "        1.89646956e-05, 1.31987854e-04, 9.53617571e-05, 2.88445706e-04,\n",
              "        1.13974615e-04, 5.84617524e-05, 3.69943900e-05, 4.22653674e-05,\n",
              "        8.22018027e-05, 1.00838534e-04, 1.04932716e-04, 3.62262576e-05,\n",
              "        9.72577856e-05, 8.84762834e-05, 2.72776971e-04, 3.09247922e-05,\n",
              "        2.71058333e-05, 1.11640563e-04, 4.98910674e-04, 7.07717376e-04,\n",
              "        2.56915684e-05, 1.54776156e-04, 4.37006102e-05, 5.28462942e-05,\n",
              "        7.59613716e-05, 5.76958380e-05, 5.13136162e-05, 1.23469282e-04,\n",
              "        7.30698857e-04, 1.31885055e-04, 3.16479110e-04, 8.86000139e-05,\n",
              "        1.11239824e-04, 2.96102437e-05, 1.63205791e-04, 6.56399560e-05,\n",
              "        4.04638966e-05, 1.55902636e-04, 5.82829790e-04, 2.52972364e-04]),\n",
              " 'std_test_score': array([0.04704829, 0.04723243, 0.04583333, 0.04947643, 0.04039733,\n",
              "        0.0601647 , 0.0601647 , 0.06052433, 0.0463044 , 0.05212498,\n",
              "        0.06159061, 0.06215181, 0.0477806 , 0.03818813, 0.04187448,\n",
              "        0.06731456, 0.05840769, 0.03841477, 0.03320287, 0.0529511 ,\n",
              "        0.05496211, 0.03227486, 0.02990146, 0.05043216, 0.0344853 ,\n",
              "        0.03584302, 0.03691676, 0.04289846, 0.05335937, 0.03985651,\n",
              "        0.04468252, 0.04028975, 0.04903584, 0.03985651, 0.04370037,\n",
              "        0.060596  , 0.03807431, 0.04448783, 0.03397814, 0.04448783,\n",
              "        0.05613414, 0.04686342, 0.04166667, 0.0389756 , 0.04399732,\n",
              "        0.04218428, 0.02338536, 0.04516559, 0.04535738, 0.04135299,\n",
              "        0.0601647 , 0.02124591, 0.02411633, 0.04299952, 0.04564355,\n",
              "        0.05212498, 0.04340139, 0.02990146, 0.02585349, 0.04093101,\n",
              "        0.04658475, 0.06407732, 0.07077203, 0.04639804, 0.04439016,\n",
              "        0.05720638, 0.03385016, 0.025     , 0.02338536, 0.03397814,\n",
              "        0.05      , 0.02716334, 0.04930066, 0.03118048, 0.03572173,\n",
              "        0.06319063, 0.03397814, 0.02841288, 0.04145781, 0.0497389 ,\n",
              "        0.06088183, 0.02338536, 0.03668087, 0.03423266, 0.05456584,\n",
              "        0.03523236, 0.05229125, 0.07064927, 0.03584302, 0.03703414,\n",
              "        0.03267581, 0.03397814, 0.02901748, 0.03510896, 0.03644345,\n",
              "        0.03254271, 0.06144951, 0.03547789, 0.05392575, 0.05840769,\n",
              "        0.02990146, 0.03523236, 0.05527708, 0.04796194, 0.04135299,\n",
              "        0.03397814, 0.04592793, 0.05253967, 0.03267581, 0.04956407,\n",
              "        0.03875224, 0.04238956, 0.04814258, 0.05253967, 0.03919768,\n",
              "        0.01816208, 0.03200477, 0.04732424, 0.02585349, 0.05034602,\n",
              "        0.06541799, 0.02338536, 0.04289846, 0.04439016, 0.03320287,\n",
              "        0.02635231, 0.04340139, 0.05456584, 0.05651942, 0.03118048,\n",
              "        0.01214782, 0.02901748, 0.05456584, 0.04611655, 0.05120086,\n",
              "        0.06201198, 0.03523236, 0.03818813, 0.02411633, 0.05392575,\n",
              "        0.04564355, 0.0601647 , 0.06782842, 0.05162297, 0.03864008,\n",
              "        0.05      , 0.03461093, 0.04289846, 0.03864008, 0.04439016,\n",
              "        0.05162297, 0.02319902, 0.06421265, 0.05212498, 0.0344853 ,\n",
              "        0.06159061, 0.03572173, 0.05408648, 0.04439016, 0.04677072,\n",
              "        0.05034602, 0.06215181, 0.03385016, 0.04903584, 0.04704829,\n",
              "        0.02282177, 0.0344853 , 0.03584302, 0.02684187, 0.04135299,\n",
              "        0.02841288, 0.02748105, 0.03875224, 0.05914612, 0.05690208,\n",
              "        0.05408648, 0.05408648, 0.04686342, 0.05943893, 0.05327797,\n",
              "        0.041978  , 0.05408648, 0.04399732, 0.04028975, 0.03864008,\n",
              "        0.04135299, 0.02411633, 0.0644151 , 0.04145781, 0.05      ,\n",
              "        0.04218428, 0.03985651, 0.04145781, 0.04497299, 0.04028975,\n",
              "        0.05781015, 0.03254271, 0.03875224, 0.04439016, 0.03385016,\n",
              "        0.02585349, 0.06568284, 0.03644345, 0.04903584, 0.04686342,\n",
              "        0.04686342, 0.02429563, 0.03131937, 0.03703414, 0.03952847,\n",
              "        0.04686342, 0.05496211, 0.05368374, 0.03875224, 0.04340139,\n",
              "        0.03254271, 0.0344853 , 0.05651942, 0.05488308, 0.05527708,\n",
              "        0.05187458, 0.06201198, 0.04903584, 0.04187448, 0.04439016,\n",
              "        0.05212498, 0.03320287, 0.02825971, 0.04704829, 0.04289846,\n",
              "        0.05628857, 0.03131937, 0.03385016, 0.041978  , 0.04039733,\n",
              "        0.02517301, 0.03547789, 0.041978  , 0.02825971, 0.03807431,\n",
              "        0.01692508, 0.03131937, 0.0728869 , 0.04677072, 0.05034602,\n",
              "        0.05448624, 0.03572173, 0.0477806 , 0.04912428, 0.02871677,\n",
              "        0.0344853 , 0.04238956, 0.02124591, 0.05877807, 0.06928454,\n",
              "        0.0497389 , 0.03807431, 0.04903584, 0.04956407, 0.05017331,\n",
              "        0.04399732, 0.04187448, 0.02185018, 0.02019867, 0.04991312,\n",
              "        0.07383352, 0.05245699, 0.03090083, 0.02716334, 0.05408648,\n",
              "        0.03461093, 0.02716334, 0.04399732, 0.041978  , 0.04399732,\n",
              "        0.05335937, 0.05043216, 0.04545297, 0.05833333, 0.03807431,\n",
              "        0.04750731, 0.0625    , 0.06737901, 0.03584302, 0.02795085,\n",
              "        0.02990146, 0.02716334, 0.05253967, 0.03572173, 0.03864008,\n",
              "        0.03200477, 0.06501869, 0.03523236, 0.0477806 , 0.04350128,\n",
              "        0.06501869, 0.03930825, 0.03423266, 0.03841477, 0.03875224,\n",
              "        0.04592793, 0.0463044 , 0.04487637, 0.04487637, 0.03668087,\n",
              "        0.09605952, 0.05416667, 0.04956407, 0.03807431, 0.05796012,\n",
              "        0.05628857, 0.05781015, 0.04592793, 0.04991312, 0.03703414,\n",
              "        0.0477806 , 0.01743042, 0.03385016, 0.0488585 , 0.03186887,\n",
              "        0.07987621, 0.05      , 0.03320287, 0.04399732, 0.03875224,\n",
              "        0.03118048, 0.05690208, 0.0463044 , 0.04350128, 0.04823265,\n",
              "        0.03254271, 0.03930825, 0.04583333, 0.02946278, 0.04187448,\n",
              "        0.07186745, 0.04497299, 0.04903584, 0.04028975, 0.04991312,\n",
              "        0.02990146, 0.03930825, 0.03320287, 0.05212498, 0.03254271,\n",
              "        0.04399732, 0.03227486, 0.04487637, 0.03761556, 0.04238956,\n",
              "        0.04723243, 0.0344853 , 0.03818813, 0.05644257, 0.04639804,\n",
              "        0.04028975, 0.01792151, 0.03254271, 0.04028975, 0.03761556,\n",
              "        0.08025567, 0.03227486, 0.0488585 , 0.03090083, 0.03807431,\n",
              "        0.0389756 , 0.0576598 , 0.04039733, 0.04912428, 0.05170697,\n",
              "        0.04007372, 0.05212498, 0.04093101, 0.0559017 , 0.03461093,\n",
              "        0.05034602, 0.01412985, 0.04545297, 0.04859127, 0.04249183,\n",
              "        0.03864008, 0.04487637, 0.01530931, 0.03761556, 0.02144923,\n",
              "        0.02019867, 0.0477806 , 0.04639804, 0.03047654, 0.03547789,\n",
              "        0.05145454, 0.06666667, 0.041978  , 0.0477806 , 0.03875224,\n",
              "        0.02375365, 0.041978  , 0.05980292, 0.04340139, 0.05077524,\n",
              "        0.05376453, 0.04320092, 0.04823265, 0.05667279, 0.05408648,\n",
              "        0.04497299, 0.01932004, 0.02684187, 0.04299952, 0.04028975,\n",
              "        0.03523236, 0.04289846, 0.03461093, 0.04487637, 0.04516559,\n",
              "        0.03572173, 0.03919768, 0.03761556, 0.04535738, 0.03761556,\n",
              "        0.03047654, 0.0344853 , 0.03919768, 0.0463044 , 0.06002025,\n",
              "        0.02990146, 0.03047654, 0.03267581, 0.04340139, 0.02901748,\n",
              "        0.06833841, 0.02825971, 0.04135299, 0.04289846, 0.04903584,\n",
              "        0.02901748, 0.05980292, 0.0344853 , 0.03919768, 0.03333333,\n",
              "        0.04039733, 0.05311479, 0.03632416, 0.04028975, 0.02901748,\n",
              "        0.04723243, 0.03668087, 0.05212498, 0.03584302, 0.03131937,\n",
              "        0.05448624, 0.04956407, 0.03047654, 0.02916667, 0.03608439,\n",
              "        0.02901748, 0.04238956, 0.03320287, 0.03320287, 0.03841477,\n",
              "        0.02871677, 0.02019867, 0.04868051, 0.05644257, 0.04535738,\n",
              "        0.03807431, 0.02825971, 0.05987545, 0.03608439, 0.04093101,\n",
              "        0.04399732, 0.05566829, 0.01473139, 0.05527708, 0.041978  ,\n",
              "        0.04956407, 0.06201198, 0.02684187, 0.03294039, 0.04289846,\n",
              "        0.05376453, 0.0463044 , 0.04545297, 0.05376453, 0.04814258,\n",
              "        0.04187448, 0.07077203, 0.03875224, 0.05060399, 0.05245699,\n",
              "        0.04930066, 0.02825971, 0.05833333, 0.04658475, 0.05535554,\n",
              "        0.04947643, 0.041978  , 0.03047654, 0.01530931, 0.04497299,\n",
              "        0.02282177, 0.02975595, 0.0372678 , 0.05245699, 0.04166667,\n",
              "        0.04370037, 0.04028975, 0.05128556, 0.04686342, 0.05456584,\n",
              "        0.05245699, 0.04114254, 0.0463044 , 0.04947643, 0.04439016,\n",
              "        0.03333333, 0.06400955, 0.04238956, 0.04399732, 0.04370037,\n",
              "        0.07064927, 0.03930825, 0.03584302, 0.03523236, 0.04448783,\n",
              "        0.05705443, 0.02517301, 0.04238956, 0.0535218 , 0.05270463,\n",
              "        0.0529511 , 0.04028975, 0.05128556, 0.03320287, 0.05103104,\n",
              "        0.04039733, 0.03320287, 0.0529511 , 0.03691676, 0.03523236,\n",
              "        0.05245699, 0.04516559, 0.0477806 , 0.05229125, 0.04639804,\n",
              "        0.05270463, 0.03584302, 0.0559017 , 0.02763854, 0.02901748,\n",
              "        0.03584302, 0.03397814, 0.04903584, 0.0477806 , 0.05187458,\n",
              "        0.05270463, 0.02429563, 0.04903584, 0.03320287, 0.05987545,\n",
              "        0.0477806 , 0.03320287, 0.04028975, 0.05667279, 0.04399732,\n",
              "        0.02975595, 0.04093101, 0.05212498, 0.05535554, 0.04677072,\n",
              "        0.03691676, 0.02763854, 0.03864008, 0.05527708, 0.05416667,\n",
              "        0.05690208, 0.04439016, 0.06353313, 0.04723243, 0.03875224,\n",
              "        0.03691676, 0.03047654, 0.03547789, 0.03761556, 0.02946278,\n",
              "        0.03186887, 0.03423266, 0.03572173, 0.02990146, 0.0488585 ,\n",
              "        0.06407732, 0.01792151, 0.03267581, 0.041978  , 0.05690208,\n",
              "        0.03864008, 0.03523236, 0.0389756 , 0.0372678 , 0.03875224,\n",
              "        0.06144951, 0.01816208, 0.04639804, 0.04732424, 0.02901748,\n",
              "        0.06284626, 0.04439016, 0.04750731, 0.05103104, 0.05335937,\n",
              "        0.05987545, 0.04299952, 0.06215181, 0.01559024, 0.05566829,\n",
              "        0.02901748, 0.02871677, 0.0372678 , 0.03572173, 0.02667968,\n",
              "        0.03584302, 0.04039733, 0.03186887, 0.04704829, 0.05667279,\n",
              "        0.0557462 , 0.0559017 , 0.03875224, 0.02224391, 0.0344853 ,\n",
              "        0.05613414, 0.04439016, 0.04399732, 0.03397814, 0.03047654,\n",
              "        0.04859127, 0.05162297, 0.02975595, 0.04039733, 0.02871677])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMstuJy4mp8J"
      },
      "source": [
        "**Melhores parâmetros**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "psp5vHV6mp8K",
        "outputId": "189c28a0-93f0-4791-a535-b3a4195135a5"
      },
      "source": [
        "grid.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'gini',\n",
              " 'max_depth': 50,\n",
              " 'min_samples_leaf': 10,\n",
              " 'min_samples_split': 15,\n",
              " 'n_estimators': 100}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1ILIPHkmp8O"
      },
      "source": [
        "**Melhores scores**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-e1t9eSBmp8P",
        "outputId": "b018f6fb-13bf-4d9d-8281-ea9b8450e047"
      },
      "source": [
        "grid.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7270833333333334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-saCeuJ8nUGI"
      },
      "source": [
        "# Obrigado!\n",
        "\n",
        "Obrigado por ter disponibilizado um pouco do seu tempo e atenção aqui. Espero que, de alguma forma, tenha sido útil para seu crescimento. Se houver qualquer dúvida ou sugestão, não hesite em entrar em contato no [LinkedIn](https://www.linkedin.com/in/daniel-sousa-amador) e verificar meus outros projetos no [GitHub](https://github.com/amadords).\n",
        "\n",
        "\n",
        "[![LinkedIn](https://img.shields.io/badge/LinkedIn-DanielSousaAmador-cyan.svg)](https://www.linkedin.com/in/daniel-sousa-amador)\n",
        "[![GitHub](https://img.shields.io/badge/GitHub-amadords-darkblue.svg)](https://github.com/amadords)\n",
        "[![Medium](https://img.shields.io/badge/Medium-DanielSousaAmador-white.svg)](https://daniel-s-amador.medium.com/)\n",
        "\n",
        "\n",
        "<center><img width=\"90%\" src=\"https://raw.githubusercontent.com/danielamador12/Portfolio/master/github.png\"></center>"
      ]
    }
  ]
}